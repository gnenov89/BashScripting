{
	"acm": [{
			"name": "acm"
		},
		{
			"description": "Welcome to the AWS Certificate Manager (ACM) API documentation. You  can use ACM to manage SSL/TLS certificates for your AWS-based web-\n       sites and applications. For general information about  using  ACM,  see\n       the       `      AWS      Certificate      Manager      User      Guide\n       http://docs.aws.amazon.com/acm/latest/userguide/.\n\n      \n              Inline interpreted text or phrase reference start-string without\n              end-string."
		},
		{
			"available commands": [
				"add-tags-to-certificate",
				"delete-certificate",
				"describe-certificate",
				"export-certificate",
				"get-certificate",
				"help",
				"import-certificate",
				"list-certificates",
				"list-tags-for-certificate",
				"remove-tags-from-certificate",
				"request-certificate",
				"resend-validation-email",
				"update-certificate-options",
				"wait"
			]
		}
	],
	"acm-pca": [{
			"name": "acm-pca"
		},
		{
			"description": "You  can  use the ACM PCA API to create a private certificate authority\n       (CA). You must first call the  create-certificate-authority  operation.\n       If  successful, the operation returns an Amazon Resource Name (ARN) for\n       your private CA. Use this ARN as input to the   get-certificate-author-\n       ity-csr operation to retrieve the certificate signing request (CSR) for\n       your private CA certificate. Sign the CSR using the root or an interme-\n       diate  CA  in your on-premises PKI hierarchy, and call the  import-cer-\n       tificate-authority-certificate to import your signed  private  CA  cer-\n       tificate into ACM PCA.\n\n       Use your private CA to issue and revoke certificates. These are private\n       certificates that identify and secure client computers, servers, appli-\n       cations,  services, devices, and users over SSLS/TLS connections within\n       your organization. Call the  issue-certificate  operation  to  issue  a\n       certificate.  Call  the   revoke-certificate operation to revoke a cer-\n       tificate.\n\n       NOTE:\n          Certificates issued by your private CA can be  trusted  only  within\n          your organization, not publicly.\n\n       Your  private  CA  can  optionally create a certificate revocation list\n       (CRL) to track the certificates you revoke. To create a CRL,  you  must\n       specify  a   RevocationConfiguration  object  when  you  call the  cre-\n       ate-certificate-authority operation. ACM PCA writes the CRL  to  an  S3\n       bucket  that  you specify. You must specify a bucket policy that grants\n       ACM PCA write permission.\n\n       You can also  call  the   create-certificate-authority-audit-report  to\n       create  an  optional  audit report that lists every time the CA private\n       key is used. The private key is used for signing  when  the  issue-cer-\n       tificate or revoke-certificate operation is called."
		},
		{
			"available commands": [
				"create-certificate-authority",
				"create-certificate-authority-audit-report",
				"delete-certificate-authority",
				"describe-certificate-authority",
				"describe-certificate-authority-audit-report",
				"get-certificate",
				"get-certificate-authority-certificate",
				"get-certificate-authority-csr",
				"help",
				"import-certificate-authority-certificate",
				"issue-certificate",
				"list-certificate-authorities",
				"list-tags",
				"restore-certificate-authority",
				"revoke-certificate",
				"tag-certificate-authority",
				"untag-certificate-authority",
				"update-certificate-authority"
			]
		}
	],
	"alexaforbusiness": [{
			"name": "alexaforbusiness"
		},
		{
			"description": "Alexa for Business makes it easy for you to use Alexa in your organiza-\n       tion. Alexa for Business gives you the  tools  you  need  for  managing\n       Alexa  devices, enroll your users, and assign skills, at scale. You can\n       build your own context-aware voice skills using the  Alexa  Skills  Kit\n       and  the  Alexa  for  Business  API operations. You can make also these\n       available as private skills for your organization. Alexa  for  Business\n       makes  it  easy  to  voice-enable your products and services, providing\n       context-aware voice experiences for your customers."
		},
		{
			"available commands": [
				"associate-contact-with-address-book",
				"associate-device-with-room",
				"associate-skill-group-with-room",
				"create-address-book",
				"create-contact",
				"create-profile",
				"create-room",
				"create-skill-group",
				"create-user",
				"delete-address-book",
				"delete-contact",
				"delete-profile",
				"delete-room",
				"delete-room-skill-parameter",
				"delete-skill-group",
				"delete-user",
				"disassociate-contact-from-address-book",
				"disassociate-device-from-room",
				"disassociate-skill-group-from-room",
				"get-address-book",
				"get-contact",
				"get-device",
				"get-profile",
				"get-room",
				"get-room-skill-parameter",
				"get-skill-group",
				"help",
				"list-device-events",
				"list-skills",
				"list-tags",
				"put-room-skill-parameter",
				"resolve-room",
				"revoke-invitation",
				"search-address-books",
				"search-contacts",
				"search-devices",
				"search-profiles",
				"search-rooms",
				"search-skill-groups",
				"search-users",
				"send-invitation",
				"start-device-sync",
				"tag-resource",
				"untag-resource",
				"update-address-book",
				"update-contact",
				"update-device",
				"update-profile",
				"update-room",
				"update-skill-group"
			]
		}
	],
	"apigateway": [{
			"name": "apigateway"
		},
		{
			"description": "Amazon  API  Gateway helps developers deliver robust, secure, and scal-\n       able mobile and web application back ends. API Gateway allows  develop-\n       ers to securely connect mobile and web applications to APIs that run on\n       AWS Lambda, Amazon EC2, or other publicly addressable web services that\n       are hosted outside of AWS."
		},
		{
			"available commands": [
				"create-api-key",
				"create-authorizer",
				"create-base-path-mapping",
				"create-deployment",
				"create-documentation-part",
				"create-documentation-version",
				"create-domain-name",
				"create-model",
				"create-request-validator",
				"create-resource",
				"create-rest-api",
				"create-stage",
				"create-usage-plan",
				"create-usage-plan-key",
				"create-vpc-link",
				"delete-api-key",
				"delete-authorizer",
				"delete-base-path-mapping",
				"delete-client-certificate",
				"delete-deployment",
				"delete-documentation-part",
				"delete-documentation-version",
				"delete-domain-name",
				"delete-gateway-response",
				"delete-integration",
				"delete-integration-response",
				"delete-method",
				"delete-method-response",
				"delete-model",
				"delete-request-validator",
				"delete-resource",
				"delete-rest-api",
				"delete-stage",
				"delete-usage-plan",
				"delete-usage-plan-key",
				"delete-vpc-link",
				"flush-stage-authorizers-cache",
				"flush-stage-cache",
				"generate-client-certificate",
				"get-account",
				"get-api-key",
				"get-api-keys",
				"get-authorizer",
				"get-authorizers",
				"get-base-path-mapping",
				"get-base-path-mappings",
				"get-client-certificate",
				"get-client-certificates",
				"get-deployment",
				"get-deployments",
				"get-documentation-part",
				"get-documentation-parts",
				"get-documentation-version",
				"get-documentation-versions",
				"get-domain-name",
				"get-domain-names",
				"get-export",
				"get-gateway-response",
				"get-gateway-responses",
				"get-integration",
				"get-integration-response",
				"get-method",
				"get-method-response",
				"get-model",
				"get-model-template",
				"get-models",
				"get-request-validator",
				"get-request-validators",
				"get-resource",
				"get-resources",
				"get-rest-api",
				"get-rest-apis",
				"get-sdk",
				"get-sdk-type",
				"get-sdk-types",
				"get-stage",
				"get-stages",
				"get-tags",
				"get-usage",
				"get-usage-plan",
				"get-usage-plan-key",
				"get-usage-plan-keys",
				"get-usage-plans",
				"get-vpc-link",
				"get-vpc-links",
				"help",
				"import-api-keys",
				"import-documentation-parts",
				"import-rest-api",
				"put-gateway-response",
				"put-integration",
				"put-integration-response",
				"put-method",
				"put-method-response",
				"put-rest-api",
				"tag-resource",
				"test-invoke-authorizer",
				"test-invoke-method",
				"untag-resource",
				"update-account",
				"update-api-key",
				"update-authorizer",
				"update-base-path-mapping",
				"update-client-certificate",
				"update-deployment",
				"update-documentation-part",
				"update-documentation-version",
				"update-domain-name",
				"update-gateway-response",
				"update-integration",
				"update-integration-response",
				"update-method",
				"update-method-response",
				"update-model",
				"update-request-validator",
				"update-resource",
				"update-rest-api",
				"update-stage",
				"update-usage",
				"update-usage-plan",
				"update-vpc-link"
			]
		}
	],
	"application-autoscaling": [{
			"name": "application-autoscaling"
		},
		{
			"description": "With  Application Auto Scaling, you can configure automatic scaling for\n       your scalable resources. You can use Application Auto Scaling to accom-\n       plish the following tasks:\n\n      Define  scaling  policies  to  automatically scale your AWS or custom\n         resources\n\n      Scale your resources in response to CloudWatch alarms\n\n      Schedule one-time or recurring scaling actions\n\n      View the history of your scaling events\n\n       Application Auto Scaling can scale the following resources:\n\n      Amazon ECS services. For more information, see Service  Auto  Scaling\n         in the Amazon Elastic Container Service Developer Guide .\n\n      Amazon  EC2  Spot fleets. For more information, see Automatic Scaling\n         for Spot Fleet in the Amazon EC2 User Guide .\n\n      Amazon EMR clusters. For more information, see Using Automatic  Scal-\n         ing in Amazon EMR in the Amazon EMR Management Guide .\n\n      AppStream  2.0  fleets.  For more information, see Fleet Auto Scaling\n         for Amazon AppStream 2.0 in the Amazon AppStream 2.0 Developer  Guide\n         .\n\n      Provisioned  read  and  write capacity for Amazon DynamoDB tables and\n         global secondary indexes. For more information, see Managing Through-\n         put  Capacity  Automatically with DynamoDB Auto Scaling in the Amazon\n         DynamoDB Developer Guide .\n\n      Amazon Aurora Replicas. For more information, see Using Amazon Aurora\n         Auto Scaling with Aurora Replicas .\n\n      Amazon   SageMaker  endpoint  variants.  For  more  information,  see\n         Automatically Scaling Amazon SageMaker Models .\n\n      Custom resources provided by your own applications or services.  More\n         information is available in our GitHub repository .\n\n       To  learn more about Application Auto Scaling, see the Application Auto\n       Scaling User Guide .\n\n       To configure automatic scaling for multiple resources  across  multiple\n       services, use AWS Auto Scaling to create a scaling plan for your appli-\n       cation. For more information, see the AWS Auto Scaling User Guide ."
		},
		{
			"available commands": [
				"delete-scaling-policy",
				"delete-scheduled-action",
				"deregister-scalable-target",
				"describe-scalable-targets",
				"describe-scaling-activities",
				"describe-scaling-policies",
				"describe-scheduled-actions",
				"help",
				"put-scaling-policy",
				"put-scheduled-action",
				"register-scalable-target"
			]
		}
	],
	"appstream": [{
			"name": "appstream"
		},
		{
			"description": "You  can use Amazon AppStream 2.0 to stream desktop applications to any\n       device running a web browser, without rewriting them."
		},
		{
			"available commands": [
				"associate-fleet",
				"copy-image",
				"create-directory-config",
				"create-fleet",
				"create-image-builder",
				"create-image-builder-streaming-url",
				"create-stack",
				"create-streaming-url",
				"delete-directory-config",
				"delete-fleet",
				"delete-image",
				"delete-image-builder",
				"delete-stack",
				"describe-directory-configs",
				"describe-fleets",
				"describe-image-builders",
				"describe-images",
				"describe-sessions",
				"describe-stacks",
				"disassociate-fleet",
				"expire-session",
				"help",
				"list-associated-fleets",
				"list-associated-stacks",
				"list-tags-for-resource",
				"start-fleet",
				"start-image-builder",
				"stop-fleet",
				"stop-image-builder",
				"tag-resource",
				"untag-resource",
				"update-directory-config",
				"update-fleet",
				"update-stack",
				"wait"
			]
		}
	],
	"appsync": [{
			"name": "appsync"
		},
		{
			"description": "AWS AppSync provides API actions for creating and interacting with data\n       sources using GraphQL from your application."
		},
		{
			"available commands": [
				"create-api-key",
				"create-data-source",
				"create-graphql-api",
				"create-resolver",
				"create-type",
				"delete-api-key",
				"delete-data-source",
				"delete-graphql-api",
				"delete-resolver",
				"delete-type",
				"get-data-source",
				"get-graphql-api",
				"get-introspection-schema",
				"get-resolver",
				"get-schema-creation-status",
				"get-type",
				"help",
				"list-api-keys",
				"list-data-sources",
				"list-graphql-apis",
				"list-resolvers",
				"list-types",
				"start-schema-creation",
				"update-api-key",
				"update-data-source",
				"update-graphql-api",
				"update-resolver",
				"update-type"
			]
		}
	],
	"athena": [{
			"name": "athena"
		},
		{
			"description": "Amazon  Athena  is an interactive query service that lets you use stan-\n       dard SQL to analyze data directly in Amazon S3. You can point Athena at\n       your  data  in Amazon S3 and run ad-hoc queries and get results in sec-\n       onds. Athena is serverless, so there is no infrastructure to set up  or\n       manage.  You  pay only for the queries you run. Athena scales automati-\n       callyexecuting queries in parallelso results are fast, even with  large\n       datasets  and complex queries. For more information, see What is Amazon\n       Athena in the Amazon Athena User Guide .\n\n       For code samples using the AWS SDK for Java, see Examples and Code Sam-\n       ples in the Amazon Athena User Guide ."
		},
		{
			"available commands": [
				"batch-get-named-query",
				"batch-get-query-execution",
				"create-named-query",
				"delete-named-query",
				"get-named-query",
				"get-query-execution",
				"get-query-results",
				"help",
				"list-named-queries",
				"list-query-executions",
				"start-query-execution",
				"stop-query-execution"
			]
		}
	],
	"autoscaling": [{
			"name": "autoscaling"
		},
		{
			"description": "Amazon  EC2  Auto Scaling is designed to automatically launch or termi-\n       nate EC2 instances  based  on  user-defined  policies,  schedules,  and\n       health  checks. Use this service in conjunction with the AWS Auto Scal-\n       ing, Amazon CloudWatch, and Elastic Load Balancing services."
		},
		{
			"available commands": [
				"attach-instances",
				"attach-load-balancer-target-groups",
				"attach-load-balancers",
				"complete-lifecycle-action",
				"create-auto-scaling-group",
				"create-launch-configuration",
				"create-or-update-tags",
				"delete-auto-scaling-group",
				"delete-launch-configuration",
				"delete-lifecycle-hook",
				"delete-notification-configuration",
				"delete-policy",
				"delete-scheduled-action",
				"delete-tags",
				"describe-account-limits",
				"describe-adjustment-types",
				"describe-auto-scaling-groups",
				"describe-auto-scaling-instances",
				"describe-auto-scaling-notification-types",
				"describe-launch-configurations",
				"describe-lifecycle-hook-types",
				"describe-lifecycle-hooks",
				"describe-load-balancer-target-groups",
				"describe-load-balancers",
				"describe-metric-collection-types",
				"describe-notification-configurations",
				"describe-policies",
				"describe-scaling-activities",
				"describe-scaling-process-types",
				"describe-scheduled-actions",
				"describe-tags",
				"describe-termination-policy-types",
				"detach-instances",
				"detach-load-balancer-target-groups",
				"detach-load-balancers",
				"disable-metrics-collection",
				"enable-metrics-collection",
				"enter-standby",
				"execute-policy",
				"exit-standby",
				"help",
				"put-lifecycle-hook",
				"put-notification-configuration",
				"put-scaling-policy",
				"put-scheduled-update-group-action",
				"record-lifecycle-action-heartbeat",
				"resume-processes",
				"set-desired-capacity",
				"set-instance-health",
				"set-instance-protection",
				"suspend-processes",
				"terminate-instance-in-auto-scaling-group",
				"update-auto-scaling-group"
			]
		}
	],
	"autoscaling-plans": [{
			"name": "autoscaling-plans"
		},
		{
			"description": "Use AWS Auto Scaling to quickly discover all the scalable AWS resources\n       for your application and configure dynamic scaling  for  your  scalable\n       resources.\n\n       To  get  started, create a scaling plan with a set of instructions used\n       to configure dynamic scaling for the scalable resources in your  appli-\n       cation.  AWS  Auto Scaling creates target tracking scaling policies for\n       the scalable resources in your scaling plan.  Target  tracking  scaling\n       policies  adjust  the capacity of your scalable resource as required to\n       maintain resource utilization at the target value that you specified."
		},
		{
			"available commands": [
				"create-scaling-plan",
				"delete-scaling-plan",
				"describe-scaling-plan-resources",
				"describe-scaling-plans",
				"help",
				"update-scaling-plan"
			]
		}
	],
	"batch": [{
			"name": "batch"
		},
		{
			"description": "AWS  Batch  enables  you  to  run  batch computing workloads on the AWS\n       Cloud. Batch computing is a common way for developers, scientists,  and\n       engineers  to  access large amounts of compute resources, and AWS Batch\n       removes the undifferentiated heavy lifting of configuring and  managing\n       the  required  infrastructure.  AWS  Batch will be familiar to users of\n       traditional batch computing software. This service can efficiently pro-\n       vision  resources  in  response to jobs submitted in order to eliminate\n       capacity  constraints,  reduce  compute  costs,  and  deliver   results\n       quickly.\n\n       As  a  fully managed service, AWS Batch enables developers, scientists,\n       and engineers to run batch computing workloads of any scale. AWS  Batch\n       automatically  provisions  compute resources and optimizes the workload\n       distribution based on the quantity and scale of the workloads. With AWS\n       Batch,  there is no need to install or manage batch computing software,\n       which allows you to focus on analyzing results  and  solving  problems.\n       AWS  Batch  reduces  operational  complexities, saves time, and reduces\n       costs, which makes it easy for developers, scientists, and engineers to\n       run their batch jobs in the AWS Cloud."
		},
		{
			"available commands": [
				"cancel-job",
				"create-compute-environment",
				"create-job-queue",
				"delete-compute-environment",
				"delete-job-queue",
				"deregister-job-definition",
				"describe-compute-environments",
				"describe-job-definitions",
				"describe-job-queues",
				"describe-jobs",
				"help",
				"list-jobs",
				"register-job-definition",
				"submit-job",
				"terminate-job",
				"update-compute-environment",
				"update-job-queue"
			]
		}
	],
	"budgets": [{
			"name": "budgets"
		},
		{
			"description": "Budgets  enable you to plan your service usage, service costs, and your\n       RI utilization. You can also track how close your plan is to your  bud-\n       geted  amount  or  to  the free tier limits. Budgets provide you with a\n       quick way to see your usage-to-date and current estimated charges  from\n       AWS  and to see how much your predicted usage accrues in charges by the\n       end of the month. Budgets also compare current estimates and charges to\n       the amount that you indicated you want to use or spend and lets you see\n       how much of your budget has been used. AWS updates your  budget  status\n       several times a day. Budgets track your unblended costs, subscriptions,\n       and refunds. You can create the following types of budgets:\n\n      Cost budgets allow you to say how much you want to spend  on  a  ser-\n         vice.\n\n      Usage budgets allow you to say how many hours you want to use for one\n         or more services.\n\n      RI utilization budgets allow you to define  a  utilization  threshold\n         and receive alerts when RIs are tracking below that threshold.\n\n       You  can create up to 20,000 budgets per AWS master account. Your first\n       two budgets are free of charge. Each additional budget costs $0.02  per\n       day. You can set up optional notifications that warn you if you exceed,\n       or are forecasted to exceed, your budgeted amount. You can have notifi-\n       cations  sent  to an Amazon SNS topic, to an email address, or to both.\n       For more information, see Creating an Amazon SNS Topic for Budget Noti-\n       fications . AWS Free Tier usage alerts via AWS Budgets are provided for\n       you, and do not count toward your budget limits.\n\n       Service Endpoint\n\n       The AWS Budgets API provides the following endpoint:\n\n        https://budgets.amazonaws.com\n\n       For information about costs associated with the AWS  Budgets  API,  see\n       AWS Cost Ma"
		},
		{
			"available commands": [
				"create-budget",
				"create-notification",
				"create-subscriber",
				"delete-budget",
				"delete-notification",
				"delete-subscriber",
				"describe-budget",
				"describe-budgets",
				"describe-notifications-for-budget",
				"describe-subscribers-for-notification",
				"help",
				"update-budget",
				"update-notification",
				"update-subscriber"
			]
		}
	],

	"ce": [{
			"name": "ce"
		},
		{
			"description": "The  Cost  Explorer  API allows you to programmatically query your cost\n       and usage data. You can query for aggregated data such as total monthly\n       costs  or total daily usage. You can also query for granular data, such\n       as the number of daily write operations for  Amazon  DynamoDB  database\n       tables in your production environment.\n\n       Service Endpoint\n\n       The Cost Explorer API provides the following endpoint:\n\n     < https://ce.us-east-1.amazonaws.com\n\n       For  information about costs associated with the Cost Explorer API, see\n       AWS Cost Management Pricing ."
		},
		{
			"available commands": [
				"get-cost-and-usage",
				"get-dimension-values",
				"get-reservation-coverage",
				"get-reservation-purchase-recommendation",
				"get-reservation-utilization",
				"get-tags",
				"help"
			]
		}
	],
	"cloud9": [{
			"name": "cloud9"
		},
		{
			"description": "AWS  Cloud9  is  a collection of tools that you can use to code, build,\n       run, test, debug, and release software in the cloud.\n\n       For more information about AWS Cloud9, see the AWS Cloud9 User Guide  .\n\n       AWS Cloud9 supports these operations:\n\n       -create-environment-ec2  :  Creates an AWS Cloud9 development environ-\n         ment, launches an Amazon EC2 instance, and  then  connects  from  the\n         instance to the environment.\n\n       -create-environment-membership  :  Adds  an  environment  member to an\n         environment.\n\n       -delete-environment  :  Deletes  an  environment.  If  an  Amazon  EC2\n         instance  is  connected  to  the  environment,  also  terminates  the\n         instance.\n\n       -delete-environment-membership : Deletes an environment member from an\n         environment.\n\n       -describe-environment-memberships : Gets information about environment\n         members for an environment.\n\n       -describe-environments : Gets information about environments.\n\n       -describe-environment-status : Gets status information for an environ-\n         ment.\n\n       -list-environments : Gets a list of environment identifiers.\n\n       -update-environment : Changes the settings of an existing environment.\n\n       -update-environment-membership : Changes the settings of  an  existing\n         environme"
		},
		{
			"available commands": [
				"create-environment-ec",
				"create-environment-membership",
				"delete-environment",
				"delete-environment-membership",
				"describe-environment-memberships",
				"describe-environment-status",
				"describe-environments",
				"help",
				"list-environments",
				"update-environment",
				"update-environment-membership"
			]
		}
	],
	"clouddirectory": [{
			"name": "clouddirectory"
		},
		{
			"description": "Amazon Cloud Directory is a component of the AWS Directory Service that\n       simplifies the development and management of cloud-scale  web,  mobile,\n       and  IoT  applications. This guide describes the Cloud Directory opera-\n       tions that you can call programmatically and includes detailed informa-\n       tion on data types and errors. For information about AWS Directory Ser-\n       vices features, see AWS Directory Service and the AWS Directory Service\n       Administration Guide ."
		},
		{
			"available commands": [
				"add-facet-to-object",
				"apply-schema",
				"attach-object",
				"attach-policy",
				"attach-to-index",
				"attach-typed-link",
				"batch-read",
				"batch-write",
				"create-directory",
				"create-facet",
				"create-index",
				"create-object",
				"create-schema",
				"create-typed-link-facet",
				"delete-directory",
				"delete-facet",
				"delete-object",
				"delete-schema",
				"delete-typed-link-facet",
				"detach-from-index",
				"detach-object",
				"detach-policy",
				"detach-typed-link",
				"disable-directory",
				"enable-directory",
				"get-applied-schema-version",
				"get-directory",
				"get-facet",
				"get-link-attributes",
				"get-object-attributes",
				"get-object-information",
				"get-schema-as-json",
				"get-typed-link-facet-information",
				"help",
				"list-applied-schema-arns",
				"list-attached-indices",
				"list-development-schema-arns",
				"list-directories",
				"list-facet-attributes",
				"list-facet-names",
				"list-incoming-typed-links",
				"list-index",
				"list-managed-schema-arns",
				"list-object-attributes",
				"list-object-children",
				"list-object-parent-paths",
				"list-object-parents",
				"list-object-policies",
				"list-outgoing-typed-links",
				"list-policy-attachments",
				"list-published-schema-arns",
				"list-tags-for-resource",
				"list-typed-link-facet-attributes",
				"list-typed-link-facet-names",
				"lookup-policy",
				"publish-schema",
				"put-schema-from-json",
				"remove-facet-from-object",
				"tag-resource",
				"untag-resource",
				"update-facet",
				"update-link-attributes",
				"update-object-attributes",
				"update-schema",
				"update-typed-link-facet",
				"upgrade-applied-schema",
				"upgrade-published-schema"
			]
		}
	],
	"cloudformation": [{
			"name": "cloudformation"
		},
		{
			"description": "AWS  CloudFormation  allows you to create and manage AWS infrastructure\n       deployments predictably and repeatedly. You can use AWS  CloudFormation\n       to  leverage AWS products, such as Amazon Elastic Compute Cloud, Amazon\n       Elastic Block Store, Amazon Simple Notification Service,  Elastic  Load\n       Balancing,  and Auto Scaling to build highly-reliable, highly scalable,\n       cost-effective applications without creating or configuring the  under-\n       lying AWS infrastructure.\n\n       With  AWS  CloudFormation, you declare all of your resources and depen-\n       dencies in a template  file.  The  template  defines  a  collection  of\n       resources  as  a single unit called a stack. AWS CloudFormation creates\n       and deletes all member resources of the stack together and manages  all\n       dependencies between the resources for you.\n\n       For  more information about AWS CloudFormation, see the AWS CloudForma-\n       tion Product Page .\n\n       Amazon CloudFormation makes use of other  AWS  products.  If  you  need\n       additional  technical information about a specific AWS product, you can\n       find the product's technical documentation at docs.aws.amazon.com ."
		},
		{
			"available commands": [
				"cancel-update-stack",
				"continue-update-rollback",
				"create-change-set",
				"create-stack",
				"create-stack-instances",
				"create-stack-set",
				"delete-change-set",
				"delete-stack",
				"delete-stack-instances",
				"delete-stack-set",
				"deploy",
				"describe-account-limits",
				"describe-change-set",
				"describe-stack-events",
				"describe-stack-instance",
				"describe-stack-resource",
				"describe-stack-resources",
				"describe-stack-set",
				"describe-stack-set-operation",
				"describe-stacks",
				"estimate-template-cost",
				"execute-change-set",
				"get-stack-policy",
				"get-template",
				"get-template-summary",
				"help",
				"list-change-sets",
				"list-exports",
				"list-imports",
				"list-stack-instances",
				"list-stack-resources",
				"list-stack-set-operation-results",
				"list-stack-set-operations",
				"list-stack-sets",
				"list-stacks",
				"package",
				"set-stack-policy",
				"signal-resource",
				"stop-stack-set-operation",
				"update-stack",
				"update-stack-instances",
				"update-stack-set",
				"update-termination-protection",
				"validate-template",
				"wait"
			]
		}
	],
	"cloudfront": [{
			"name": "cloudfront"
		},
		{
			"description": "This  is the Amazon CloudFront API Reference . This guide is for devel-\n       opers who need detailed information about CloudFront API actions,  data\n       types,  and errors. For detailed information about CloudFront features,\n       see the Amazon CloudFront Developer Guide ."
		},
		{
			"available commands": [
				"create-cloud-front-origin-access-identity",
				"create-distribution",
				"create-distribution-with-tags",
				"create-field-level-encryption-config",
				"create-field-level-encryption-profile",
				"create-invalidation",
				"create-public-key",
				"create-streaming-distribution",
				"create-streaming-distribution-with-tags",
				"delete-cloud-front-origin-access-identity",
				"delete-distribution",
				"delete-field-level-encryption-config",
				"delete-field-level-encryption-profile",
				"delete-public-key",
				"delete-streaming-distribution",
				"get-cloud-front-origin-access-identity",
				"get-cloud-front-origin-access-identity-config",
				"get-distribution",
				"get-distribution-config",
				"get-field-level-encryption",
				"get-field-level-encryption-config",
				"get-field-level-encryption-profile",
				"get-field-level-encryption-profile-config",
				"get-invalidation",
				"get-public-key",
				"get-public-key-config",
				"get-streaming-distribution",
				"get-streaming-distribution-config",
				"help",
				"list-cloud-front-origin-access-identities",
				"list-distributions",
				"list-distributions-by-web-acl-id",
				"list-field-level-encryption-configs",
				"list-field-level-encryption-profiles",
				"list-invalidations",
				"list-public-keys",
				"list-streaming-distributions",
				"list-tags-for-resource",
				"sign",
				"tag-resource",
				"untag-resource",
				"update-cloud-front-origin-access-identity",
				"update-distribution",
				"update-field-level-encryption-config",
				"update-field-level-encryption-profile",
				"update-public-key",
				"update-streaming-distribution",
				"wait"
			]
		}
	],
	"cloudhsm": [{
			"name": "cloudhsm"
		},
		{
			"description": "This  is documentation for AWS CloudHSM Classic . For more information,\n       see AWS CloudHSM Classic FAQs , the AWS CloudHSM Classic User  Guide  ,\n       and the AWS CloudHSM Classic API Reference .\n          For  information about the current version of AWS CloudHSM , see AWS\n          CloudHSM , the AWS CloudHSM User Guide , and the  AWS  CloudHSM  API\n          Reference ."
		},
		{
			"available commands": [
				"add-tags-to-resource",
				"create-hapg",
				"create-hsm",
				"create-luna-client",
				"delete-hapg",
				"delete-hsm",
				"delete-luna-client",
				"describe-hapg",
				"describe-hsm",
				"describe-luna-client",
				"get-config",
				"help",
				"list-available-zones",
				"list-hapgs",
				"list-hsms",
				"list-luna-clients",
				"list-tags-for-resource",
				"modify-hapg",
				"modify-hsm",
				"modify-luna-client",
				"remove-tags-from-resource"
			]
		}
	],
	"cloudhsmv2": [{
			"name": "cloudhsmv2"
		},
		{
			"description": "For  more  information about AWS CloudHSM, see AWS CloudHSM and the AWS\n       CloudHSM User Guide ."
		},
		{
			"available commands": [
				"create-cluster",
				"create-hsm",
				"delete-cluster",
				"delete-hsm",
				"describe-backups",
				"describe-clusters",
				"help",
				"initialize-cluster",
				"list-tags",
				"tag-resource",
				"untag-resource"
			]
		}
	],
	"cloudsearch": [{
			"name": "cloudsearch"
		},
		{
			"description": "You use the Amazon CloudSearch configuration service to create, config-\n       ure, and manage search domains. Configuration service requests are sub-\n       mitted  using  the  AWS  Query protocol. AWS Query requests are HTTP or\n       HTTPS requests submitted via HTTP GET or POST with  a  query  parameter\n       named Action.\n\n       The  endpoint  for  configuration  service requests is region-specific:\n       cloudsearch.*region*    .amazonaws.com.     For     example,     cloud-\n       search.us-east-1.amazonaws.com. For a current list of supported regions\n       and endpoints, see Regions and Endpoints ."
		},
		{
			"available commands": [
				"build-suggesters",
				"create-domain",
				"define-analysis-scheme",
				"define-expression",
				"define-index-field",
				"define-suggester",
				"delete-analysis-scheme",
				"delete-domain",
				"delete-expression",
				"delete-index-field",
				"delete-suggester",
				"describe-analysis-schemes",
				"describe-availability-options",
				"describe-domains",
				"describe-expressions",
				"describe-index-fields",
				"describe-scaling-parameters",
				"describe-service-access-policies",
				"describe-suggesters",
				"help",
				"index-documents",
				"list-domain-names",
				"update-availability-options",
				"update-scaling-parameters",
				"update-service-access-policies"
			]
		}
	],
	"cloudsearchdomain": [{
			"name": "cloudsearchdomain"
		},
		{
			"description": "You  use  the AmazonCloudSearch2013 API to upload documents to a search\n       domain and search those documents.\n\n       The endpoints for submitting upload-documents , search  ,  and  suggest\n       requests are domain-specific. To get the endpoints for your domain, use\n       the Amazon CloudSearch configuration  service  DescribeDomains  action.\n       The  domain endpoints are also displayed on the domain dashboard in the\n       Amazon CloudSearch console. You submit suggest requests to  the  search\n       endpoint.\n\n       For more information, see the Amazon CloudSearch Developer Guide ."
		},
		{
			"available commands": [
				"help",
				"search",
				"suggest",
				"upload-documents"
			]
		}
	],
	"cloudtrail": [{
			"name": "cloudtrail"
		},
		{
			"description": "This  is  the  CloudTrail  API  Reference.  It provides descriptions of\n       actions, data types, common parameters, and common  errors  for  Cloud-\n       Trail.\n\n       CloudTrail  is  a  web  service that records AWS API calls for your AWS\n       account and delivers log files to an Amazon  S3  bucket.  The  recorded\n       information  includes  the  identity of the user, the start time of the\n       AWS API call, the source IP address, the request  parameters,  and  the\n       response elements returned by the service.\n\n       NOTE:\n          As an alternative to the API, you can use one of the AWS SDKs, which\n          consist of libraries and sample code for  various  programming  lan-\n          guages  and  platforms  (Java,  Ruby, .NET, iOS, Android, etc.). The\n          SDKs provide a convenient  way  to  create  programmatic  access  to\n          AWSCloudTrail.  For example, the SDKs take care of cryptographically\n          signing requests, managing errors, and retrying  requests  automati-\n          cally. For information about the AWS SDKs, including how to download\n          and install them, see the Tools for Amazon Web Services page .\n\n       See the AWS CloudTrail User Guide for information about the  data  that\n       is included with each AWS API call listed in the log files."
		},
		{
			"available commands": [
				"add-tags",
				"create-subscription",
				"create-trail",
				"delete-trail",
				"describe-trails",
				"get-event-selectors",
				"get-trail-status",
				"help",
				"list-public-keys",
				"list-tags",
				"lookup-events",
				"put-event-selectors",
				"remove-tags",
				"start-logging",
				"stop-logging",
				"update-subscription",
				"update-trail",
				"validate-logs"
			]
		}
	],
	"cloudwatch": [{
			"name": "cloudwatch"
		},
		{
			"description": "Amazon CloudWatch monitors your Amazon Web Services (AWS) resources and\n       the applications you run on AWS in real time. You can use CloudWatch to\n       collect  and track metrics, which are the variables you want to measure\n       for your resources and applications.\n\n       CloudWatch  alarms  send  notifications  or  automatically  change  the\n       resources  you are monitoring based on rules that you define. For exam-\n       ple, you can monitor the CPU usage and disk reads and  writes  of  your\n       Amazon  EC2  instances.  Then,  use  this data to determine whether you\n       should launch additional instances to handle increased  load.  You  can\n       also use this data to stop under-used instances to save money.\n\n       In  addition to monitoring the built-in metrics that come with AWS, you\n       can monitor your own custom metrics. With  CloudWatch,  you  gain  sys-\n       tem-wide visibility into resource utilization, application performance,\n       and operational health."
		},
		{
			"available commands": [
				"delete-alarms",
				"delete-dashboards",
				"describe-alarm-history",
				"describe-alarms",
				"describe-alarms-for-metric",
				"disable-alarm-actions",
				"enable-alarm-actions",
				"get-dashboard",
				"get-metric-data",
				"get-metric-statistics",
				"help",
				"list-dashboards",
				"list-metrics",
				"put-dashboard",
				"put-metric-alarm",
				"put-metric-data",
				"set-alarm-state",
				"wait"
			]
		}
	],
	"codebuild": [{
			"name": "codebuild"
		},
		{
			"description": "AWS  CodeBuild is a fully managed build service in the cloud. AWS Code-\n       Build compiles your source code, runs unit tests,  and  produces  arti-\n       facts  that  are  ready to deploy. AWS CodeBuild eliminates the need to\n       provision, manage, and  scale  your  own  build  servers.  It  provides\n       prepackaged  build  environments  for the most popular programming lan-\n       guages and build tools, such as Apache Maven, Gradle, and more. You can\n       also  fully  customize  build environments in AWS CodeBuild to use your\n       own build tools. AWS CodeBuild scales automatically to meet peak  build\n       requests,  and  you  pay  only for the build time you consume. For more\n       information about AWS CodeBuild, see the AWS CodeBuild User Guide .\n\n       AWS CodeBuild supports these operations:\n\n       -batch-delete-builds : Deletes one or more builds.\n\n       -batch-get-projects  :  Gets  information  about  one  or  more  build\n         projects. A build project defines how AWS CodeBuild will run a build.\n         This includes information such as where to get  the  source  code  to\n         build,  the  build environment to use, the build commands to run, and\n         where to store the build output. A  build  environment  represents  a\n         combination  of  operating  system, programming language runtime, and\n         tools that AWS CodeBuild will use to run a build. Also, you  can  add\n         tags to build projects to help manage your resources and costs.\n\n       -create-project : Creates a build project.\n\n       -create-webhook : For an existing AWS CodeBuild build project that has\n         its source code stored in a GitHub repository, enables AWS  CodeBuild\n         to  begin  automatically rebuilding the source code every time a code\n         change is pushed to the repository.\n\n       -update-webhook : Changes the settings of an existing webhook.\n\n       -delete-project : Deletes a build project.\n\n       -delete-webhook : For an existing AWS CodeBuild build project that has\n         its  source  code  stored in a GitHub repository, stops AWS CodeBuild\n         from automatically rebuilding the  source  code  every  time  a  code\n         change is pushed to the repository.\n\n       -list-projects  :  Gets a list of build project names, with each build\n         project name representing a single build project.\n\n       -update-project : Changes the settings of an existing build project.\n\n       -batch-get-builds : Gets information about one or more builds.\n\n       -list-builds : Gets a list of build IDs, with each build ID represent-\n         ing a single build.\n\n       -list-builds-for-project  : Gets a list of build IDs for the specified\n         build project, with each build ID representing a single build.\n\n       -start-build : Starts running a build.\n\n       -stop-build : Attempts to stop running a build.\n\n       -list-curated-environment-images  :  Gets  information  about   Docker\n         images that are managed by AWS CodeBuild."
		},
		{
			"available commands": [
				"batch-delete-builds",
				"batch-get-builds",
				"batch-get-projects",
				"create-project",
				"create-webhook",
				"delete-project",
				"delete-webhook",
				"help",
				"invalidate-project-cache",
				"list-builds",
				"list-builds-for-project",
				"list-curated-environment-images",
				"list-projects",
				"start-build",
				"stop-build",
				"update-project",
				"update-webhook"
			]
		}
	],
	"codecommit": [{
			"name": "codecommit"
		},
		{
			"description": "This  is  the  AWS  CodeCommit  API Reference . This reference provides\n       descriptions of the operations and data types for  AWS  CodeCommit  API\n       along with usage examples.\n\n       You can use the AWS CodeCommit API to work with the following objects:\n\n       Repositories, by calling the following:\n\n      batch-get-repositories  , which returns information about one or more\n         repositories associated with your AWS account.\n\n      create-repository , which creates an AWS CodeCommit repository.\n\n      delete-repository , which deletes an AWS CodeCommit repository.\n\n      get-repository , which returns information about a specified  reposi-\n         tory.\n\n      list-repositories , which lists all AWS CodeCommit repositories asso\n         ciated with your AWS account.\n\n    update-repository-description , which sets or updates the description\n         of the repository.\n\n      update-repository-name , which changes the name of the repository. If\n         you change the name of a repository, no other users of  that  reposi-\n         tory  will  be able to access it until you send them the new HTTPS or\n         SSH URL to use.\n\n       Branches, by calling the following:\n\n      create-branch , which creates a new branch in a specified repository.\n\n      delete-branch  ,  which  deletes the specified branch in a repository\n         unless it is the default branch.\n\n      get-branch , which returns information about a specified branch.\n\n      list-branches , which lists all branches for a specified  repository.\n\n      update-default-branch , which changes the default branch for a repos-\n         itory.\n\n       Files, by calling the following:\n\n      put-file , which adds or modifies a file in  a  specified  repository\n         and branch.\n\n       Information  about  committed code in a repository, by calling the fol-\n       lowing:\n\n      get-blob , which returns the base- '64' encoded content of an individual\n         Git blob object within a repository.\n\n      get-commit , which returns information about a commit, including com-\n         mit messages and author and committer information.\n\n      get-differences , which returns information about the differences  in\n         a  valid  commit specifier (such as a branch, tag, HEAD, commit ID or\n         other fully qualified reference).\n\n       Pull requests, by calling the following:\n\n      create-pull-request , which creates a pull  request  in  a  specified\n         repository.\n\n      describe-pull-request-events , which returns information about one or\n         more pull request events.\n\n      get-comments-for-pull-request , which returns information about  com-\n         ments on a specified pull request.\n\n      get-merge-conflicts , which returns information about merge conflicts\n         between the source and destination branch in a pull request.\n\n      get-pull-request , which returns information about a  specified  pull\n         request.\n\n      list-pull-requests  , which lists all pull requests for a repository.\n\n      merge-pull-request-by-fast-forward , which merges the source destina-\n         tion  branch  of a pull request into the specified destination branch\n         for that pull request using the fast-forward merge option.\n\n      post-comment-for-pull-request , which  posts  a  comment  to  a  pull\n         request at the specified line, file, or request.\n\n      update-pull-request-description  , which updates the description of a\n         pull request.\n\n      update-pull-request-status , which  updates  the  status  of  a  pull\n         requst.\n\n      update-pull-request-title  ,  which  updates  the  title  of  a  pull\n         request.\n\n       Information about comments in a repository, by calling the following:\n\n      delete-comment-content , which deletes the content of a comment on  a\n         commit in a repository.\n\n      get-comment  , which returns information about a comment on a commit.\n\n      get-comments-for-compared-commit , which  returns  information  about\n         comments on the comparison between two commit specifiers in a reposi-\n         tory.\n\n      post-comment-for-compared-commit , which creates  a  comment  on  the\n         comparison between two commit specifiers in a repository.\n\n      post-comment-reply , which creates a reply to a comment.\n\n      update-comment  ,  which updates the content of a comment on a commit\n         in a repository.\n\n       Triggers, by calling the following:\n\n      get-repository-triggers , which returns  information  about  triggers\n         configured for a repository.\n\n      put-repository-triggers  ,  which replaces all triggers for a reposi-\n         tory and can be used to create or delete triggers.\n\n      test-repository-triggers , which tests the functionality of a reposi-\n         tory trigger by sending data to the trigger target.\n\n       For information about how to use AWS CodeCommit, see the AWS CodeCommit\n       User Guide ."
		},
		{
			"available commands": [
				"batch-get-repositories",
				"create-branch",
				"create-pull-request",
				"create-repository",
				"credential-helper",
				"delete-branch",
				"delete-comment-content",
				"delete-repository",
				"describe-pull-request-events",
				"get-blob",
				"get-branch",
				"get-comment",
				"get-comments-for-compared-commit",
				"get-comments-for-pull-request",
				"get-commit",
				"get-differences",
				"get-merge-conflicts",
				"get-pull-request",
				"get-repository",
				"get-repository-triggers",
				"help",
				"list-branches",
				"list-pull-requests",
				"list-repositories",
				"merge-pull-request-by-fast-forward",
				"post-comment-for-compared-commit",
				"post-comment-for-pull-request",
				"post-comment-reply",
				"put-file",
				"put-repository-triggers",
				"test-repository-triggers",
				"update-comment",
				"update-default-branch",
				"update-pull-request-description",
				"update-pull-request-status",
				"update-pull-request-title",
				"update-repository-description",
				"update-repository-name"
			]
		}
	],
	"codepipeline": [{
			"name": "codepipeline"
		},

		{
			"description": "This  is  the  AWS  CodePipeline  API  Reference.  This  guide provides\n       descriptions of the actions and data types for AWS  CodePipeline.  Some\n       functionality  for  your pipeline is only configurable through the API.\n       For additional information, see the AWS CodePipeline User Guide .\n\n       You can use the AWS CodePipeline API to work  with  pipelines,  stages,\n       actions, and transitions, as described below.\n          Pipelines  are  models of automated release processes. Each pipeline\n          is uniquely named, and consists of stages, actions, and transitions."
		},

		{
			"overview": "This  is  the  AWS  CodePipeline  API  Reference.  This  guide provides\n       descriptions of the actions and data types for AWS  CodePipeline.  Some\n       functionality  for  your pipeline is only configurable through the API.\n       For additional information, see the AWS CodePipeline User Guide .\n\n       You can use the AWS CodePipeline API to work  with  pipelines,  stages,\n       actions, and transitions, as described below.\n          Pipelines  are  models of automated release processes. Each pipeline\n          is uniquely named, and consists of stages, actions, and transitions.\n\n       You can work with pipelines by calling:\n\n      -create-pipeline , which creates a uniquely-named pipeline.\n\n      -delete-pipeline , which deletes the specified pipeline.\n\n      get-pipeline , which returns information about the pipeline structure\n         and pipeline metadata, including the pipeline  Amazon  Resource  Name\n         (ARN).\n\n      get-pipeline-execution  ,  which returns information about a specific\n         execution of a pipeline.\n\n      -get-pipeline-state , which  returns  information  about  the  current\n         state of the stages and actions of a pipeline.\n\n      -list-pipelines , which gets a summary of all of the pipelines associ-\n         ated with your account.\n\n      -list-pipeline-executions , which gets a summary of  the  most  recent\n         executions for a pipeline.\n\n      -start-pipeline-execution , which runs the the most recent revision of\n         an artifact through the pipeline.\n\n      -update-pipeline , which updates a pipeline with edits or  changes  to\n         the structure of the pipeline.\n\n       Pipelines include stages . Each stage contains one or more actions that\n       must complete before the next stage begins. A stage will result in suc-\n       cess  or  failure.  If  a  stage fails, then the pipeline stops at that\n       stage and will remain stopped until either a new version of an artifact\n       appears  in  the  source location, or a user takes action to re-run the\n       most recent artifact through the  pipeline.  You  can  call   get-pipe-\n       line-state  ,  which  displays  the status of a pipeline, including the\n       status of stages in the pipeline, or  get-pipeline , which returns  the\n       entire  structure  of  the pipeline, including the stages of that pipe-\n       line. For more information about the structure of stages  and  actions,\n       also refer to the AWS CodePipeline Pipeline Structure Reference .\n\n       Pipeline stages include actions , which are categorized into categories\n       such as source or build actions performed within a stage of a pipeline.\n       For  example,  you  can  use a source action to import artifacts into a\n       pipeline from a source such as Amazon S3. Like stages, you do not  work\n       with  actions  directly  in  most cases, but you do define and interact\n       with actions when  working  with  pipeline  operations  such  as   cre-\n       ate-pipeline and  get-pipeline-state ."
		},
		{
			"valid action categories": [
				"Source",
				"Build",
				"Test",
				"Deploy",
				"Approval",
				"Invoke"
			]
		},
		{
			"calls": [
				"disable-stage-transition",
				"enable-stage-transition"
			]
		},
		{
			"jobs": [
				"acknowledge-job",
				"get-job-details",
				"poll-for-jobs ",
				"put-job-failure-result",
				"put-job-success-result",
				"acknowledge-third-party-job",
				"get-third-party-job-details",
				"poll-for-third-party-jobs",
				"put-third-party-job-failure-result",
				"put-third-party-job-success-result"
			]
		},
		{
			"available commands": [
				"acknowledge-job",
				"acknowledge-third-party-job",
				"create-custom-action-type",
				"create-pipeline",
				"delete-custom-action-type",
				"delete-pipeline",
				"delete-webhook",
				"deregister-webhook-with-third-party",
				"disable-stage-transition",
				"enable-stage-transition",
				"get-job-details",
				"get-pipeline",
				"get-pipeline-execution",
				"get-pipeline-state",
				"get-third-party-job-details",
				"help",
				"list-action-types",
				"list-pipeline-executions",
				"list-pipelines",
				"list-webhooks",
				"poll-for-jobs",
				"poll-for-third-party-jobs",
				"put-action-revision",
				"put-approval-result",
				"put-job-failure-result",
				"put-job-success-result",
				"put-third-party-job-failure-result",
				"put-third-party-job-success-result",
				"put-webhook",
				"register-webhook-with-third-party",
				"retry-stage-execution",
				"start-pipeline-execution",
				"update-pipeline"
			]
		}
	],
	"codestar": [{
			"name": "codestar"
		},

		{
			"description": "This  is  the  API  reference for AWS CodeStar. This reference provides\n       descriptions of the operations and data types for the AWS CodeStar API along with usage examples. You can use the AWS CodeStar API to work with: Projects and their resources. Teams and team members. Users"
		},

		{
			"projects": [
				"delete-project",
				"describe-project",
				"list-projects",
				"list-resources",
				"list-tags-for-project",
				"tag-project",
				"untag-project",
				"update-project"
			]
		},
		{
			"teams": [
				"associate-team-member",
				"disassociate-team-member",
				"list-team-members",
				"update-team-member"
			]
		},

		{
			"calls": [
				"create-user-profile",
				"delete-user-profile",
				"describe-user-profile",
				"list-user-profiles",
				"update-user-profile"
			]
		},
		{
			"available commands": [
				"associate-team-member",
				"create-project",
				"create-user-profile",
				"delete-project",
				"delete-user-profile",
				"describe-project",
				"describe-user-profile",
				"disassociate-team-member",
				"help",
				"list-projects",
				"list-resources",
				"list-tags-for-project",
				"list-team-members",
				"list-user-profiles",
				"tag-project",
				"untag-project",
				"update-project",
				"update-team-member",
				"update-user-profile"
			]
		}
	],
	"cognito-identity": [{
			"name": "cognito-identity"
		},
		{
			"description": "Amazon  Cognito is a web service that delivers scoped temporary creden-\n       tials to mobile devices and other untrusted environments.  Amazon  Cog-\n       nito  uniquely identifies a device and supplies the user with a consis-\n       tent identity over the lifetime of an application.\n\n       Using Amazon Cognito, you can enable authentication with  one  or  more\n       third-party  identity  providers  (Facebook, Google, or Login with Ama-\n       zon), and you can also choose to support  unauthenticated  access  from\n       your  app.  Cognito delivers a unique identifier for each user and acts\n       as an OpenID token provider trusted by AWS Security Token Service (STS)\n       to access temporary, limited-privilege AWS credentials.\n\n       To provide end-user credentials, first make an unsigned call to  get-id\n       . If the end user is authenticated with one of the  supported  identity\n       providers,  set the Logins map with the identity provider token. get-id\n       returns a unique identifier for the user.\n\n       Next, make an unsigned call  to   get-credentials-for-identity  .  This\n       call  expects  the  same  Logins map as the get-id call, as well as the\n       IdentityID originally returned by get-id . Assuming your identity  pool\n       has   been   configured  via  the   set-identity-pool-roles  operation,\n       get-credentials-for-identity will return AWS credentials for your  use.\n       If  your pool has not been configured with set-identity-pool-roles , or\n       if  you  want  to  follow  legacy  flow,  make  an  unsigned  call   to\n       get-open-id-token  ,  which  returns the OpenID token necessary to call\n       STS and retrieve AWS credentials. This call expects the same Logins map\n       as  the  get-id  call, as well as the IdentityID originally returned by\n       get-id . The token returned by get-open-id-token can be passed  to  the\n       STS operation AssumeRoleWithWebIdentity to retrieve AWS credentials.\n\n       If you want to use Amazon Cognito in an Android, iOS, or Unity applica-\n       tion, you will probably want to make API calls via the AWS Mobile  SDK.\n       To learn more, see the AWS Mobile SDK Developer Guide ."
		},
		{
			"available commands": [
				"create-identity-pool",
				"delete-identities",
				"delete-identity-pool",
				"describe-identity",
				"describe-identity-pool",
				"get-credentials-for-identity",
				"get-id",
				"get-identity-pool-roles",
				"get-open-id-token",
				"get-open-id-token-for-developer-identity",
				"help",
				"list-identities",
				"list-identity-pools",
				"lookup-developer-identity",
				"merge-developer-identities",
				"set-identity-pool-roles",
				"unlink-developer-identity",
				"unlink-identity",
				"update-identity-pool"
			]
		}
	],
	"cognito-idp": [{
			"name": "cognito-idp"
		},
		{
			"description": "Using  the Amazon Cognito User Pools API, you can create a user pool to\n       manage directories and users. You can authenticate  a  user  to  obtain\n       tokens related to user identity and access policies.\n\n       This API reference provides information about user pools in Amazon Cog-\n       nito User Pools.\n\n       For more information, see the Amazon Cognito Documentation."
		},
		{
			"available commands": [
				"add-custom-attributes",
				"admin-add-user-to-group",
				"admin-confirm-sign-up",
				"admin-create-user",
				"admin-delete-user",
				"admin-delete-user-attributes",
				"admin-disable-provider-for-user",
				"admin-disable-user",
				"admin-enable-user",
				"admin-forget-device",
				"admin-get-device",
				"admin-get-user",
				"admin-initiate-auth",
				"admin-link-provider-for-user",
				"admin-list-devices",
				"admin-list-groups-for-user",
				"admin-list-user-auth-events",
				"admin-remove-user-from-group",
				"admin-reset-user-password",
				"admin-respond-to-auth-challenge",
				"admin-set-user-mfa-preference",
				"admin-set-user-settings",
				"admin-update-auth-event-feedback",
				"admin-update-device-status",
				"admin-update-user-attributes",
				"admin-user-global-sign-out",
				"associate-software-token",
				"change-password",
				"confirm-device",
				"confirm-forgot-password",
				"confirm-sign-up",
				"create-group",
				"create-identity-provider",
				"create-resource-server",
				"create-user-import-job",
				"create-user-pool",
				"create-user-pool-client",
				"create-user-pool-domain",
				"delete-group",
				"delete-identity-provider",
				"delete-resource-server",
				"delete-user",
				"delete-user-attributes",
				"delete-user-pool",
				"delete-user-pool-client",
				"delete-user-pool-domain",
				"describe-identity-provider",
				"describe-resource-server",
				"describe-risk-configuration",
				"describe-user-import-job",
				"describe-user-pool",
				"describe-user-pool-client",
				"describe-user-pool-domain",
				"forget-device",
				"forgot-password",
				"get-csv-header",
				"get-device",
				"get-group",
				"get-identity-provider-by-identifier",
				"get-signing-certificate",
				"get-ui-customization",
				"get-user",
				"get-user-attribute-verification-code",
				"get-user-pool-mfa-config",
				"global-sign-out",
				"help",
				"initiate-auth",
				"list-devices",
				"list-groups",
				"list-identity-providers",
				"list-resource-servers",
				"list-user-import-jobs",
				"list-user-pool-clients",
				"list-user-pools",
				"list-users",
				"list-users-in-group",
				"resend-confirmation-code",
				"respond-to-auth-challenge",
				"set-risk-configuration",
				"set-ui-customization",
				"set-user-mfa-preference",
				"set-user-pool-mfa-config",
				"set-user-settings",
				"sign-up",
				"start-user-import-job",
				"stop-user-import-job",
				"update-auth-event-feedback",
				"update-device-status",
				"update-group",
				"update-identity-provider",
				"update-resource-server",
				"update-user-attributes",
				"update-user-pool",
				"update-user-pool-client",
				"verify-software-token",
				"verify-user-attribute"
			]
		}
	],
	"cognito-sync": [{
			"name": "cognito-sync"
		},
		{
			"description": "Amazon  Cognito  Sync  provides  an AWS service and client library that\n       enable  cross-device  syncing   of   application-related   user   data.\n       High-level client libraries are available for both iOS and Android. You\n       can use these libraries to persist data locally so that it's  available\n       even  if  the device is offline. Developer credentials don't need to be\n       stored on the mobile device to access the service. You can  use  Amazon\n       Cognito  to  obtain  a normalized user ID and credentials. User data is\n       persisted in a dataset that can store up to 1 MB  of  key-value  pairs,\n       and you can have up to 20 datasets per user identity.\n\n       With Amazon Cognito Sync, the data stored for each identity is accessi-\n       ble only to credentials assigned to that identity. In order to use  the\n       Cognito  Sync  service,  you  need  to make API calls using credentials\n       retrieved with Amazon Cognito Identity service .\n\n       If you want to use Cognito Sync in an Android or iOS  application,  you\n       will  probably  want to make API calls via the AWS Mobile SDK. To learn\n       more, see the Developer Guide for Android and the Developer  Guide  for\n       iOS ."
		},
		{
			"available commands": [
				"bulk-publish",
				"delete-dataset",
				"describe-dataset",
				"describe-identity-pool-usage",
				"describe-identity-usage",
				"get-bulk-publish-details",
				"get-cognito-events",
				"get-identity-pool-configuration",
				"help",
				"list-datasets",
				"list-identity-pool-usage",
				"list-records",
				"register-device",
				"set-cognito-events",
				"set-identity-pool-configuration",
				"subscribe-to-dataset",
				"unsubscribe-from-dataset",
				"update-records"
			]
		}
	],
	"comprehend": [{
			"name": "comprehend"
		},
		{
			"description": "Amazon  Comprehend  is an AWS service for gaining insight into the con-\n       tent of documents. Use these actions to determine the topics  contained\n       in  your  documents, the topics they discuss, the predominant sentiment\n       expressed in them, the predominant language used, and more."
		},
		{
			"available commands": [
				"batch-detect-dominant-language",
				"batch-detect-entities",
				"batch-detect-key-phrases",
				"batch-detect-sentiment",
				"describe-dominant-language-detection-job",
				"describe-entities-detection-job",
				"describe-key-phrases-detection-job",
				"describe-sentiment-detection-job",
				"describe-topics-detection-job",
				"detect-dominant-language",
				"detect-entities",
				"detect-key-phrases",
				"detect-sentiment",
				"help",
				"list-dominant-language-detection-jobs",
				"list-entities-detection-jobs",
				"list-key-phrases-detection-jobs",
				"list-sentiment-detection-jobs",
				"list-topics-detection-jobs",
				"start-dominant-language-detection-job",
				"start-entities-detection-job",
				"start-key-phrases-detection-job",
				"start-sentiment-detection-job",
				"start-topics-detection-job",
				"stop-dominant-language-detection-job",
				"stop-entities-detection-job",
				"stop-key-phrases-detection-job",
				"stop-sentiment-detection-job"
			]
		}
	],
	"configservice": [{
			"name": "configservice"
		},
		{
			"description": "AWS  Config  provides  a way to keep track of the configurations of all\n       the AWS resources associated with your AWS account.  You  can  use  AWS\n       Config  to  get  the  current and historical configurations of each AWS\n       resource and also to get information about the relationship between the\n       resources.  An AWS resource can be an Amazon Compute Cloud (Amazon EC2)\n       instance, an Elastic Block  Store  (EBS)  volume,  an  elastic  network\n       Interface  (ENI), or a security group. For a complete list of resources\n       currently supported by AWS Config, see Supported AWS Resources .\n\n       You can access and manage AWS Config through the  AWS  Management  Con-\n       sole,  the AWS Command Line Interface (AWS CLI), the AWS Config API, or\n       the AWS SDKs for AWS Config. This reference guide  contains  documenta-\n       tion  for  the AWS Config API and the AWS CLI commands that you can use\n       to manage AWS Config. The AWS Config API uses the Signature  Version  4\n       protocol for signing requests. For more information about how to sign a\n       request with this protocol, see Signature Version 4 Signing  Process  .\n       For detailed information about AWS Config features and their associated\n       actions or commands, as well as how to work with  AWS  Management  Con-\n       sole, see What Is AWS Config in the AWS Config Developer Guide ."
		},
		{
			"available commands": [
				"batch-get-resource-config",
				"delete-aggregation-authorization",
				"delete-config-rule",
				"delete-configuration-aggregator",
				"delete-configuration-recorder",
				"delete-delivery-channel",
				"delete-evaluation-results",
				"delete-pending-aggregation-request",
				"delete-retention-configuration",
				"deliver-config-snapshot",
				"describe-aggregate-compliance-by-config-rules",
				"describe-aggregation-authorizations",
				"describe-compliance-by-config-rule",
				"describe-compliance-by-resource",
				"describe-config-rule-evaluation-status",
				"describe-config-rules",
				"describe-configuration-aggregator-sources-status",
				"describe-configuration-aggregators",
				"describe-configuration-recorder-status",
				"describe-configuration-recorders",
				"describe-delivery-channel-status",
				"describe-delivery-channels",
				"describe-pending-aggregation-requests",
				"describe-retention-configurations",
				"get-aggregate-compliance-details-by-config-rule",
				"get-aggregate-config-rule-compliance-summary",
				"get-compliance-details-by-config-rule",
				"get-compliance-details-by-resource",
				"get-compliance-summary-by-config-rule",
				"get-compliance-summary-by-resource-type",
				"get-discovered-resource-counts",
				"get-resource-config-history",
				"get-status",
				"help",
				"list-discovered-resources",
				"put-aggregation-authorization",
				"put-config-rule",
				"put-configuration-aggregator",
				"put-configuration-recorder",
				"put-delivery-channel",
				"put-evaluations",
				"put-retention-configuration",
				"start-config-rules-evaluation",
				"start-configuration-recorder",
				"stop-configuration-recorder",
				"subscribe"
			]
		}
	],
	"configure": [{
			"name": "configure"
		},
		{
			"description": "Configure  AWS  CLI  options. If this command is run with no arguments,\n       you will be prompted for configuration values such as your  AWS  Access\n       Key  Id  and you AWS Secret Access Key.  You can configure a named pro-\n       file using the --profile argument.  If your config file does not  exist\n       (the default location is ~/.aws/config), the AWS CLI will create it for\n       you.  To keep an existing value, hit enter when prompted for the value.\n       When  you  are prompted for information, the current value will be dis-\n       played in [brackets.  If the config item has no value, it be displayed\n       as  [None.  Note that the configure command only work with values from\n       the config file.  It does not use any configuration values  from  envi-\n       ronment variables or the IAM role.\n       Note:  the  values  you  provide  for the AWS Access Key ID and the AWS\n       Secret Access Key will  be  written  to  the  shared  credentials  file\n       (~/.aws/credentials)."
		},
		{
			"configuration variables": [
				"aws_access_key_id",
				"aws_secret_access_key",
				"aws_session_token",
				"metadata_service_timeout",
				"metadata_service_num_attempts"
			]
		},
		{
			"synopsis": "aws configure [--profile profile-name"
		},
		{
			"options": "None"
		},

		{
			"available commands": [
				"add-model",
				"get",
				"list",
				"set"
			]
		},
		{
			"examples": "$ aws configure\n\n          AWS Access Key ID None: accesskey\n          AWS Secret Access Key None: secretkey\n          Default region name None: us-west-2\n          Default output format None .\n       To update just the region name:\n\n          $ aws configure\n          AWS Access Key ID [****:\n          AWS Secret Access Key [****:\n          Default region name [us-west-1: us-west-2\n          Default output format [None:"
		}
	],
	"connect": [{
			"name": "connect"
		},
		{
			"description": "The  Amazon  Connect  API  Reference provides descriptions, syntax, and\n       usage examples for each of the  Amazon  Connect  actions,  data  types,\n       parameters,  and errors. Amazon Connect is a cloud-based contact center\n       solution that makes it easy to set up and  manage  a  customer  contact\n       center and provide reliable customer engagement at any scale."
		},
		{
			"available commands": [
				"help",
				"start-outbound-voice-contact",
				"stop-contact"
			]
		}
	],
	"cur": [{
			"name": "cur"
		},
		{
			"description": "All public APIs for AWS Cost and Usage Report service"
		},
		{
			"available commands": [
				"delete-report-definition",
				"describe-report-definitions",
				"help",
				"put-report-definition"
			]
		}
	],
	"datapipeline": [{
			"name": "datapipeline"
		},
		{
			"description": "AWS  Data Pipeline configures and manages a data-driven workflow called\n       a pipeline. AWS Data Pipeline handles the  details  of  scheduling  and\n       ensuring  that  data  dependencies are met so that your application can\n       focus on processing the data.\n\n       AWS Data Pipeline provides a JAR implementation of a task runner called\n       AWS  Data  Pipeline Task Runner. AWS Data Pipeline Task Runner provides\n       logic for common data management scenarios, such as performing database\n       queries  and running data analysis using Amazon Elastic MapReduce (Ama-\n       zon EMR). You can use AWS Data Pipeline Task Runner as your  task  run-\n       ner,  or you can write your own task runner to provide custom data man-\n       agement.\n\n       AWS Data Pipeline implements two main sets of  functionality.  Use  the\n       first  set  to  create  a  pipeline and define data sources, schedules,\n       dependencies, and the transforms to be performed on the data.  Use  the\n       second  set  in  your  task runner application to receive the next task\n       ready for processing. The logic for performing the task, such as query-\n       ing  the  data,  running data analysis, or converting the data from one\n       format to another, is contained within the task runner. The task runner\n       performs the task assigned to it by the web service, reporting progress\n       to the web service as it does so. When the task is done, the task  run-\n       ner  reports  the  final success or failure of the task to the web ser-\n       vice."
		},
		{
			"available commands": [
				"activate-pipeline",
				"add-tags",
				"create-default-roles",
				"create-pipeline",
				"deactivate-pipeline",
				"delete-pipeline",
				"describe-objects",
				"describe-pipelines",
				"evaluate-expression",
				"get-pipeline-definition",
				"help",
				"list-pipelines",
				"list-runs",
				"poll-for-task",
				"put-pipeline-definition",
				"query-objects",
				"remove-tags",
				"report-task-progress",
				"report-task-runner-heartbeat",
				"set-status",
				"set-task-status",
				"validate-pipeline-definition"
			]
		}
	],
	"dax": [{
			"name": "dax"
		},
		{
			"description": "DAX  is  a  managed caching service engineered for Amazon DynamoDB. DAX\n       dramatically speeds up database reads  by  caching  frequently-accessed\n       data  from DynamoDB, so applications can access that data with sub-mil-\n       lisecond latency. You can create a DAX cluster easily,  using  the  AWS\n       Management  Console. With a few simple modifications to your code, your\n       application can begin taking advantage of the DAX cluster  and  realize\n       significant improvements in read performance."
		},
		{
			"available commands": [
				"create-cluster",
				"create-parameter-group",
				"create-subnet-group",
				"decrease-replication-factor",
				"delete-cluster",
				"delete-parameter-group",
				"delete-subnet-group",
				"describe-clusters",
				"describe-default-parameters",
				"describe-events",
				"describe-parameter-groups",
				"describe-parameters",
				"describe-subnet-groups",
				"help",
				"increase-replication-factor",
				"list-tags",
				"reboot-node",
				"tag-resource",
				"untag-resource",
				"update-cluster",
				"update-parameter-group",
				"update-subnet-group"
			]
		}
	],
	"deploy": [{
			"name": "deploy"
		},
		{
			"description": "AWS  CodeDeploy  is  a  deployment  service  that automates application\n       deployments to Amazon EC2 instances, on-premises instances  running  in\n       your own facility, or serverless AWS Lambda functions.\n\n       You  can deploy a nearly unlimited variety of application content, such\n       as an updated Lambda function, code, web and configuration files,  exe-\n       cutables,  packages,  scripts, multimedia files, and so on. AWS CodeDe-\n       ploy can deploy application content stored in Amazon S3 buckets, GitHub\n       repositories,  or  Bitbucket  repositories.  You  do  not  need to make\n       changes to your existing code before you can use AWS CodeDeploy.\n\n       AWS CodeDeploy makes it easier for you to rapidly release new features,\n       helps you avoid downtime during application deployment, and handles the\n       complexity of updating your applications, without  many  of  the  risks\n       associated with error-prone manual deployments.\n          AWS CodeDeploy Components\n\n       Use  the  information in this guide to help you work with the following\n       AWS CodeDeploy components:\n\n     < Application : A name that uniquely  identifies  the  application  you\n         want  to  deploy. AWS CodeDeploy uses this name, which functions as a\n         container, to ensure the correct combination of revision,  deployment\n         configuration,  and  deployment group are referenced during a deploy-\n         ment.\n\n     < Deployment group : A set of individual instances or CodeDeploy Lambda\n         applications.  A Lambda deployment group contains a group of applica-\n         tions. An  EC2/On-premises  deployment  group  contains  individually\n         tagged  instances,  Amazon  EC2  instances in Auto Scaling groups, or\n         both.\n\n     < Deployment configuration : A set of deployment rules  and  deployment\n         success  and  failure  conditions  used  by  AWS  CodeDeploy during a\n         deployment.\n\n     < Deployment : The process and the components used in  the  process  of\n         updating  a  Lambda  function or of installing content on one or more\n         instances.\n\n     < Application revisions : For an AWS Lambda deployment, this is an App-\n         Spec  file  that  specifies  the Lambda function to update and one or\n         more functions  to  validate  deployment  lifecycle  events.  For  an\n         EC2/On-premises deployment, this is an archive file containing source\n         contentsource code,  web  pages,  executable  files,  and  deployment\n         scriptsalong  with an AppSpec file. Revisions are stored in Amazon S3\n         buckets or GitHub repositories. For Amazon S3, a revision is uniquely\n         identified  by  its  Amazon  S3  object key and its ETag, version, or\n         both. For GitHub, a revision is uniquely identified by its commit ID.\n\n       This  guide also contains information to help you get details about the\n       instances in your deployments, to make on-premises instances  available\n       for AWS CodeDeploy deployments, and to get details about a Lambda func-\n       tion deployment.\n          AWS CodeDeploy Information Resources\n\n       'AWS CodeDeploy User Guide',\n\n      'AWS CodeDeploy API Reference Guide',\n\n      'AWS CLI Reference for AWS CodeDeploy',\n\n      'AWS CodeDeploy Developer Forum' "
		},
		{
			"available commands": [
				"add-tags-to-on-premises-instances",
				"batch-get-application-revisions",
				"batch-get-applications",
				"batch-get-deployment-groups",
				"batch-get-deployment-instances",
				"batch-get-deployments",
				"batch-get-on-premises-instances",
				"continue-deployment",
				"create-application",
				"create-deployment",
				"create-deployment-config",
				"create-deployment-group",
				"delete-application",
				"delete-deployment-config",
				"delete-deployment-group",
				"delete-git-hub-account-token",
				"deregister",
				"deregister-on-premises-instance",
				"get-application",
				"get-application-revision",
				"get-deployment",
				"get-deployment-config",
				"get-deployment-group",
				"get-deployment-instance",
				"get-on-premises-instance",
				"help",
				"install",
				"list-application-revisions",
				"list-applications",
				"list-deployment-configs",
				"list-deployment-groups",
				"list-deployment-instances",
				"list-deployments",
				"list-git-hub-account-token-names",
				"list-on-premises-instances",
				"push",
				"put-lifecycle-event-hook-execution-status",
				"register",
				"register-application-revision",
				"register-on-premises-instance",
				"remove-tags-from-on-premises-instances",
				"skip-wait-time-for-instance-termination",
				"stop-deployment",
				"uninstall",
				"update-application",
				"update-deployment-group",
				"wait"
			]
		}
	],
	"devicefarm": [{
			"name": "devicefarm"
		},
		{
			"description": "AWS Device Farm is a service that enables mobile app developers to test\n       Android, iOS, and Fire OS apps on physical phones, tablets,  and  other\n       devices in the cloud."
		},
		{
			"available commands": [
				"create-device-pool",
				"create-instance-profile",
				"create-network-profile",
				"create-project",
				"create-remote-access-session",
				"create-upload",
				"create-vpce-configuration",
				"delete-device-pool",
				"delete-instance-profile",
				"delete-network-profile",
				"delete-project",
				"delete-remote-access-session",
				"delete-run",
				"delete-upload",
				"delete-vpce-configuration",
				"get-account-settings",
				"get-device",
				"get-device-instance",
				"get-device-pool",
				"get-device-pool-compatibility",
				"get-instance-profile",
				"get-job",
				"get-network-profile",
				"get-offering-status",
				"get-project",
				"get-remote-access-session",
				"get-run",
				"get-suite",
				"get-test",
				"get-upload",
				"get-vpce-configuration",
				"help",
				"install-to-remote-access-session",
				"list-artifacts",
				"list-device-instances",
				"list-device-pools",
				"list-devices",
				"list-instance-profiles",
				"list-jobs",
				"list-network-profiles",
				"list-offering-promotions",
				"list-offering-transactions",
				"list-offerings",
				"list-projects",
				"list-remote-access-sessions",
				"list-runs",
				"list-samples",
				"list-suites",
				"list-tests",
				"list-unique-problems",
				"list-uploads",
				"list-vpce-configurations",
				"purchase-offering",
				"renew-offering",
				"schedule-run",
				"stop-remote-access-session",
				"stop-run",
				"update-device-instance",
				"update-device-pool",
				"update-instance-profile",
				"update-network-profile",
				"update-project",
				"update-vpce-configuration"
			]
		}
	],
	"directconnect": [{
			"name": "directconnect"
		},
		{
			"description": "AWS Direct Connect links your internal network to an AWS Direct Connect\n       location over a standard 1 gigabit or 10 gigabit  Ethernet  fiber-optic\n       cable.  One  end of the cable is connected to your router, the other to\n       an AWS Direct Connect router. With this connection in  place,  you  can\n       create  virtual  interfaces  directly to the AWS cloud (for example, to\n       Amazon Elastic Compute Cloud (Amazon EC2)  and  Amazon  Simple  Storage\n       Service  (Amazon S3)) and to Amazon Virtual Private Cloud (Amazon VPC),\n       bypassing Internet service providers  in  your  network  path.  An  AWS\n       Direct  Connect  location  provides  access  to AWS in the region it is\n       associated with, as well as access to other US  regions.  For  example,\n       you  can  provision a single connection to any AWS Direct Connect loca-\n       tion in the US and use it to access  public  AWS  services  in  all  US\n       Regions and AWS GovCloud (US)."
		},
		{
			"available commands": [
				"allocate-hosted-connection",
				"allocate-private-virtual-interface",
				"allocate-public-virtual-interface",
				"associate-connection-with-lag",
				"associate-hosted-connection",
				"associate-virtual-interface",
				"confirm-connection",
				"confirm-private-virtual-interface",
				"confirm-public-virtual-interface",
				"create-bgp-peer",
				"create-connection",
				"create-direct-connect-gateway",
				"create-direct-connect-gateway-association",
				"create-interconnect",
				"create-lag",
				"create-private-virtual-interface",
				"create-public-virtual-interface",
				"delete-bgp-peer",
				"delete-connection",
				"delete-direct-connect-gateway",
				"delete-direct-connect-gateway-association",
				"delete-interconnect",
				"delete-lag",
				"delete-virtual-interface",
				"describe-connections",
				"describe-direct-connect-gateway-associations",
				"describe-direct-connect-gateway-attachments",
				"describe-direct-connect-gateways",
				"describe-hosted-connections",
				"describe-interconnects",
				"describe-lags",
				"describe-loa",
				"describe-locations",
				"describe-tags",
				"describe-virtual-gateways",
				"describe-virtual-interfaces",
				"disassociate-connection-from-lag",
				"help",
				"tag-resource",
				"untag-resource",
				"update-lag"
			]
		}
	],
	"discovery": [{
			"name": "discovery"
		},
		{
			"description": "AWS  Application Discovery Service helps you plan application migration\n       projects by automatically identifying servers, virtual machines  (VMs),\n       software,  and  software  dependencies running in your on-premises data\n       centers. Application Discovery Service also collects  application  per-\n       formance data, which can help you assess the outcome of your migration.\n       The  data  collected  by  Application  Discovery  Service  is  securely\n       retained  in  an  AWS-hosted and managed database in the cloud. You can\n       export the data as a CSV or XML file into your preferred  visualization\n       tool  or  cloud-migration  solution  to  plan  your migration. For more\n       information, see AWS Application Discovery Service FAQ .\n\n       Application Discovery Service offers two modes of operation:\n\n      Agentless discovery mode is recommended  for  environments  that  use\n         VMware  vCenter  Server.  This mode doesn't require you to install an\n         agent on each host. Agentless discovery  gathers  server  information\n         regardless  of  the  operating  systems,  which  minimizes  the  time\n         required for initial on-premises infrastructure assessment. Agentless\n         discovery  doesn't  collect  information  about software and software\n         dependencies. It also doesn't work in non-VMware environments.\n\n      Agent-based discovery mode collects a richer set of data than  agent\n         less  discovery  by  using the AWS Application Discovery Agent, which\n         you install on one or more hosts in your data center. The agent  cap-\n         tures infrastructure and application information, including an inven-\n         tory of installed software applications, system and  process  perfor-\n         mance,  resource  utilization, and network dependencies between work-\n         loads. The information collected by agents is secured at rest and  in\n         transit to the Application Discovery Service database in the cloud.\n\n       We recommend that you use agent-based discovery for non-VMware environ-\n       ments and to collect information about software and software  dependen-\n       cies.  You  can also run agent-based and agentless discovery simultane-\n       ously. Use agentless discovery to quickly complete the  initial  infra-\n       structure assessment and then install agents on select hosts.\n\n       Application  Discovery  Service  integrates  with application discovery\n       solutions from AWS Partner Network (APN) partners. Third-party applica-\n       tion  discovery tools can query Application Discovery Service and write\n       to the Application Discovery Service database using a public  API.  You\n       can   then  import  the  data  into  either  a  visualization  tool  or\n       cloud-migration solution.\n\n       WARNING:\n          Application Discovery Service doesn't gather sensitive  information.\n          All  data  is  handled according to the AWS Privacy Policy . You can\n          operate Application Discovery Service offline to  inspect  collected\n          data before it is shared with the service.\n\n       Your  AWS  account must be granted access to Application Discovery Ser-\n       vice, a process called whitelisting . This is true for AWS partners and\n       customers  alike.  To request access, sign up for Application Discovery\n       Service .\n\n       This API reference provides descriptions, syntax,  and  usage  examples\n       for  each  of the actions and data types for Application Discovery Ser-\n       vice. The topic for each action shows the API  request  parameters  and\n       the  response. Alternatively, you can use one of the AWS SDKs to access\n       an API that is tailored to the programming language  or  platform  that\n       you're using. For more information, see AWS SDKs .\n\n       This  guide  is  intended  for use with the ` AWS Application Discovery\n       Service                           User                            Guide\n       http://docs.aws.amazon.com/application-discovery/latest/userguide/\n       `\n       __ ."
		},
		{
			"available commands": [
				"associate-configuration-items-to-application",
				"create-application",
				"create-tags",
				"delete-applications",
				"delete-tags",
				"describe-agents",
				"describe-configurations",
				"describe-export-tasks",
				"describe-tags",
				"disassociate-configuration-items-from-application",
				"get-discovery-summary",
				"help",
				"list-configurations",
				"list-server-neighbors",
				"start-data-collection-by-agent-ids",
				"start-export-task",
				"stop-data-collection-by-agent-ids",
				"update-application"
			]
		}
	],
	"dms": [{
			"name": "dms"
		},
		{
			"description": "AWS  Database  Migration Service (AWS DMS) can migrate your data to and\n       from the most widely used commercial and open-source databases such  as\n       Oracle,  PostgreSQL,  Microsoft  SQL  Server, Amazon Redshift, MariaDB,\n       Amazon Aurora, MySQL, and SAP Adaptive  Server  Enterprise  (ASE).  The\n       service  supports  homogeneous  migrations such as Oracle to Oracle, as\n       well as heterogeneous migrations between different database  platforms,\n       such as Oracle to MySQL or SQL Server to PostgreSQL.\n\n       For  more information about AWS DMS, see the AWS DMS user guide at What\n       Is AWS Database Migration Service?"
		},
		{
			"available commands": [
				"add-tags-to-resource",
				"create-endpoint",
				"create-event-subscription",
				"create-replication-instance",
				"create-replication-subnet-group",
				"create-replication-task",
				"delete-certificate",
				"delete-endpoint",
				"delete-event-subscription",
				"delete-replication-instance",
				"delete-replication-subnet-group",
				"delete-replication-task",
				"describe-account-attributes",
				"describe-certificates",
				"describe-connections",
				"describe-endpoint-types",
				"describe-endpoints",
				"describe-event-categories",
				"describe-event-subscriptions",
				"describe-events",
				"describe-orderable-replication-instances",
				"describe-refresh-schemas-status",
				"describe-replication-instance-task-logs",
				"describe-replication-instances",
				"describe-replication-subnet-groups",
				"describe-replication-task-assessment-results",
				"describe-replication-tasks",
				"describe-schemas",
				"describe-table-statistics",
				"help",
				"import-certificate",
				"list-tags-for-resource",
				"modify-endpoint",
				"modify-event-subscription",
				"modify-replication-instance",
				"modify-replication-subnet-group",
				"modify-replication-task",
				"reboot-replication-instance",
				"refresh-schemas",
				"reload-tables",
				"remove-tags-from-resource",
				"start-replication-task",
				"start-replication-task-assessment",
				"stop-replication-task",
				"test-connection"
			]
		}
	],
	"ds": [{
			"name": "ds"
		},
		{
			"description": "AWS  Directory  Service  is a web service that makes it easy for you to\n       setup and run directories  in  the  AWS  cloud,  or  connect  your  AWS\n       resources with an existing on-premises Microsoft Active Directory. This\n       guide provides detailed information about AWS Directory Service  opera-\n       tions,  data  types,  parameters, and errors. For information about AWS\n       Directory Services features, see AWS  Directory  Service  and  the  AWS\n       Directory Service Administration Guide .\n\n       NOTE:\n          AWS provides SDKs that consist of libraries and sample code for var-\n          ious programming languages and platforms  (Java,  Ruby,  .Net,  iOS,\n          Android, etc.). The SDKs provide a convenient way to create program-\n          matic access to AWS Directory Service and other  AWS  services.  For\n          more  information  about the AWS SDKs, including how to download and\n          install them, see Tools for Amazon Web Services ."
		},
		{
			"available commands": [
				"add-ip-routes",
				"add-tags-to-resource",
				"cancel-schema-extension",
				"connect-directory",
				"create-alias",
				"create-computer",
				"create-conditional-forwarder",
				"create-directory",
				"create-microsoft-ad",
				"create-snapshot",
				"create-trust",
				"delete-conditional-forwarder",
				"delete-directory",
				"delete-snapshot",
				"delete-trust",
				"deregister-event-topic",
				"describe-conditional-forwarders",
				"describe-directories",
				"describe-domain-controllers",
				"describe-event-topics",
				"describe-snapshots",
				"describe-trusts",
				"disable-radius",
				"disable-sso",
				"enable-radius",
				"enable-sso",
				"get-directory-limits",
				"get-snapshot-limits",
				"help",
				"list-ip-routes",
				"list-schema-extensions",
				"list-tags-for-resource",
				"register-event-topic",
				"remove-ip-routes",
				"remove-tags-from-resource",
				"reset-user-password",
				"restore-from-snapshot",
				"start-schema-extension",
				"update-conditional-forwarder",
				"update-number-of-domain-controllers",
				"update-radius",
				"verify-trust"
			]
		}
	],
	"dynamodb": [{
			"name": "dynamodb"
		},
		{
			"description": "Amazon DynamoDB is a fully managed NoSQL database service that provides\n       fast and predictable performance with  seamless  scalability.  DynamoDB\n       lets  you offload the administrative burdens of operating and scaling a\n       distributed database, so that you don't have to  worry  about  hardware\n       provisioning,  setup and configuration, replication, software patching,\n       or cluster scaling.\n\n       With DynamoDB, you can  create  database  tables  that  can  store  and\n       retrieve  any  amount  of data, and serve any level of request traffic.\n       You can scale up or scale down your tables' throughput capacity without\n       downtime or performance degradation, and use the AWS Management Console\n       to monitor resource utilization and performance metrics.\n\n       DynamoDB automatically spreads the data and  traffic  for  your  tables\n       over a sufficient number of servers to handle your throughput and stor-\n       age requirements, while maintaining consistent  and  fast  performance.\n       All  of  your  data is stored on solid state disks (SSDs) and automati-\n       cally replicated across multiple Availability Zones in an  AWS  region,\n       providing b"
		},
		{
			"available commands": [
				"batch-get-item",
				"batch-write-item",
				"create-backup",
				"create-global-table",
				"create-table",
				"delete-backup",
				"delete-item",
				"delete-table",
				"describe-backup",
				"describe-continuous-backups",
				"describe-global-table",
				"describe-global-table-settings",
				"describe-limits",
				"describe-table",
				"describe-time-to-live",
				"get-item",
				"help",
				"list-backups",
				"list-global-tables",
				"list-tables",
				"list-tags-of-resource",
				"put-item",
				"query",
				"restore-table-from-backup",
				"restore-table-to-point-in-time",
				"scan",
				"tag-resource",
				"untag-resource",
				"update-continuous-backups",
				"update-global-table",
				"update-global-table-settings",
				"update-item",
				"update-table",
				"update-time-to-live",
				"wait"
			]
		}
	],
	"dynamodbstreams": [{
			"name": "dynamodbstreams"
		},
		{
			"description": "Amazon  DynamoDB Streams provides API actions for accessing streams and\n       processing stream records. To learn more about application  development\n       with Streams, see Capturing Table Activity with DynamoDB Streams in the\n       Amazon DynamoDB Developer Guide."
		},
		{
			"available commands": [
				"describe-stream",
				"get-records",
				"get-shard-iterator",
				"help",
				"list-streams"
			]
		}
	],
	"ec2": [{
			"name": "ec2"
		},
		{
			"description": "Amazon  Elastic Compute Cloud (Amazon EC2) provides resizable computing\n       capacity in the AWS Cloud. Using Amazon  EC2  eliminates  the  need  to\n       invest in hardware up front, so you can develop and deploy applications\n       faster."
		},
		{
			"available commands": [
				"accept-reserved-instances-exchange-quote",
				"accept-vpc-endpoint-connections",
				"accept-vpc-peering-connection",
				"allocate-address",
				"allocate-hosts",
				"assign-ipv",
				"assign-private-ip-addresses",
				"associate-address",
				"associate-dhcp-options",
				"associate-iam-instance-profile",
				"associate-route-table",
				"associate-subnet-cidr-block",
				"associate-vpc-cidr-block",
				"attach-classic-link-vpc",
				"attach-internet-gateway",
				"attach-network-interface",
				"attach-volume",
				"attach-vpn-gateway",
				"authorize-security-group-egress",
				"authorize-security-group-ingress",
				"bundle-instance",
				"cancel-bundle-task",
				"cancel-conversion-task",
				"cancel-export-task",
				"cancel-import-task",
				"cancel-reserved-instances-listing",
				"cancel-spot-fleet-requests",
				"cancel-spot-instance-requests",
				"confirm-product-instance",
				"copy-fpga-image",
				"copy-image",
				"copy-snapshot",
				"create-customer-gateway",
				"create-default-subnet",
				"create-default-vpc",
				"create-dhcp-options",
				"create-egress-only-internet-gateway",
				"create-fleet",
				"create-flow-logs",
				"create-fpga-image",
				"create-image",
				"create-instance-export-task",
				"create-internet-gateway",
				"create-key-pair",
				"create-launch-template",
				"create-launch-template-version",
				"create-nat-gateway",
				"create-network-acl",
				"create-network-acl-entry",
				"create-network-interface",
				"create-network-interface-permission",
				"create-placement-group",
				"create-reserved-instances-listing",
				"create-route",
				"create-route-table",
				"create-security-group",
				"create-snapshot",
				"create-spot-datafeed-subscription",
				"create-subnet",
				"create-tags",
				"create-volume",
				"create-vpc",
				"create-vpc-endpoint",
				"create-vpc-endpoint-connection-notification",
				"create-vpc-endpoint-service-configuration",
				"create-vpc-peering-connection",
				"create-vpn-connection",
				"create-vpn-connection-route",
				"create-vpn-gateway",
				"delete-customer-gateway",
				"delete-dhcp-options",
				"delete-egress-only-internet-gateway",
				"delete-fleets",
				"delete-flow-logs",
				"delete-fpga-image",
				"delete-internet-gateway",
				"delete-key-pair",
				"delete-launch-template",
				"delete-launch-template-versions",
				"delete-nat-gateway",
				"delete-network-acl",
				"delete-network-acl-entry",
				"delete-network-interface",
				"delete-network-interface-permission",
				"delete-placement-group",
				"delete-route",
				"delete-route-table",
				"delete-security-group",
				"delete-snapshot",
				"delete-spot-datafeed-subscription",
				"delete-subnet",
				"delete-tags",
				"delete-volume",
				"delete-vpc",
				"delete-vpc-endpoint-connection-notifications",
				"delete-vpc-endpoint-service-configurations",
				"delete-vpc-endpoints",
				"delete-vpc-peering-connection",
				"delete-vpn-connection",
				"delete-vpn-connection-route",
				"delete-vpn-gateway",
				"deregister-image",
				"describe-account-attributes",
				"describe-addresses",
				"describe-aggregate-id-format",
				"describe-availability-zones",
				"describe-bundle-tasks",
				"describe-classic-link-instances",
				"describe-conversion-tasks",
				"describe-customer-gateways",
				"describe-dhcp-options",
				"describe-egress-only-internet-gateways",
				"describe-elastic-gpus",
				"describe-export-tasks",
				"describe-fleet-history",
				"describe-fleet-instances",
				"describe-fleets",
				"describe-flow-logs",
				"describe-fpga-image-attribute",
				"describe-fpga-images",
				"describe-host-reservation-offerings",
				"describe-host-reservations",
				"describe-hosts",
				"describe-iam-instance-profile-associations",
				"describe-id-format",
				"describe-identity-id-format",
				"describe-image-attribute",
				"describe-images",
				"describe-import-image-tasks",
				"describe-import-snapshot-tasks",
				"describe-instance-attribute",
				"describe-instance-credit-specifications",
				"describe-instance-status",
				"describe-instances",
				"describe-internet-gateways",
				"describe-key-pairs",
				"describe-launch-template-versions",
				"describe-launch-templates",
				"describe-moving-addresses",
				"describe-nat-gateways",
				"describe-network-acls",
				"describe-network-interface-attribute",
				"describe-network-interface-permissions",
				"describe-network-interfaces",
				"describe-placement-groups",
				"describe-prefix-lists",
				"describe-principal-id-format",
				"describe-regions",
				"describe-reserved-instances",
				"describe-reserved-instances-listings",
				"describe-reserved-instances-modifications",
				"describe-reserved-instances-offerings",
				"describe-route-tables",
				"describe-scheduled-instance-availability",
				"describe-scheduled-instances",
				"describe-security-group-references",
				"describe-security-groups",
				"describe-snapshot-attribute",
				"describe-snapshots",
				"describe-spot-datafeed-subscription",
				"describe-spot-fleet-instances",
				"describe-spot-fleet-request-history",
				"describe-spot-fleet-requests",
				"describe-spot-instance-requests",
				"describe-spot-price-history",
				"describe-stale-security-groups",
				"describe-subnets",
				"describe-tags",
				"describe-volume-attribute",
				"describe-volume-status",
				"describe-volumes",
				"describe-volumes-modifications",
				"describe-vpc-attribute",
				"describe-vpc-classic-link",
				"describe-vpc-classic-link-dns-support",
				"describe-vpc-endpoint-connection-notifications",
				"describe-vpc-endpoint-connections",
				"describe-vpc-endpoint-service-configurations",
				"describe-vpc-endpoint-service-permissions",
				"describe-vpc-endpoint-services",
				"describe-vpc-endpoints",
				"describe-vpc-peering-connections",
				"describe-vpcs",
				"describe-vpn-connections",
				"describe-vpn-gateways",
				"detach-classic-link-vpc",
				"detach-internet-gateway",
				"detach-network-interface",
				"detach-volume",
				"detach-vpn-gateway",
				"disable-vgw-route-propagation",
				"disable-vpc-classic-link",
				"disable-vpc-classic-link-dns-support",
				"disassociate-address",
				"disassociate-iam-instance-profile",
				"disassociate-route-table",
				"disassociate-subnet-cidr-block",
				"disassociate-vpc-cidr-block",
				"enable-vgw-route-propagation",
				"enable-volume-io",
				"enable-vpc-classic-link",
				"enable-vpc-classic-link-dns-support",
				"get-console-output",
				"get-console-screenshot",
				"get-host-reservation-purchase-preview",
				"get-launch-template-data",
				"get-password-data",
				"get-reserved-instances-exchange-quote",
				"help",
				"import-image",
				"import-key-pair",
				"import-snapshot",
				"modify-fleet",
				"modify-fpga-image-attribute",
				"modify-hosts",
				"modify-id-format",
				"modify-identity-id-format",
				"modify-image-attribute",
				"modify-instance-attribute",
				"modify-instance-credit-specification",
				"modify-instance-placement",
				"modify-launch-template",
				"modify-network-interface-attribute",
				"modify-reserved-instances",
				"modify-snapshot-attribute",
				"modify-spot-fleet-request",
				"modify-subnet-attribute",
				"modify-volume",
				"modify-volume-attribute",
				"modify-vpc-attribute",
				"modify-vpc-endpoint",
				"modify-vpc-endpoint-connection-notification",
				"modify-vpc-endpoint-service-configuration",
				"modify-vpc-endpoint-service-permissions",
				"modify-vpc-peering-connection-options",
				"modify-vpc-tenancy",
				"monitor-instances",
				"move-address-to-vpc",
				"purchase-host-reservation",
				"purchase-reserved-instances-offering",
				"purchase-scheduled-instances",
				"reboot-instances",
				"register-image",
				"reject-vpc-endpoint-connections",
				"reject-vpc-peering-connection",
				"release-address",
				"release-hosts",
				"replace-iam-instance-profile-association",
				"replace-network-acl-association",
				"replace-network-acl-entry",
				"replace-route",
				"replace-route-table-association",
				"report-instance-status",
				"request-spot-fleet",
				"request-spot-instances",
				"reset-fpga-image-attribute",
				"reset-image-attribute",
				"reset-instance-attribute",
				"reset-network-interface-attribute",
				"reset-snapshot-attribute",
				"restore-address-to-classic",
				"revoke-security-group-egress",
				"revoke-security-group-ingress",
				"run-instances",
				"run-scheduled-instances",
				"start-instances",
				"stop-instances",
				"terminate-instances",
				"unassign-ipv",
				"unassign-private-ip-addresses",
				"unmonitor-instances",
				"update-security-group-rule-descriptions-egress",
				"update-security-group-rule-descriptions-ingress",
				"wait"
			]
		}
	],
	"ecr": [{
			"name": "ecr"
		},
		{
			"description": "Amazon Elastic Container Registry (Amazon ECR) is a managed Docker reg-\n       istry service. Customers can use the familiar Docker CLI to push, pull,\n       and manage images. Amazon ECR provides a secure, scalable, and reliable\n       registry.  Amazon  ECR  supports  private  Docker   repositories   with\n       resource-based  permissions  using IAM so that specific users or Amazon\n       EC2 instances can access repositories and images.  Developers  can  use\n       the Docker CLI to author and manage images."
		},
		{
			"available commands": [
				"batch-check-layer-availability",
				"batch-delete-image",
				"batch-get-image",
				"complete-layer-upload",
				"create-repository",
				"delete-lifecycle-policy",
				"delete-repository",
				"delete-repository-policy",
				"describe-images",
				"describe-repositories",
				"get-authorization-token",
				"get-download-url-for-layer",
				"get-lifecycle-policy",
				"get-lifecycle-policy-preview",
				"get-login",
				"get-repository-policy",
				"help",
				"initiate-layer-upload",
				"list-images",
				"put-image",
				"put-lifecycle-policy",
				"set-repository-policy",
				"start-lifecycle-policy-preview",
				"upload-layer-part"
			]
		}
	],
	"ecs": [{
			"name": "ecs"
		},
		{
			"description": "Amazon  Elastic  Container  Service  (Amazon ECS) is a highly scalable,\n       fast, container management service that makes it easy to run, stop, and\n       manage  Docker  containers on a cluster. You can host your cluster on a\n       serverless infrastructure that is managed by Amazon  ECS  by  launching\n       your services or tasks using the Fargate launch type. For more control,\n       you can host your tasks on a cluster of Amazon  Elastic  Compute  Cloud\n       (Amazon  EC2)  instances  that you manage by using the EC2 launch type.\n       For more information about launch types, see Amazon ECS Launch Types  .\n\n       Amazon  ECS  lets you launch and stop container-based applications with\n       simple API calls, allows you to get the state of your  cluster  from  a\n       centralized  service,  and gives you access to many familiar Amazon EC2\n       features.\n\n       You can use Amazon ECS to schedule the placement of  containers  across\n       your  cluster  based  on  your  resource needs, isolation policies, and\n       availability requirements. Amazon ECS eliminates the need  for  you  to\n       operate  your  own cluster management and configuration management sys-\n       tems or worry about scaling your management infrastructure."
		},
		{
			"available commands": [
				"create-cluster",
				"create-service",
				"delete-attributes",
				"delete-cluster",
				"delete-service",
				"deregister-container-instance",
				"deregister-task-definition",
				"describe-clusters",
				"describe-container-instances",
				"describe-services",
				"describe-task-definition",
				"describe-tasks",
				"discover-poll-endpoint",
				"help",
				"list-attributes",
				"list-clusters",
				"list-container-instances",
				"list-services",
				"list-task-definition-families",
				"list-task-definitions",
				"list-tasks",
				"put-attributes",
				"register-container-instance",
				"register-task-definition",
				"run-task",
				"start-task",
				"stop-task",
				"submit-container-state-change",
				"submit-task-state-change",
				"update-container-agent",
				"update-container-instances-state",
				"update-service",
				"wait"
			]
		}
	],
	"efs": [{
			"name": "efs"
		},
		{
			"description": "Amazon  Elastic File System (Amazon EFS) provides simple, scalable file\n       storage for use with Amazon EC2 instances in the AWS Cloud. With Amazon\n       EFS,  storage  capacity is elastic, growing and shrinking automatically\n       as you add and remove files, so your applications have the storage they\n       need, when they need it. For more information, see the User Guide ."
		},
		{
			"available commands": [
				"create-file-system",
				"create-mount-target",
				"create-tags",
				"delete-file-system",
				"delete-mount-target",
				"delete-tags",
				"describe-file-systems",
				"describe-mount-target-security-groups",
				"describe-mount-targets",
				"describe-tags",
				"help",
				"modify-mount-target-security-groups"
			]
		}
	],
	"eks": [{
			"name": "eks"
		},
		{
			"description": "Amazon  Elastic Container Service for Kubernetes (Amazon EKS) is a man-\n       aged service that makes it easy for you to run Kubernetes on AWS  with-\n       out  needing to stand up or maintain your own Kubernetes control plane.\n       Kubernetes is an open-source  system  for  automating  the  deployment,\n       scaling, and management of containerized applications.\n\n       Amazon  EKS  runs three Kubernetes control plane instances across three\n       Availability Zones to ensure high availability.  Amazon  EKS  automati-\n       cally  detects  and  replaces unhealthy control plane instances, and it\n       provides automated version upgrades and patching for them.\n\n       Amazon EKS is also integrated with many AWS services to provide  scala-\n       bility and security for your applications, including the following:\n\n      'Elastic Load Balancing for load distribution',\n\n      'IAM for authentication',\n\n      'Amazon VPC for isolation',\n\n       Amazon EKS runs up to date versions of the open-source Kubernetes soft-\n       ware, so you can use all the existing  plugins  and  tooling  from  the\n       Kubernetes community. Applications running on Amazon EKS are fully com-\n       patible with applications running on any standard  Kubernetes  environ-\n       ment,  whether  running  in  on-premises data centers or public clouds.\n       This means that you can easily migrate any standard Kubernetes applica-\n       tion to Amazon EKS without any code modification required."
		},
		{
			"available commands": [
				"create-cluster",
				"delete-cluster",
				"describe-cluster",
				"help",
				"list-clusters"
			]
		}
	],
	"elasticache": [{
			"name": "elasticache"
		},
		{
			"description": "Amazon  ElastiCache  is  a  web service that makes it easier to set up,\n       operate, and scale a distributed cache in the cloud.\n\n       With ElastiCache, customers get all of the benefits of  a  high-perfor-\n       mance,  in-memory cache with less of the administrative burden involved\n       in launching and managing a distributed cache. The service makes setup,\n       scaling,  and cluster failure handling much simpler than in a self-man-\n       aged cache deployment.\n\n       In addition, through integration with Amazon CloudWatch, customers  get\n       enhanced visibility into the key performance statistics associated with\n       their cache and can receive alarms if a part of their cache runs hot."
		},
		{
			"available commands": [
				"add-tags-to-resource",
				"authorize-cache-security-group-ingress",
				"copy-snapshot",
				"create-cache-cluster",
				"create-cache-parameter-group",
				"create-cache-security-group",
				"create-cache-subnet-group",
				"create-replication-group",
				"create-snapshot",
				"delete-cache-cluster",
				"delete-cache-parameter-group",
				"delete-cache-security-group",
				"delete-cache-subnet-group",
				"delete-replication-group",
				"delete-snapshot",
				"describe-cache-clusters",
				"describe-cache-engine-versions",
				"describe-cache-parameter-groups",
				"describe-cache-parameters",
				"describe-cache-security-groups",
				"describe-cache-subnet-groups",
				"describe-engine-default-parameters",
				"describe-events",
				"describe-replication-groups",
				"describe-reserved-cache-nodes",
				"describe-reserved-cache-nodes-offerings",
				"describe-snapshots",
				"help",
				"list-allowed-node-type-modifications",
				"list-tags-for-resource",
				"modify-cache-cluster",
				"modify-cache-parameter-group",
				"modify-cache-subnet-group",
				"modify-replication-group",
				"modify-replication-group-shard-configuration",
				"purchase-reserved-cache-nodes-offering",
				"reboot-cache-cluster",
				"remove-tags-from-resource",
				"reset-cache-parameter-group",
				"revoke-cache-security-group-ingress",
				"test-failover",
				"wait"
			]
		}
	],
	"elasticbeanstalk": [{
			"name": "elasticbeanstalk"
		},
		{
			"description": "AWS Elastic Beanstalk makes it easy for you to create, deploy, and man-\n       age scalable, fault-tolerant applications running  on  the  Amazon  Web\n       Services cloud.\n\n       For  more  information  about  this  product,  go  to  the  AWS Elastic\n       Beanstalk  details  page.  The  location  of  the  latest  AWS  Elastic\n       Beanstalk                            WSDL                            is\n       http://elasticbeanstalk.s3.amazonaws.com/doc/2010-12-01/AWSElasticBeanstalk.wsdl\n       .  To install the Software Development Kits (SDKs), Integrated Develop-\n       ment Environment (IDE) Toolkits, and command line tools that enable you\n       to access the API, go to Tools for Amazon Web Services .\n          Endpoints\n\n       For a list of region-specific endpoints that AWS Elastic Beanstalk sup-\n       ports, go to Regions and Endpoints in the Amazon Web Services  Glossary\n       ."
		},
		{
			"available commands": [
				"abort-environment-update",
				"apply-environment-managed-action",
				"check-dns-availability",
				"compose-environments",
				"create-application",
				"create-application-version",
				"create-configuration-template",
				"create-environment",
				"create-platform-version",
				"create-storage-location",
				"delete-application",
				"delete-application-version",
				"delete-configuration-template",
				"delete-environment-configuration",
				"delete-platform-version",
				"describe-account-attributes",
				"describe-application-versions",
				"describe-applications",
				"describe-configuration-options",
				"describe-configuration-settings",
				"describe-environment-health",
				"describe-environment-managed-action-history",
				"describe-environment-managed-actions",
				"describe-environment-resources",
				"describe-environments",
				"describe-events",
				"describe-instances-health",
				"describe-platform-version",
				"help",
				"list-available-solution-stacks",
				"list-platform-versions",
				"list-tags-for-resource",
				"rebuild-environment",
				"request-environment-info",
				"restart-app-server",
				"retrieve-environment-info",
				"swap-environment-cnames",
				"terminate-environment",
				"update-application",
				"update-application-resource-lifecycle",
				"update-application-version",
				"update-configuration-template",
				"update-environment",
				"update-tags-for-resource",
				"validate-configuration-settings"
			]
		}
	],
	"elastictranscoder": [{
			"name": "elastictranscoder"
		},
		{
			"description": "The AWS Elastic Transcoder Service."
		},
		{
			"available commands": [
				"cancel-job",
				"create-job",
				"create-pipeline",
				"create-preset",
				"delete-pipeline",
				"delete-preset",
				"help",
				"list-jobs-by-pipeline",
				"list-jobs-by-status",
				"list-pipelines",
				"list-presets",
				"read-job",
				"read-pipeline",
				"read-preset",
				"update-pipeline",
				"update-pipeline-notifications",
				"update-pipeline-status",
				"wait"
			]
		}
	],
	"elb": [{
			"name": "elb"
		},
		{
			"description": "A  load  balancer  can  distribute  incoming  traffic  across  your EC2\n       instances. This enables you to increase the availability of your appli-\n       cation.  The  load  balancer also monitors the health of its registered\n       instances and ensures that it routes traffic only to healthy instances.\n       You configure your load balancer to accept incoming traffic by specify-\n       ing one or more listeners, which are configured  with  a  protocol  and\n       port  number  for  connections  from clients to the load balancer and a\n       protocol and port number for connections from the load balancer to  the\n       instances.\n\n       Elastic Load Balancing supports three types of load balancers: Applica-\n       tion Load Balancers, Network Load  Balancers,  and  Classic  Load  Bal-\n       ancers. You can select a load balancer based on your application needs.\n       For more information, see the Elastic Load Balancing User Guide .\n\n       This reference covers the 2012-06-01 API, which supports  Classic  Load\n       Balancers.  The  2015-12-01 API supports Application Load Balancers and\n       Network Load Balancers.\n\n       To get started, create a load balancer with one or more listeners using\n       create-load-balancer  .  Register your instances with the load balancer\n       using  register-instances-with-load-balancer .\n\n       All Elastic Load Balancing operations are idempotent , which means that\n       they complete at most one time. If you repeat an operation, it succeeds\n       with a 200 OK response code."
		},
		{
			"available commands": [
				"add-tags",
				"apply-security-groups-to-load-balancer",
				"attach-load-balancer-to-subnets",
				"configure-health-check",
				"create-app-cookie-stickiness-policy",
				"create-lb-cookie-stickiness-policy",
				"create-load-balancer",
				"create-load-balancer-listeners",
				"create-load-balancer-policy",
				"delete-load-balancer",
				"delete-load-balancer-listeners",
				"delete-load-balancer-policy",
				"deregister-instances-from-load-balancer",
				"describe-account-limits",
				"describe-instance-health",
				"describe-load-balancer-attributes",
				"describe-load-balancer-policies",
				"describe-load-balancer-policy-types",
				"describe-load-balancers",
				"describe-tags",
				"detach-load-balancer-from-subnets",
				"disable-availability-zones-for-load-balancer",
				"enable-availability-zones-for-load-balancer",
				"help",
				"modify-load-balancer-attributes",
				"register-instances-with-load-balancer",
				"remove-tags",
				"set-load-balancer-listener-ssl-certificate",
				"set-load-balancer-policies-for-backend-server",
				"set-load-balancer-policies-of-listener",
				"wait"
			]
		}
	],
	"elbv2": [{
			"name": "elbv2"
		},
		{
			"description": "A  load  balancer  distributes incoming traffic across targets, such as\n       your EC2 instances. This enables you to increase  the  availability  of\n       your  application.  The  load  balancer also monitors the health of its\n       registered targets and ensures that it routes traffic only  to  healthy\n       targets. You configure your load balancer to accept incoming traffic by\n       specifying one or more listeners, which are configured with a  protocol\n       and  port number for connections from clients to the load balancer. You\n       configure a target group with a protocol and port  number  for  connec-\n       tions from the load balancer to the targets, and with health check set-\n       tings to be used when checking the health status of the targets.\n\n       Elastic Load Balancing supports the following types of load  balancers:\n       Application  Load  Balancers,  Network Load Balancers, and Classic Load\n       Balancers.\n\n       An Application Load Balancer makes routing and load balancing decisions\n       at  the  application  layer (HTTP/HTTPS). A Network Load Balancer makes\n       routing and load balancing decisions at the transport layer (TCP). Both\n       Application  Load  Balancers  and  Network  Load  Balancers  can  route\n       requests to one or  more  ports  on  each  EC2  instance  or  container\n       instance in your virtual private cloud (VPC).\n\n       A  Classic  Load  Balancer  makes  routing and load balancing decisions\n       either at the  transport  layer  (TCP/SSL)  or  the  application  layer\n       (HTTP/HTTPS), and supports either EC2-Classic or a VPC. For more infor-\n       mation, see the Elastic Load Balancing User Guide .\n\n       This reference covers the 2015-12-01 API,  which  supports  Application\n       Load  Balancers and Network Load Balancers. The 2012-06-01 API supports\n       Classic Load Balancers.\n\n       To get started, complete the following tasks:\n\n      -Create a load balancer using  create-load-balancer .\n\n      -Create a target group using  create-target-group .\n\n      -Register targets for the target group using  register-targets .\n\n      -Create one or more listeners  for  your  load  balancer  using   cre-\n         ate-listener .\n\n       To  delete a load balancer and its related resources, complete the fol-\n       lowing tasks:\n\n      -Delete the load balancer using  delete-load-balancer .\n\n      Delete the target group using  delete-target-group .\n\n       All Elastic Load Balancing operations are idempotent, which means  that\n       they  complete  at  most  one time. If you repeat an operation, it suc-\n       ceeds."
		},
		{
			"available commands": [
				"add-listener-certificates",
				"add-tags",
				"create-listener",
				"create-load-balancer",
				"create-rule",
				"create-target-group",
				"delete-listener",
				"delete-load-balancer",
				"delete-rule",
				"delete-target-group",
				"deregister-targets",
				"describe-account-limits",
				"describe-listener-certificates",
				"describe-listeners",
				"describe-load-balancer-attributes",
				"describe-load-balancers",
				"describe-rules",
				"describe-ssl-policies",
				"describe-tags",
				"describe-target-group-attributes",
				"describe-target-groups",
				"describe-target-health",
				"help",
				"modify-listener",
				"modify-load-balancer-attributes",
				"modify-rule",
				"modify-target-group",
				"modify-target-group-attributes",
				"register-targets",
				"remove-listener-certificates",
				"remove-tags",
				"set-ip-address-type",
				"set-rule-priorities",
				"set-security-groups",
				"set-subnets",
				"wait"
			]
		}
	],
	"emr": [{
			"name": "emr"
		},
		{
			"description": "Amazon EMR is a web service that makes it easy to process large amounts\n       of data efficiently. Amazon EMR uses Hadoop  processing  combined  with\n       several AWS products to do tasks such as web indexing, data mining, log\n       file analysis, machine learning, scientific simulation, and data  ware-\n       housing."
		},
		{
			"available commands": [
				"add-instance-fleet",
				"add-instance-groups",
				"add-steps",
				"add-tags",
				"cancel-steps",
				"create-cluster",
				"create-default-roles",
				"create-hbase-backup",
				"create-security-configuration",
				"delete-security-configuration",
				"describe-cluster",
				"describe-security-configuration",
				"describe-step",
				"disable-hbase-backups",
				"get",
				"help",
				"install-applications",
				"list-clusters",
				"list-instance-fleets",
				"list-instances",
				"list-security-configurations",
				"list-steps",
				"modify-cluster-attributes",
				"modify-instance-fleet",
				"modify-instance-groups",
				"put",
				"put-auto-scaling-policy",
				"remove-auto-scaling-policy",
				"remove-tags",
				"restore-from-hbase-backup",
				"schedule-hbase-backup",
				"socks",
				"ssh",
				"terminate-clusters",
				"wait"
			]
		}
	],
	"es": [{
			"name": "es"
		},
		{
			"description": "Use  the  Amazon  Elasticsearch configuration API to create, configure,\n       and manage Elasticsearch domains.\n\n       The endpoint for configuration  service  requests  is  region-specific:\n       es.*region*  .amazonaws.com.  For  example, es.us-east-1.amazonaws.com.\n       For a current list of supported regions and endpoints, see Regions  and\n       Endpoints ."
		},
		{
			"available commands": [
				"add-tags",
				"create-elasticsearch-domain",
				"delete-elasticsearch-domain",
				"delete-elasticsearch-service-role",
				"describe-elasticsearch-domain",
				"describe-elasticsearch-domain-config",
				"describe-elasticsearch-domains",
				"describe-elasticsearch-instance-type-limits",
				"describe-reserved-elasticsearch-instance-offerings",
				"describe-reserved-elasticsearch-instances",
				"help",
				"list-domain-names",
				"list-elasticsearch-instance-types",
				"list-elasticsearch-versions",
				"list-tags",
				"purchase-reserved-elasticsearch-instance-offering",
				"remove-tags",
				"update-elasticsearch-domain-config"
			]
		}
	],
	"events": [{
			"name": "events"
		},
		{
			"description": "Amazon  CloudWatch Events helps you to respond to state changes in your\n       AWS resources. When your resources  change  state,  they  automatically\n       send  events  into  an  event  stream.  You can create rules that match\n       selected events in the stream and route them to targets to take action.\n       You can also use rules to take action on a pre-determined schedule. For\n       example, you can configure rules to:\n\n      Automatically invoke an AWS Lambda function  to  update  DNS  entries.\n         when  an  event notifies you that Amazon EC2 instance enters the run-\n         ning state.\n\n      Direct specific API records from  CloudTrail  to  an  Amazon  Kinesis.\n         stream  for  detailed  analysis of potential security or availability\n         risks.\n\n      Periodically invoke a built-in target to create a snapshot of an Ama-\n         zon EBS volume.\n\n       For  more  information  about the features of Amazon CloudWatch Events,\n       see the Amazon CloudWatch Events User Guide ."
		},
		{
			"available commands": [
				"delete-rule",
				"describe-event-bus",
				"describe-rule",
				"disable-rule",
				"enable-rule",
				"help",
				"list-rule-names-by-target",
				"list-rules",
				"list-targets-by-rule",
				"put-events",
				"put-permission",
				"put-rule",
				"put-targets",
				"remove-permission",
				"remove-targets",
				"test-event-pattern"
			]
		}
	],
	"firehose": [{
			"name": "firehose"
		},
		{
			"description": "Amazon  Kinesis  Data Firehose is a fully managed service that delivers\n       real-time streaming data to destinations such as Amazon Simple  Storage\n       Service  (Amazon  S3), Amazon Elasticsearch Service (Amazon ES), Amazon\n       Redshift, and Splunk."
		},
		{
			"available commands": [
				"create-delivery-stream",
				"delete-delivery-stream",
				"describe-delivery-stream",
				"help",
				"list-delivery-streams",
				"list-tags-for-delivery-stream",
				"put-record",
				"put-record-batch",
				"tag-delivery-stream",
				"untag-delivery-stream",
				"update-destination"
			]
		}
	],
	"fms": [{
			"name": "fms"
		},
		{
			"description": "This  is  the  AWS  Firewall  Manager API Reference . This guide is for\n       developers who need detailed information about the AWS Firewall Manager\n       API actions, data types, and errors. For detailed information about AWS\n       Firewall Manager features, see the AWS Firewall Manager Developer Guide\n       ."
		},
		{
			"available commands": [
				"associate-admin-account",
				"delete-notification-channel",
				"delete-policy",
				"disassociate-admin-account",
				"get-admin-account",
				"get-compliance-detail",
				"get-notification-channel",
				"get-policy",
				"help",
				"list-compliance-status",
				"list-policies",
				"put-notification-channel",
				"put-policy"
			]
		}
	],

	"gamelift": [{
			"name": "gamelift"
		},
		{
			"description": "Amazon  GameLift  is  a managed service for developers who need a scal-\n       able, dedicated server solution for their multiplayer games. Use Amazon\n       GameLift  for  these  tasks:  (1) set up computing resources and deploy\n       your game servers, (2) run game sessions and get  players  into  games,\n       (3) automatically scale your resources to meet player demand and manage\n       costs, and (4) track in-depth metrics on game  server  performance  and\n       player usage.\n\n       The Amazon GameLift service API includes two important function sets:\n\n      Manage  game  sessions  and  player access -- Retrieve information on\n         available game  sessions;  create  new  game  sessions;  send  player\n         requests to join a game session.\n\n      Configure  and manage game server resources -- Manage builds, fleets,\n         queues, and aliases; set auto-scaling  policies;  retrieve  logs  and\n         metrics.\n\n       This  reference  guide  describes  the low-level service API for Amazon\n       GameLift. You can use the API functionality with these tools:\n\n      The Amazon Web Services software development kit (AWS SDK ) is avail-\n         able  in  multiple  languages  including  C++  and C#. Use the SDK to\n         access the API programmatically from an application, such as  a  game\n         client.\n\n      The  AWS  command-line  interface  (CLI) tool is primarily useful for\n         handling administrative actions, such as setting up and managing Ama-\n         zon  GameLift settings and resources. You can use the AWS CLI to man-\n         age all of your AWS services.\n\n      The AWS Management Console for Amazon GameLift provides a web  inter-\n         face  to manage your Amazon GameLift settings and resources. The con-\n         sole includes a  dashboard  for  tracking  key  resources,  including\n         builds  and  fleets,  and  displays usage and performance metrics for\n         your games as customizable graphs.\n\n      Amazon GameLift Local is a tool for testing your  game's  integration\n         with  Amazon  GameLift before deploying it on the service. This tools\n         supports a subset of key API actions, which can be called from either\n         the AWS CLI or programmatically. See Testing an Integration .\n          Learn more\n\n      Developer Guide -- Read about Amazon GameLift features and how to use\n         them.\n\n      Tutorials -- Get started fast with walkthroughs and sample  projects.\n\n      GameDev Blog -- Stay up to date with new features and techniques.\n\n      GameDev Forums -- Connect with the GameDev community.\n\n      Release  notes  and  document history -- Stay current with updates to\n         the Amazon GameLift service, SDKs, and documentation.\n          API SUMMARY\n\n       This list offers a functional overview of the Amazon  GameLift  service\n       API.\n          Managing Games and Players\n\n       Use  these  actions to start new game sessions, find existing game ses-\n       sions, track game session status  and  other  information,  and  enable\n       player access to game sessions.\n\n      Discover existing game sessions\n\n        search-game-sessions  --  Retrieve  all  available game sessions or\n           search for game sessions that match a set of criteria.\n\n      Start new game sessions\n\n        Start new games with Queues to  find  the  best  available  hosting\n           resources  across  multiple  regions,  minimize player latency, and\n           balance game session activity for efficiency  and  cost  effective-\n           ness.\n\n          -start-game-session-placement -- Request a new game session place-\n             ment and add one or more players to it.\n\n          -describe-game-session-placement -- Get  details  on  a  placement\n             request, including status.\n\n          -stop-game-session-placement -- Cancel a placement request.\n\n        -create-game-session  --  Start  a  new  game  session on a specific\n           fleet. Available in Amazon GameLift Local.\n\n      Match players to game sessions with FlexMatch matchmaking\n\n        -start-matchmaking -- Request matchmaking for one players or a group\n           who want to play together.\n\n        -start-match-backfill  -  Request  additional player matches to fill\n           empty slots in an existing game session.\n\n        -describe-matchmaking --  Get  details  on  a  matchmaking  request,\n           including status.\n\n        -accept-match  --  Register  that a player accepts a proposed match,\n           for matches that require player acceptance.\n\n        -stop-matchmaking -- Cancel a matchmaking request.\n\n      Manage game session data\n\n        -describe-game-sessions -- Retrieve metadata for one  or  more  game\n           sessions, including length of time active and current player count.\n           Available in Amazon GameLift Local.\n\n        -describe-game-session-details -- Retrieve  metadata  and  the  game\n           session protection setting for one or more game sessions.\n\n        -update-game-session  -- Change game session settings, such as maxi-\n           mum player count and join policy.\n\n        -get-game-session-log-url -- Get the location of saved  logs  for  a\n           game session.\n\n      Manage player sessions\n\n        -create-player-session -- Send a request for a player to join a game\n           session. Available in Amazon GameLift Local.\n\n        -create-player-sessions -- Send a request for  multiple  players  to\n           join a game session. Available in Amazon GameLift Local.\n\n        -describe-player-sessions -- Get details on player activity, includ-\n           ing status, playing time, and  player  data.  Available  in  Amazon\n           GameLift Local.\n          Setting Up and Managing Game Servers\n\n       When  setting  up  Amazon  GameLift  resources for your game, you first\n       create a game build and upload it to Amazon GameLift. You can then  use\n       these  actions to configure and manage a fleet of resources to run your\n       game servers, scale capacity to meet player demand, access  performance\n       and utilization metrics, and more.\n\n      Manage game builds\n\n        -create-build  -- Create a new build using files stored in an Amazon\n           S3 bucket. To create a build and upload files from  a  local  path,\n           use the AWS CLI command upload-build .\n\n        -list-builds  --  Get  a  list  of  all  builds uploaded to a Amazon\n           GameLift region.\n\n        -describe-build -- Retrieve information associated with a build.\n\n        -update-build -- Change build metadata,  including  build  name  and\n           version.\n\n        -delete-build -- Remove a build from Amazon GameLift.\n\n      Manage fleets\n\n        create-fleet -- Configure and activate a new fleet to run a build's\n           game servers.\n\n        -list-fleets -- Get a list of all fleet IDs  in  a  Amazon  GameLift\n           region (all statuses).\n\n        -delete-fleet  --  Terminate  a fleet that is no longer running game\n           servers or hosting players.\n\n        View / update fleet configurations.\n\n          describe-fleet-attributes /  update-fleet-attributes --  View  or\n             change  a  fleet's metadata and settings for game session protec-\n             tion and resource creation limits.\n\n          describe-fleet-port-settings  /   update-fleet-port-settings   --\n             View  or change the inbound permissions (IP address and port set-\n             ting ranges) allowed for a fleet.\n\n          describe-runtime-configuration /  update-runtime-configuration --\n             View  or  change  what  server processes (and how many) to run on\n             each instance in a fleet.\n\n      Control fleet capacity\n\n        describe-ec2-instance-limits  --   Retrieve   maximum   number   of\n           instances allowed for the current AWS account and the current usage\n           level.\n\n        describe-fleet-capacity /  update-fleet-capacity  --  Retrieve  the\n           capacity  settings  and the current number of instances in a fleet;\n           adjust fleet capacity settings to scale up or down.\n\n        Autoscale -- Manage auto-scaling rules and apply them to a fleet.\n\n          -put-scaling-policy -- Create a new auto-scaling policy, or update\n             an existing one.\n\n          -describe-scaling-policies  --  Retrieve  an existing auto-scaling\n             policy.\n\n          -delete-scaling-policy -- Delete an auto-scaling policy  and  stop\n             it from affecting a fleet's capacity.\n\n          -start-fleet-actions -- Restart a fleet's auto-scaling policies.\n\n          -stop-fleet-actions -- Suspend a fleet's auto-scaling policies.\n\n      Manage VPC peering connections for fleets\n\n        -create-vpc-peering-authorization  -- Authorize a peering connection\n           to one of your VPCs.\n\n        -describe-vpc-peering-authorizations -- Retrieve valid peering  con-\n           nection authorizations.\n\n        -delete-vpc-peering-authorization  --  Delete  a  peering connection\n           authorization.\n\n        -create-vpc-peering-connection --  Establish  a  peering  connection\n           between the VPC for a Amazon GameLift fleet and one of your VPCs.\n\n        -describe-vpc-peering-connections  -- Retrieve information on active\n           or pending VPC peering connections with a Amazon GameLift fleet.\n\n        -delete-vpc-peering-connection -- Delete a  VPC  peering  connection\n           with a Amazon GameLift fleet.\n\n      Access fleet activity statistics\n\n        -describe-fleet-utilization  --  Get  current  data on the number of\n           server processes, game sessions, and players currently active on  a\n           fleet.\n\n        -describe-fleet-events  --  Get a fleet's logged events for a speci-\n           fied time span.\n\n        -describe-game-sessions -- Retrieve metadata associated with one  or\n           more  game  sessions,  including  length of time active and current\n           player count.\n\n      Remotely access an instance\n\n        -describe-instances -- Get information on each instance in a  fleet,\n           including instance ID, IP address, and status.\n\n        -get-instance-access   --   Request  access  credentials  needed  to\n           remotely connect to a specified instance in a fleet.\n\n      Manage fleet aliases\n\n        -create-alias -- Define a new alias and optionally assign  it  to  a\n           fleet.\n\n        -list-aliases  -- Get all fleet aliases defined in a Amazon GameLift\n           region.\n\n        -describe-alias -- Retrieve information on an existing alias.\n\n        -update-alias -- Change settings for a alias, such as redirecting it\n           from one fleet to another.\n\n        delete-alias -- Remove an alias from the region.\n\n        resolve-alias -- Get the fleet ID that a specified alias points to.\n\n      Manage game session queues\n\n        -create-game-session-queue -- Create a queue for processing requests\n           for new game sessions.\n\n        -describe-game-session-queues   --   Retrieve  game  session  queues\n           defined in a Amazon GameLift region.\n\n        -update-game-session-queue -- Change the  configuration  of  a  game\n           session queue.\n\n        -delete-game-session-queue  --  Remove a game session queue from the\n           region.\n\n      Manage FlexMatch resources\n\n        create-matchmaking-configuration -- Create a matchmaking configura-\n           tion with instructions for building a player group and placing in a\n           new game session.\n\n        describe-matchmaking-configurations -- Retrieve matchmaking config-\n           urations defined a Amazon GameLift region.\n\n        update-matchmaking-configuration -- Change settings for matchmaking\n           configuration. queue.\n\n        delete-matchmaking-configuration -- Remove a matchmaking configura-\n           tion from the region.\n\n        create-matchmaking-rule-set  --  Create  a set of rules to use when\n           searching for player matches.\n\n        describe-matchmaking-rule-sets -- Retrieve  matchmaking  rule  sets\n           defined in a Amazon GameLift region.\n\n        validate-matchmaking-rule-set  -- Verify syntax for a set of match-\n           making rules."
		},
		{
			"available commands": [
				"accept-match",
				"create-alias",
				"create-build",
				"create-fleet",
				"create-game-session",
				"create-game-session-queue",
				"create-matchmaking-configuration",
				"create-matchmaking-rule-set",
				"create-player-session",
				"create-player-sessions",
				"create-vpc-peering-authorization",
				"create-vpc-peering-connection",
				"delete-alias",
				"delete-build",
				"delete-fleet",
				"delete-game-session-queue",
				"delete-matchmaking-configuration",
				"delete-scaling-policy",
				"delete-vpc-peering-authorization",
				"delete-vpc-peering-connection",
				"describe-alias",
				"describe-build",
				"describe-ec2-instance-limits",
				"describe-fleet-attributes",
				"describe-fleet-capacity",
				"describe-fleet-events",
				"describe-fleet-port-settings",
				"describe-fleet-utilization",
				"describe-game-session-details",
				"describe-game-session-placement",
				"describe-game-session-queues",
				"describe-game-sessions",
				"describe-instances",
				"describe-matchmaking",
				"describe-matchmaking-configurations",
				"describe-matchmaking-rule-sets",
				"describe-player-sessions",
				"describe-runtime-configuration",
				"describe-scaling-policies",
				"describe-vpc-peering-authorizations",
				"describe-vpc-peering-connections",
				"get-game-session-log",
				"get-game-session-log-url",
				"get-instance-access",
				"help",
				"list-aliases",
				"list-builds",
				"list-fleets",
				"put-scaling-policy",
				"request-upload-credentials",
				"resolve-alias",
				"search-game-sessions",
				"start-fleet-actions",
				"start-game-session-placement",
				"start-match-backfill",
				"start-matchmaking",
				"stop-fleet-actions",
				"stop-game-session-placement",
				"stop-matchmaking",
				"update-alias",
				"update-build",
				"update-fleet-attributes",
				"update-fleet-capacity",
				"update-fleet-port-settings",
				"update-game-session",
				"update-game-session-queue",
				"update-matchmaking-configuration",
				"update-runtime-configuration",
				"upload-build"
			]
		}
	],
	"glacier": [{
			"name": "glacier"
		},
		{
			"description": "Amazon Glacier is a storage solution for 'cold data'\n       Amazon  Glacier  is an extremely low-cost storage service that provides\n       secure, durable, and easy-to-use storage for data backup and  archival.\n       With  Amazon  Glacier,  customers can store their data cost effectively\n       for months, years, or decades. Amazon Glacier also enables customers to\n       offload  the administrative burdens of operating and scaling storage to\n       AWS, so they don't have to worry about capacity planning, hardware pro-\n       visioning,   data   replication,  hardware  failure  and  recovery,  or\n       time-consuming hardware migrations.\n\n       Amazon Glacier is a great storage choice when low storage cost is para-\n       mount,  your data is rarely retrieved, and retrieval latency of several\n       hours is acceptable. If your  application  requires  fast  or  frequent\n       access  to  your  data, consider using Amazon S3. For more information,\n       see Amazon Simple Storage Service (Amazon S3) .\n\n       You can store any kind of data in any format. There is no maximum limit\n       on the total amount of data you can store in Amazon Glacier.\n\n       If  you  are a first-time user of Amazon Glacier, we recommend that you\n       begin by reading the following sections in the Amazon Glacier Developer\n       Guide :\n\n      What  is  Amazon  Glacier  -  This  section  of  the  Developer Guide\n         describes the underlying data model, the operations it supports,  and\n         the AWS SDKs that you can use to interact with the service.\n\n      Getting  Started  with  Amazon  Glacier - The Getting Started section\n         walks you through the process of  creating  a  vault,  uploading  ar-\n         chives,  creating  jobs to download archives, retrieving the job out-\n         put, and deleting archives."
		},
		{
			"available commands": [
				"abort-multipart-upload",
				"abort-vault-lock",
				"add-tags-to-vault",
				"complete-multipart-upload",
				"complete-vault-lock",
				"create-vault",
				"delete-archive",
				"delete-vault",
				"delete-vault-access-policy",
				"delete-vault-notifications",
				"describe-job",
				"describe-vault",
				"get-data-retrieval-policy",
				"get-job-output",
				"get-vault-access-policy",
				"get-vault-lock",
				"get-vault-notifications",
				"help",
				"initiate-job",
				"initiate-multipart-upload",
				"initiate-vault-lock",
				"list-jobs",
				"list-multipart-uploads",
				"list-parts",
				"list-provisioned-capacity",
				"list-tags-for-vault",
				"list-vaults",
				"purchase-provisioned-capacity",
				"remove-tags-from-vault",
				"set-data-retrieval-policy",
				"set-vault-access-policy",
				"set-vault-notifications",
				"upload-archive",
				"upload-multipart-part",
				"wait"
			]
		}
	],
	"glue": [{
			"name": "glue"
		},
		{
			"description": "Defines the public endpoint for the AWS Glue service."
		},
		{
			"available commands": [
				"batch-create-partition",
				"batch-delete-connection",
				"batch-delete-partition",
				"batch-delete-table",
				"batch-delete-table-version",
				"batch-get-partition",
				"batch-stop-job-run",
				"create-classifier",
				"create-connection",
				"create-crawler",
				"create-database",
				"create-dev-endpoint",
				"create-job",
				"create-partition",
				"create-script",
				"create-table",
				"create-trigger",
				"create-user-defined-function",
				"delete-classifier",
				"delete-connection",
				"delete-crawler",
				"delete-database",
				"delete-dev-endpoint",
				"delete-job",
				"delete-partition",
				"delete-table",
				"delete-table-version",
				"delete-trigger",
				"delete-user-defined-function",
				"get-catalog-import-status",
				"get-classifier",
				"get-classifiers",
				"get-connection",
				"get-connections",
				"get-crawler",
				"get-crawler-metrics",
				"get-crawlers",
				"get-database",
				"get-databases",
				"get-dataflow-graph",
				"get-dev-endpoint",
				"get-dev-endpoints",
				"get-job",
				"get-job-run",
				"get-job-runs",
				"get-jobs",
				"get-mapping",
				"get-partition",
				"get-partitions",
				"get-plan",
				"get-table",
				"get-table-version",
				"get-table-versions",
				"get-tables",
				"get-trigger",
				"get-triggers",
				"get-user-defined-function",
				"get-user-defined-functions",
				"help",
				"import-catalog-to-glue",
				"reset-job-bookmark",
				"start-crawler",
				"start-crawler-schedule",
				"start-job-run",
				"start-trigger",
				"stop-crawler",
				"stop-crawler-schedule",
				"stop-trigger",
				"update-classifier",
				"update-connection",
				"update-crawler",
				"update-crawler-schedule",
				"update-database",
				"update-dev-endpoint",
				"update-job",
				"update-partition",
				"update-table",
				"update-trigger",
				"update-user-defined-function"
			]
		}
	],
	"greengrass": [{
			"name": "greengrass"
		},
		{
			"description": "AWS Greengrass seamlessly extends AWS onto physical devices so they can\n       act locally on the data they generate, while still using the cloud  for\n       management, analytics, and durable storage. AWS Greengrass ensures your\n       devices can respond quickly to local events and operate with  intermit-\n       tent  connectivity.  AWS  Greengrass minimizes the cost of transmitting\n       data to the cloud by allowing you to author AWS Lambda  functions  that\n       execute locally."
		},
		{
			"available commands": [
				"associate-role-to-group",
				"associate-service-role-to-account",
				"create-core-definition",
				"create-core-definition-version",
				"create-deployment",
				"create-device-definition",
				"create-device-definition-version",
				"create-function-definition",
				"create-function-definition-version",
				"create-group",
				"create-group-certificate-authority",
				"create-group-version",
				"create-logger-definition",
				"create-logger-definition-version",
				"create-resource-definition",
				"create-resource-definition-version",
				"create-software-update-job",
				"create-subscription-definition",
				"create-subscription-definition-version",
				"delete-core-definition",
				"delete-device-definition",
				"delete-function-definition",
				"delete-group",
				"delete-logger-definition",
				"delete-resource-definition",
				"delete-subscription-definition",
				"disassociate-role-from-group",
				"disassociate-service-role-from-account",
				"get-associated-role",
				"get-connectivity-info",
				"get-core-definition",
				"get-core-definition-version",
				"get-deployment-status",
				"get-device-definition",
				"get-device-definition-version",
				"get-function-definition",
				"get-function-definition-version",
				"get-group",
				"get-group-certificate-authority",
				"get-group-certificate-configuration",
				"get-group-version",
				"get-logger-definition",
				"get-logger-definition-version",
				"get-resource-definition",
				"get-resource-definition-version",
				"get-service-role-for-account",
				"get-subscription-definition",
				"get-subscription-definition-version",
				"help",
				"list-core-definition-versions",
				"list-core-definitions",
				"list-deployments",
				"list-device-definition-versions",
				"list-device-definitions",
				"list-function-definition-versions",
				"list-function-definitions",
				"list-group-certificate-authorities",
				"list-group-versions",
				"list-groups",
				"list-logger-definition-versions",
				"list-logger-definitions",
				"list-resource-definition-versions",
				"list-resource-definitions",
				"list-subscription-definition-versions",
				"list-subscription-definitions",
				"reset-deployments",
				"update-connectivity-info",
				"update-core-definition",
				"update-device-definition",
				"update-function-definition",
				"update-group",
				"update-group-certificate-configuration",
				"update-logger-definition",
				"update-resource-definition",
				"update-subscription-definition"
			]
		}
	],
	"guardduty": [{
			"name": "guardduty"
		},
		{
			"description": "Assess,  monitor, manage, and remediate security issues across your AWS\n       infrastructure, applications, and data."
		},
		{
			"available commands": [
				"accept-invitation",
				"archive-findings",
				"create-detector",
				"create-filter",
				"create-ip-set",
				"create-members",
				"create-sample-findings",
				"create-threat-intel-set",
				"decline-invitations",
				"delete-detector",
				"delete-filter",
				"delete-invitations",
				"delete-ip-set",
				"delete-members",
				"delete-threat-intel-set",
				"disassociate-from-master-account",
				"disassociate-members",
				"get-detector",
				"get-filter",
				"get-findings",
				"get-findings-statistics",
				"get-invitations-count",
				"get-ip-set",
				"get-master-account",
				"get-members",
				"get-threat-intel-set",
				"help",
				"invite-members",
				"list-detectors",
				"list-filters",
				"list-findings",
				"list-invitations",
				"list-ip-sets",
				"list-members",
				"list-threat-intel-sets",
				"start-monitoring-members",
				"stop-monitoring-members",
				"unarchive-findings",
				"update-detector",
				"update-filter",
				"update-findings-feedback",
				"update-ip-set",
				"update-threat-intel-set"
			]
		}
	],
	"health": [{
			"name": "health"
		},
		{
			"description": "The  AWS  Health  API  provides  programmatic  access to the AWS Health\n       information that is presented in the AWS Personal  Health  Dashboard  .\n       You can get information about events that affect your AWS resources:\n\n       -describe-events : Summary information about events.\n\n       -describe-event-details  :  Detailed  information  about  one  or more\n         events.\n\n       -describe-affected-entities : Information about AWS resources that are\n         affected by one or more events.\n\n       In addition, these operations provide information about event types and\n       summary counts of events or affected entities:\n\n       -describe-event-types : Information about the kinds of events that AWS\n         Health tracks.\n\n       -describe-event-aggregates : A count of the number of events that meet\n         specified criteria.\n\n       -describe-entity-aggregates : A count of the number of affected  enti-\n         ties that meet specified criteria.\n\n       The  Health API requires a Business or Enterprise support plan from AWS\n       Support . Calling the Health API from an account that does not  have  a\n       Business or Enterprise support plan causes a SubscriptionRequiredExcep-\n       tion .\n\n       For authentication of requests, AWS Health uses the Signature Version 4\n       Signing Process .\n\n       See the AWS Health User Guide for information about how to use the API.\n          Service Endpoint\n\n       The HTTP endpoint for the AWS Health API is:\n\n        https://health.us-east-1.amazonaws.com"
		},
		{
			"available commands": [
				"describe-affected-entities",
				"describe-entity-aggregates",
				"describe-event-aggregates",
				"describe-event-details",
				"describe-event-types",
				"describe-events",
				"help"
			]
		}
	],
	"history": [{
			"name": "history"
		},
		{
			"description": "Commands  to  interact  with  the  history of AWS CLI commands ran over\n       time. To record the history of AWS  CLI  commands  set  cli_history  to\n       enabled in the ~/.aws/config file. This can be done by running:\n\n       $ aws configure set cli_history enabled\n\n       See 'aws help' for descriptions of global parameters."
		},
		{
			"synopsis": "history"
		},
		{
			"options": "None"
		},
		{
			"available commands": [
				"list",
				"show"
			]
		}
	],
	"iam": [{
			"name": "iam"
		},
		{
			"description": "<p>AWS  Identity and Access Management (IAM) is a web service that you can\n       use to manage users and user permissions under your AWS  account.  This\n       guide  provides  descriptions of IAM actions that you can call program-\n       matically. For general information about  IAM,  see  AWS  Identity  and\n       Access Management (IAM) . For the user guide for IAM, see Using IAM .\n\n       NOTE:\n          AWS provides SDKs that consist of libraries and sample code for var-\n          ious programming languages and platforms  (Java,  Ruby,  .NET,  iOS,\n          Android, etc.). The SDKs provide a convenient way to create program-\n          matic access to IAM and AWS. For example,  the  SDKs  take  care  of\n          tasks such as cryptographically signing requests (see below), manag-\n          ing errors, and retrying  requests  automatically.  For  information\n          about  the AWS SDKs, including how to download and install them, see\n          the Tools for Amazon Web Services page.\n\n       We recommend that you use the AWS SDKs to make programmatic  API  calls\n       to  IAM.  However,  you  can  also use the IAM Query API to make direct\n       calls to the IAM web service. To learn more about the  IAM  Query  API,\n       see  Making Query Requests in the Using IAM guide. IAM supports GET and\n       POST requests for all actions. That is, the API does not require you to\n       use GET for some actions and POST for others. However, GET requests are\n       subject to the limitation size of a URL. Therefore, for operations that\n       require larger sizes, use a POST request.\n          Signing Requests\n\n       Requests must be signed using an access key ID and a secret access key.\n       We strongly recommend that you do not use your AWS account  access  key\n       ID  and  secret  access key for everyday work with IAM. You can use the\n       access key ID and secret access key for an IAM user or you can use  the\n       AWS  Security  Token Service to generate temporary security credentials\n       and use those to sign requests.\n\n       To sign requests, we recommend that you use Signature Version  4  .  If\n       you  have an existing application that uses Signature Version 2, you do\n       not have to update it to use Signature Version 4. However, some  opera-\n       tions now require Signature Version 4. The documentation for operations\n       that require version 4 indicate this requirement.\n          Additional Resources\n\n       For more information, see the following:\n      -AWS Security Credentials . This topic  provides  general  information\n         about the types of credentials used for accessing AWS.\n      -IAM  Best  Practices  . This topic presents a list of suggestions for\n         using the IAM service to help secure your AWS resources.\n      -Signing AWS API Requests . This set of topics walk  you  through  the\n         process of signing a request using an access key ID and secret access\n         key.</p>"
		},
		{
			"available commands": [
				"add-client-id-to-open-id-connect-provider",
				"add-role-to-instance-profile",
				"add-user-to-group",
				"attach-group-policy",
				"attach-role-policy",
				"attach-user-policy",
				"change-password",
				"create-access-key",
				"create-account-alias",
				"create-group",
				"create-instance-profile",
				"create-login-profile",
				"create-open-id-connect-provider",
				"create-policy",
				"create-policy-version",
				"create-role",
				"create-saml-provider",
				"create-service-linked-role",
				"create-service-specific-credential",
				"create-user",
				"create-virtual-mfa-device",
				"deactivate-mfa-device",
				"delete-access-key",
				"delete-account-alias",
				"delete-account-password-policy",
				"delete-group",
				"delete-group-policy",
				"delete-instance-profile",
				"delete-login-profile",
				"delete-open-id-connect-provider",
				"delete-policy",
				"delete-policy-version",
				"delete-role",
				"delete-role-policy",
				"delete-saml-provider",
				"delete-server-certificate",
				"delete-service-linked-role",
				"delete-service-specific-credential",
				"delete-signing-certificate",
				"delete-ssh-public-key",
				"delete-user",
				"delete-user-policy",
				"delete-virtual-mfa-device",
				"detach-group-policy",
				"detach-role-policy",
				"detach-user-policy",
				"enable-mfa-device",
				"generate-credential-report",
				"get-access-key-last-used",
				"get-account-authorization-details",
				"get-account-password-policy",
				"get-account-summary",
				"get-context-keys-for-custom-policy",
				"get-context-keys-for-principal-policy",
				"get-credential-report",
				"get-group",
				"get-group-policy",
				"get-instance-profile",
				"get-login-profile",
				"get-open-id-connect-provider",
				"get-policy",
				"get-policy-version",
				"get-role",
				"get-role-policy",
				"get-saml-provider",
				"get-server-certificate",
				"get-service-linked-role-deletion-status",
				"get-ssh-public-key",
				"get-user",
				"get-user-policy",
				"help",
				"list-access-keys",
				"list-account-aliases",
				"list-attached-group-policies",
				"list-attached-role-policies",
				"list-attached-user-policies",
				"list-entities-for-policy",
				"list-group-policies",
				"list-groups",
				"list-groups-for-user",
				"list-instance-profiles",
				"list-instance-profiles-for-role",
				"list-mfa-devices",
				"list-open-id-connect-providers",
				"list-policies",
				"list-policy-versions",
				"list-role-policies",
				"list-roles",
				"list-saml-providers",
				"list-server-certificates",
				"list-service-specific-credentials",
				"list-signing-certificates",
				"list-ssh-public-keys",
				"list-user-policies",
				"list-users",
				"list-virtual-mfa-devices",
				"put-group-policy",
				"put-role-policy",
				"put-user-policy",
				"remove-client-id-from-open-id-connect-provider",
				"remove-role-from-instance-profile",
				"remove-user-from-group",
				"reset-service-specific-credential",
				"resync-mfa-device",
				"set-default-policy-version",
				"simulate-custom-policy",
				"simulate-principal-policy",
				"update-access-key",
				"update-account-password-policy",
				"update-assume-role-policy",
				"update-group",
				"update-login-profile",
				"update-open-id-connect-provider-thumbprint",
				"update-role",
				"update-role-description",
				"update-saml-provider",
				"update-server-certificate",
				"update-service-specific-credential",
				"update-signing-certificate",
				"update-ssh-public-key",
				"update-user",
				"upload-server-certificate",
				"upload-signing-certificate",
				"upload-ssh-public-key",
				"wait"
			]
		}
	],
	"importexport": [{
			"name": "importexport"
		},
		{
			"description": "AWS  Import/Export  accelerates  transferring  large  amounts  of  data\n       between the AWS cloud and portable storage devices that you mail to us.\n       AWS  Import/Export transfers data directly onto and off of your storage\n       devices using Amazon's high-speed internal network  and  bypassing  the\n       Internet.  For  large data sets, AWS Import/Export is often faster than\n       Internet transfer and more cost effective than upgrading  your  connec-\n       tivity."
		},
		{
			"available commands": [
				"cancel-job",
				"create-job",
				"get-shipping-label",
				"get-status",
				"help",
				"list-jobs",
				"update-job"
			]
		}
	],
	"inspector": [{
			"name": "inspector"
		},
		{
			"description": "Amazon  Inspector  enables  you  to  analyze  the  behavior of your AWS\n       resources and to identify potential security issues. For more  informa-\n       tion, see Amazon Inspector User Guide ."
		},
		{
			"available commands": [
				"add-attributes-to-findings",
				"create-assessment-target",
				"create-assessment-template",
				"create-exclusions-preview",
				"create-resource-group",
				"delete-assessment-run",
				"delete-assessment-target",
				"delete-assessment-template",
				"describe-assessment-runs",
				"describe-assessment-targets",
				"describe-assessment-templates",
				"describe-cross-account-access-role",
				"describe-exclusions",
				"describe-findings",
				"describe-resource-groups",
				"describe-rules-packages",
				"get-assessment-report",
				"get-exclusions-preview",
				"get-telemetry-metadata",
				"help",
				"list-assessment-run-agents",
				"list-assessment-runs",
				"list-assessment-targets",
				"list-assessment-templates",
				"list-event-subscriptions",
				"list-exclusions",
				"list-findings",
				"list-rules-packages",
				"list-tags-for-resource",
				"preview-agents",
				"register-cross-account-access-role",
				"remove-attributes-from-findings",
				"set-tags-for-resource",
				"start-assessment-run",
				"stop-assessment-run",
				"subscribe-to-event",
				"unsubscribe-from-event",
				"update-assessment-target"
			]
		}
	],
	"iot": [{
			"name": "iot"
		},
		{
			"description": "AWS  IoT  provides  secure, bi-directional communication between Inter-\n       net-connected devices (such as sensors, actuators, embedded devices, or\n       smart  appliances)  and  the  AWS  cloud.  You can discover your custom\n       IoT-Data endpoint to communicate with, configure rules  for  data  pro-\n       cessing and integration with other services, organize resources associ-\n       ated with each device (Registry), configure  logging,  and  create  and\n       manage policies and credentials to authenticate devices.\n\n       For more information about how AWS IoT works, see the Developer Guide ."
		},
		{
			"available commands": [
				"accept-certificate-transfer",
				"add-thing-to-thing-group",
				"associate-targets-with-job",
				"attach-policy",
				"attach-thing-principal",
				"cancel-certificate-transfer",
				"cancel-job",
				"cancel-job-execution",
				"clear-default-authorizer",
				"create-authorizer",
				"create-certificate-from-csr",
				"create-job",
				"create-keys-and-certificate",
				"create-ota-update",
				"create-policy",
				"create-policy-version",
				"create-role-alias",
				"create-stream",
				"create-thing",
				"create-thing-group",
				"create-thing-type",
				"create-topic-rule",
				"delete-authorizer",
				"delete-ca-certificate",
				"delete-certificate",
				"delete-job",
				"delete-job-execution",
				"delete-ota-update",
				"delete-policy",
				"delete-policy-version",
				"delete-registration-code",
				"delete-role-alias",
				"delete-stream",
				"delete-thing",
				"delete-thing-group",
				"delete-thing-type",
				"delete-topic-rule",
				"delete-v",
				"logging-level",
				"deprecate-thing-type",
				"describe-authorizer",
				"describe-ca-certificate",
				"describe-certificate",
				"describe-default-authorizer",
				"describe-endpoint",
				"describe-event-configurations",
				"describe-index",
				"describe-job",
				"describe-job-execution",
				"describe-role-alias",
				"describe-stream",
				"describe-thing",
				"describe-thing-group",
				"describe-thing-registration-task",
				"describe-thing-type",
				"detach-policy",
				"detach-thing-principal",
				"disable-topic-rule",
				"enable-topic-rule",
				"get-effective-policies",
				"get-indexing-configuration",
				"get-job-document",
				"get-logging-options",
				"get-ota-update",
				"get-policy",
				"get-policy-version",
				"get-registration-code",
				"get-topic-rule",
				"get-v",
				"logging-options",
				"help",
				"list-attached-policies",
				"list-authorizers",
				"list-ca-certificates",
				"list-certificates",
				"list-certificates-by-ca",
				"list-indices",
				"list-job-executions-for-job",
				"list-job-executions-for-thing",
				"list-jobs",
				"list-ota-updates",
				"list-outgoing-certificates",
				"list-policies",
				"list-policy-versions",
				"list-principal-things",
				"list-role-aliases",
				"list-streams",
				"list-targets-for-policy",
				"list-thing-groups",
				"list-thing-groups-for-thing",
				"list-thing-principals",
				"list-thing-registration-task-reports",
				"list-thing-registration-tasks",
				"list-thing-types",
				"list-things",
				"list-things-in-thing-group",
				"list-topic-rules",
				"list-v",
				"logging-levels",
				"register-ca-certificate",
				"register-certificate",
				"register-thing",
				"reject-certificate-transfer",
				"remove-thing-from-thing-group",
				"replace-topic-rule",
				"search-index",
				"set-default-authorizer",
				"set-default-policy-version",
				"set-logging-options",
				"set-v",
				"set-v",
				"start-thing-registration-task",
				"stop-thing-registration-task",
				"test-authorization",
				"test-invoke-authorizer",
				"transfer-certificate",
				"update-authorizer",
				"update-ca-certificate",
				"update-certificate",
				"update-event-configurations",
				"update-indexing-configuration",
				"update-role-alias",
				"update-stream",
				"update-thing",
				"update-thing-group",
				"update-thing-groups-for-thing"
			]
		}
	],
	"iot-data": [{
			"name": "iot-data"
		},
		{
			"description": "AWS  IoT-Data  enables  secure,  bi-directional  communication  between\n       Internet-connected  things  (such  as  sensors,   actuators,   embedded\n       devices, or smart appliances) and the AWS cloud. It implements a broker\n       for applications and things to publish messages over HTTP (Publish) and\n       retrieve, update, and delete thing shadows. A thing shadow is a persis-\n       tent representation of your things and their state in the AWS cloud.\n\n       NOTE:\n          The default endpoint data.iot.[region.amazonaws.com is intended for\n          testing  purposes  only.  For  production code it is strongly recom-\n          mended to use the custom endpoint for your account  (retrievable via\n          the  iot  describe-endpoint command) to ensure best availability and\n          reachability of the service."
		},
		{
			"available commands": [
				"delete-thing-shadow",
				"get-thing-shadow",
				"help",
				"publish",
				"update-thing-shadow"
			]
		}
	],
	"iot-jobs-data": [{
			"name": "iot-jobs-data"
		},
		{
			"description": "AWS  IoT  Jobs  is  a  service  that allows you to define a set of jobs\n       remote operations that are sent to and executed on one or more  devices\n       connected  to AWS IoT. For example, you can define a job that instructs\n       a set of devices  to  download  and  install  application  or  firmware\n       updates, reboot, rotate certificates, or perform remote troubleshooting\n       operations.\n\n       To create a job, you make a job document which is a description of  the\n       remote  operations  to  be performed, and you specify a list of targets\n       that should perform the  operations.  The  targets  can  be  individual\n       things, thing groups or both.\n\n       AWS IoT Jobs sends a message to inform the targets that a job is avail-\n       able. The target starts the execution of the job by downloading the job\n       document,  performing  the  operations  it specifies, and reporting its\n       progress to AWS IoT. The Jobs service provides commands  to  track  the\n       progress  of  a job on a specific target and for all the targets of the\n       job"
		},
		{
			"available commands": [
				"describe-job-execution",
				"get-pending-job-executions",
				"help",
				"start-next-pending-job-execution",
				"update-job-execution"
			]
		}
	],
	"iot1click-devices": [{
			"name": "iot1click-devices"
		},
		{
			"description": "Stub description"
		},
		{
			"available commands": [
				"claim-devices-by-claim-code",
				"describe-device",
				"finalize-device-claim",
				"get-device-methods",
				"help",
				"initiate-device-claim",
				"invoke-device-method",
				"list-device-events",
				"list-devices",
				"unclaim-device",
				"update-device-state"
			]
		}
	],
	"iot1click-projects": [{
			"name": "iot1click-projects"
		},
		{
			"description": "The AWS IoT 1-Click Project API Reference"
		},
		{
			"available commands": [
				"associate-device-with-placement",
				"create-placement",
				"create-project",
				"delete-placement",
				"delete-project",
				"describe-placement",
				"describe-project",
				"disassociate-device-from-placement",
				"get-devices-in-placement",
				"help",
				"list-placements",
				"list-projects",
				"update-placement",
				"update-project"
			]
		}
	],
	"iotanalytics": [{
			"name": "iotanalytics"
		},
		{
			"description": "AWS  IoT  Analytics allows you to collect large amounts of device data,\n       process messages, and store them. You can then query the data  and  run\n       sophisticated  analytics on it. AWS IoT Analytics enables advanced data\n       exploration through integration with Jupyter Notebooks and data visual-\n       ization through integration with Amazon QuickSight.\n\n       Traditional  analytics  and business intelligence tools are designed to\n       process structured data. IoT data often comes from devices that  record\n       noisy  processes  (such  as temperature, motion, or sound). As a result\n       the data from these devices can have significant gaps,  corrupted  mes-\n       sages,  and  false readings that must be cleaned up before analysis can\n       occur. Also, IoT data is often only meaningful in the context of  other\n       data from external sources.\n\n       AWS IoT Analytics automates the steps required to analyze data from IoT\n       devices. AWS IoT Analytics filters, transforms, and enriches  IoT  data\n       before storing it in a time-series data store for analysis. You can set\n       up the service to collect only the data you  need  from  your  devices,\n       apply  mathematical transforms to process the data, and enrich the data\n       with device-specific metadata such as device type and  location  before\n       storing  it.  Then,  you can analyze your data by running queries using\n       the built-in SQL query engine, or perform more  complex  analytics  and\n       machine learning inference. AWS IoT Analytics includes pre-built models\n       for common IoT use cases so you can answer questions like which devices\n       are  about  to  fail or which customers are at risk of abandoning their\n       wearable devices."
		},
		{
			"available commands": [
				"batch-put-message",
				"cancel-pipeline-reprocessing",
				"create-channel",
				"create-dataset",
				"create-dataset-content",
				"create-datastore",
				"create-pipeline",
				"delete-channel",
				"delete-dataset",
				"delete-dataset-content",
				"delete-datastore",
				"delete-pipeline",
				"describe-channel",
				"describe-dataset",
				"describe-datastore",
				"describe-logging-options",
				"describe-pipeline",
				"get-dataset-content",
				"help",
				"list-channels",
				"list-datasets",
				"list-datastores",
				"list-pipelines",
				"list-tags-for-resource",
				"put-logging-options",
				"run-pipeline-activity",
				"sample-channel-data",
				"start-pipeline-reprocessing",
				"tag-resource",
				"untag-resource",
				"update-channel",
				"update-dataset",
				"update-datastore",
				"update-pipeline"
			]
		}
	],
	"kinesis": [{
			"name": "kinesis"
		},
		{
			"description": "Amazon  Kinesis  Data  Streams is a managed service that scales elasti-\n       cally for real-time processing of streaming big data."
		},
		{
			"available commands": [
				"add-tags-to-stream",
				"create-stream",
				"decrease-stream-retention-period",
				"delete-stream",
				"describe-limits",
				"describe-stream",
				"describe-stream-summary",
				"disable-enhanced-monitoring",
				"enable-enhanced-monitoring",
				"get-records",
				"get-shard-iterator",
				"help",
				"increase-stream-retention-period",
				"list-shards",
				"list-streams",
				"list-tags-for-stream",
				"merge-shards",
				"put-record",
				"put-records",
				"remove-tags-from-stream",
				"split-shard",
				"start-stream-encryption",
				"stop-stream-encryption",
				"update-shard-count",
				"wait"
			]
		}
	],
	"kinesis-video-archived-media": [{
			"name": "kinesis-video-archived-media"
		},
		{
			"description": "None"
		},
		{
			"available commands": [
				"get-media-for-fragment-list",
				"help",
				"list-fragments"
			]
		}
	],
	"kinesis-video-media": [{
			"name": "kinesis-video-media"
		},
		{
			"description": "None"
		},
		{
			"available commands": [
				"get-media",
				"help"
			]
		}
	],
	"kinesisanalytics": [{
			"name": "kinesisanalytics"
		},
		{
			"description": "None"
		},
		{
			"available commands": [
				"add-application-cloud-watch-logging-option",
				"add-application-input",
				"add-application-input-processing-configuration",
				"add-application-output",
				"add-application-reference-data-source",
				"create-application",
				"delete-application",
				"delete-application-cloud-watch-logging-option",
				"delete-application-input-processing-configuration",
				"delete-application-output",
				"delete-application-reference-data-source",
				"describe-application",
				"discover-input-schema",
				"help",
				"list-applications",
				"start-application",
				"stop-application",
				"update-application"
			]
		}
	],
	"kinesisvideo": [{
			"name": "kinesisvideo"
		},
		{
			"description": "None"
		},
		{
			"available commands": [
				"create-stream",
				"delete-stream",
				"describe-stream",
				"get-data-endpoint",
				"help",
				"list-streams",
				"list-tags-for-stream",
				"tag-stream",
				"untag-stream",
				"update-data-retention",
				"update-stream"
			]
		}
	],
	"kms": [{
			"name": "kms"
		},
		{
			"description": "AWS  Key  Management Service (AWS KMS) is an encryption and key manage\n       ment web service. This guide describes the AWS KMS operations that  you\n       can  call  programmatically. For general information about AWS KMS, see\n       the AWS Key Management Service Developer Guide .\n\n       NOTE:\n          AWS provides SDKs that consist of libraries and sample code for var-\n          ious  programming  languages  and  platforms (Java, Ruby, .Net, iOS,\n          Android, etc.). The SDKs provide a convenient way to create program-\n          matic  access  to  AWS  KMS and other AWS services. For example, the\n          SDKs take care of tasks such as signing requests (see below), manag-\n          ing  errors,  and retrying requests automatically. For more informa-\n          tion about the AWS SDKs, including how to download and install them,\n          see Tools for Amazon Web Services .\n\n       We  recommend  that you use the AWS SDKs to make programmatic API calls\n       to AWS KMS.\n\n       Clients must support TLS (Transport Layer Security) 1.0.  We  recommend\n       TLS  1.2.  Clients must also support cipher suites with Perfect Forward\n       Secrecy (PFS) such as Ephemeral Diffie-Hellman (DHE) or Elliptic  Curve\n       Ephemeral  Diffie-Hellman  (ECDHE).  Most modern systems such as Java 7\n       and later support these modes.\n          Signing Requests\n\n       Requests must be signed by using an access key ID and a  secret  access\n       key.  We strongly recommend that you do not use your AWS account (root)\n       access key ID and secret key for everyday work with AWS  KMS.  Instead,\n       use the access key ID and secret access key for an IAM user, or you can\n       use the AWS Security Token Service to generate temporary security  cre-\n       dentials that you can use to sign requests.\n\n       All AWS KMS operations require Signature Version 4 .\n          Logging API Requests\n\n       AWS  KMS supports AWS CloudTrail, a service that logs AWS API calls and\n       related events for your AWS account and delivers them to an  Amazon  S3\n       bucket  that  you specify. By using the information collected by Cloud-\n       Trail, you can determine what requests were made to AWS KMS,  who  made\n       the  request,  when  it was made, and so on. To learn more about Cloud-\n       Trail, including how to turn it on and find your log files, see the AWS\n       CloudTrail User Guide .\n          Additional Resources\n\n       For  more  information  about  credentials and request signing, see the\n       following:\n\n      AWS Security Credentials - This topic  provides  general  information\n         about the types of credentials used for accessing AWS.\n\n      Temporary  Security  Credentials - This section of the IAM User Guide\n         describes how to create and use temporary security credentials.\n\n      Signature Version 4 Signing Process - This set of  topics  walks  you\n         through the process of signing a request using an access key ID and a\n         secret access key.\n          Commonly Used APIs\n\n       Of the APIs discussed in this guide, the following will prove the  most\n       useful  for  most  applications.  You will likely perform actions other\n       than these, such as creating keys and assigning policies, by using  the\n       console."
		},
		{
			"options": [
				"encrypt",
				"decrypt",
				"generate-data-key",
				"generate-data-key-without-plaintext"
			]
		},

		{
			"available commands": [
				"cancel-key-deletion",
				"create-alias",
				"create-grant",
				"create-key",
				"decrypt",
				"delete-alias",
				"delete-imported-key-material",
				"describe-key",
				"disable-key",
				"disable-key-rotation",
				"enable-key",
				"enable-key-rotation",
				"encrypt",
				"generate-data-key",
				"generate-data-key-without-plaintext",
				"generate-random",
				"get-key-policy",
				"get-key-rotation-status",
				"get-parameters-for-import",
				"help",
				"import-key-material",
				"list-aliases",
				"list-grants",
				"list-key-policies",
				"list-keys",
				"list-resource-tags",
				"list-retirable-grants",
				"put-key-policy",
				"re-encrypt",
				"retire-grant",
				"revoke-grant",
				"schedule-key-deletion",
				"tag-resource",
				"untag-resource",
				"update-alias",
				"update-key-description"
			]
		}
	],
	"lambda": [{
			"name": "lambda"
		},
		{
			"description": "Overview\n\n       This  is  the AWS Lambda API Reference . The AWS Lambda Developer Guide\n       provides additional information. For the service overview, see What  is\n       AWS  Lambda  , and for information about how the service works, see AWS\n       Lambda: How it Works in the AWS Lambda Developer Guide ."
		},
		{
			"available commands": [
				"add-permission",
				"create-alias",
				"create-event-source-mapping",
				"create-function",
				"delete-alias",
				"delete-event-source-mapping",
				"delete-function",
				"delete-function-concurrency",
				"get-account-settings",
				"get-alias",
				"get-event-source-mapping",
				"get-function",
				"get-function-configuration",
				"get-policy",
				"help",
				"invoke",
				"list-aliases",
				"list-event-source-mappings",
				"list-functions",
				"list-tags",
				"list-versions-by-function",
				"publish-version",
				"put-function-concurrency",
				"remove-permission",
				"tag-resource",
				"untag-resource",
				"update-alias",
				"update-event-source-mapping",
				"update-function-code",
				"update-function-configuration"
			]
		}
	],
	"lex-models": [{
			"name": "lex-models"
		},
		{
			"description": "Amazon Lex is an AWS service for building conversational voice and text\n       interfaces. Use these actions to create, update, and  delete  conversa-\n       tional bots for new and existing client applications."
		},
		{
			"available commands": [
				"create-bot-version",
				"create-intent-version",
				"create-slot-type-version",
				"delete-bot",
				"delete-bot-alias",
				"delete-bot-channel-association",
				"delete-bot-version",
				"delete-intent",
				"delete-intent-version",
				"delete-slot-type",
				"delete-slot-type-version",
				"delete-utterances",
				"get-bot",
				"get-bot-alias",
				"get-bot-aliases",
				"get-bot-channel-association",
				"get-bot-channel-associations",
				"get-bot-versions",
				"get-bots",
				"get-builtin-intent",
				"get-builtin-intents",
				"get-builtin-slot-types",
				"get-export",
				"get-import",
				"get-intent",
				"get-intent-versions",
				"get-intents",
				"get-slot-type",
				"get-slot-type-versions",
				"get-slot-types",
				"get-utterances-view",
				"help",
				"put-bot",
				"put-bot-alias",
				"put-intent",
				"put-slot-type",
				"start-import"
			]
		}
	],
	"lex-runtime": [{
			"name": "lex-runtime"
		},
		{
			"description": "Amazon  Lex  provides  both  build and runtime endpoints. Each endpoint\n       provides a set of operations (API). Your conversational  bot  uses  the\n       runtime  API  to understand user utterances (user input text or voice).\n       For example, suppose a user says 'I want pizza', your  bot  sends  this\n       input  to  Amazon Lex using the runtime API. Amazon Lex recognizes that\n       the user request is for the  OrderPizza  intent  (one  of  the  intents\n       defined  in  the  bot). Then Amazon Lex engages in user conversation on\n       behalf of the bot to elicit required information (slot values, such  as\n       pizza  size  and  crust  type),  and then performs fulfillment activity\n       (that you configured when you created the bot). You use the  build-time\n       API  to create and manage your Amazon Lex bot. For a list of build-time\n       operations, see the build-time API, ."
		},
		{
			"available commands": [
				"help",
				"post-content",
				"post-text"
			]
		}
	],
	"lightsail": [{
			"name": "lightsail"
		},
		{
			"description": "Amazon  Lightsail is the easiest way to get started with AWS for devel-\n       opers who just need virtual private servers. Lightsail includes  every-\n       thing  you  need  to  launch  your project quickly - a virtual machine,\n       SSD-based storage, data transfer, DNS management, and a static IP - for\n       a  low,  predictable  price. You manage those Lightsail servers through\n       the Lightsail console or by using the  API  or  command-line  interface\n       (CLI).\n\n       For  more  information  about  Lightsail  concepts  and  tasks, see the\n       Lightsail Dev Guide .\n\n       To use the Lightsail API or the CLI, you will need to use AWS  Identity\n       and  Access Management (IAM) to generate access keys. For details about\n       how to set this up, see the Lightsail Dev Guide ."
		},
		{
			"available commands": [
				"allocate-static-ip",
				"attach-disk",
				"attach-instances-to-load-balancer",
				"attach-load-balancer-tls-certificate",
				"attach-static-ip",
				"close-instance-public-ports",
				"create-disk",
				"create-disk-from-snapshot",
				"create-disk-snapshot",
				"create-domain",
				"create-domain-entry",
				"create-instance-snapshot",
				"create-instances",
				"create-instances-from-snapshot",
				"create-key-pair",
				"create-load-balancer",
				"create-load-balancer-tls-certificate",
				"delete-disk",
				"delete-disk-snapshot",
				"delete-domain",
				"delete-domain-entry",
				"delete-instance",
				"delete-instance-snapshot",
				"delete-key-pair",
				"delete-load-balancer",
				"delete-load-balancer-tls-certificate",
				"detach-disk",
				"detach-instances-from-load-balancer",
				"detach-static-ip",
				"download-default-key-pair",
				"get-active-names",
				"get-blueprints",
				"get-bundles",
				"get-disk",
				"get-disk-snapshot",
				"get-disk-snapshots",
				"get-disks",
				"get-domain",
				"get-domains",
				"get-instance",
				"get-instance-access-details",
				"get-instance-metric-data",
				"get-instance-port-states",
				"get-instance-snapshot",
				"get-instance-snapshots",
				"get-instance-state",
				"get-instances",
				"get-key-pair",
				"get-key-pairs",
				"get-load-balancer",
				"get-load-balancer-metric-data",
				"get-load-balancer-tls-certificates",
				"get-load-balancers",
				"get-operation",
				"get-operations",
				"get-operations-for-resource",
				"get-regions",
				"get-static-ip",
				"get-static-ips",
				"help",
				"import-key-pair",
				"is-vpc-peered",
				"open-instance-public-ports",
				"peer-vpc",
				"put-instance-public-ports",
				"reboot-instance",
				"release-static-ip",
				"start-instance",
				"stop-instance",
				"unpeer-vpc",
				"update-domain-entry",
				"update-load-balancer-attribute"
			]
		}
	],
	"logs": [{
			"name": "logs"
		},
		{
			"description": "You  can  use Amazon CloudWatch Logs to monitor, store, and access your\n       log files from Amazon EC2 instances, AWS CloudTrail, or other  sources.\n       You  can  then  retrieve  the  associated log data from CloudWatch Logs\n       using the CloudWatch console, CloudWatch Logs commands in the AWS  CLI,\n       CloudWatch Logs API, or CloudWatch Logs SDK.\n\n       You can use CloudWatch Logs to:\n\n     < Monitor logs from EC2 instances in real-time : You can use CloudWatch\n         Logs to monitor applications and systems using log data. For example,\n         CloudWatch  Logs  can  track  the number of errors that occur in your\n         application logs and send you a notification  whenever  the  rate  of\n         errors  exceeds  a  threshold  that you specify. CloudWatch Logs uses\n         your log data for monitoring; so, no code changes are  required.  For\n         example,  you can monitor application logs for specific literal terms\n         (such as 'NullReferenceException') or count the number of occurrences\n         of a literal term at a particular position in log data (such as '404'\n         status codes in an Apache access log). When the term you are  search-\n         ing  for  is  found, CloudWatch Logs reports the data to a CloudWatch\n         metric that you specify.\n\n     < Monitor AWS CloudTrail logged events  :  You  can  create  alarms  in\n         CloudWatch  and  receive  notifications of particular API activity as\n         captured by CloudTrail and use  the  notification  to  perform  trou-\n         bleshooting.\n\n     < Archive log data : You can use CloudWatch Logs to store your log data\n         in highly durable storage. You can change the log  retention  setting\n         so  that  any  log  events  older than this setting are automatically\n         deleted. The CloudWatch Logs agent makes it easy to quickly send both\n         rotated  and non-rotated log data off of a host and into the log ser-\n         vice. You can then access the raw log data when you need it."
		},
		{
			"available commands": [
				"associate-kms-key",
				"cancel-export-task",
				"create-export-task",
				"create-log-group",
				"create-log-stream",
				"delete-destination",
				"delete-log-group",
				"delete-log-stream",
				"delete-metric-filter",
				"delete-resource-policy",
				"delete-retention-policy",
				"delete-subscription-filter",
				"describe-destinations",
				"describe-export-tasks",
				"describe-log-groups",
				"describe-log-streams",
				"describe-metric-filters",
				"describe-resource-policies",
				"describe-subscription-filters",
				"disassociate-kms-key",
				"filter-log-events",
				"get-log-events",
				"help",
				"list-tags-log-group",
				"put-destination",
				"put-destination-policy",
				"put-log-events",
				"put-metric-filter",
				"put-resource-policy",
				"put-retention-policy",
				"put-subscription-filter",
				"tag-log-group",
				"test-metric-filter",
				"untag-log-group"
			]
		}
	],
	"machinelearning": [{
			"name": "machinelearning"
		},
		{
			"description": "Definition of the public APIs exposed by Amazon Machine Learning"
		},
		{
			"available commands": [
				"add-tags",
				"create-batch-prediction",
				"create-data-source-from-rds",
				"create-data-source-from-redshift",
				"create-data-source-from-s",
				"create-evaluation",
				"create-ml-model",
				"create-realtime-endpoint",
				"delete-batch-prediction",
				"delete-data-source",
				"delete-evaluation",
				"delete-ml-model",
				"delete-realtime-endpoint",
				"delete-tags",
				"describe-batch-predictions",
				"describe-data-sources",
				"describe-evaluations",
				"describe-ml-models",
				"describe-tags",
				"get-batch-prediction",
				"get-data-source",
				"get-evaluation",
				"get-ml-model",
				"help",
				"predict",
				"update-batch-prediction",
				"update-data-source",
				"update-evaluation",
				"update-ml-model",
				"wait"
			]
		}
	],
	"macie": [{
			"name": "macie"
		},
		{
			"description": "Amazon  Macie is a security service that uses machine learning to auto-\n       matically discover, classify, and protect sensitive data in AWS.  Macie\n       recognizes  sensitive  data such as personally identifiable information\n       (PII) or intellectual property, and provides you  with  dashboards  and\n       alerts  that  give  visibility  into how this data is being accessed or\n       moved. For more information, see the Macie User Guide ."
		},
		{
			"available commands": [
				"associate-member-account",
				"associate-s3-resources",
				"disassociate-member-account",
				"disassociate-s3-resources",
				"help",
				"list-member-accounts",
				"list-s3-resources",
				"update-s3-resources"
			]
		}
	],
	"marketplace-entitlement": [{
			"name": "marketplace-entitlement"
		},
		{
			"description": "This reference provides descriptions of the AWS Marketplace Entitlement\n       Service API.\n\n       AWS Marketplace Entitlement Service is used to determine  the  entitle-\n       ment of a customer to a given product. An entitlement represents capac-\n       ity in a product owned by the customer. For example, a  customer  might\n       own some number of users or seats in an SaaS application or some amount\n       of data capacity in a multi-tenant database.\n          Getting Entitlement Records\n\n      'get-entitlements' - Gets the entitlements for a Marketplace product."
		},
		{
			"available commands": [
				"get-entitlements",
				"help"
			]
		}
	],
	"marketplacecommerceanalytics": [{
			"name": "marketplacecommerceanalytics"
		},
		{
			"description": "Provides AWS Marketplace business intelligence data on-demand."
		},
		{
			"available commands": [
				"generate-data-set",
				"help",
				"start-support-data-export"
			]
		}
	],
	"mediaconvert": [{
			"name": "mediaconvert"
		},
		{
			"description": "AWS Elemental MediaConvert"
		},
		{
			"available commands": [
				"cancel-job",
				"create-job",
				"create-job-template",
				"create-preset",
				"create-queue",
				"delete-job-template",
				"delete-preset",
				"delete-queue",
				"describe-endpoints",
				"get-job",
				"get-job-template",
				"get-preset",
				"get-queue",
				"help",
				"list-job-templates",
				"list-jobs",
				"list-presets",
				"list-queues",
				"list-tags-for-resource",
				"tag-resource",
				"untag-resource",
				"update-job-template",
				"update-preset",
				"update-queue"
			]
		}
	],
	"medialive": [{
			"name": "medialive"
		},
		{
			"description": "API for AWS Elemental MediaLive"
		},
		{
			"available commands": [
				"create-channel",
				"create-input",
				"create-input-security-group",
				"delete-channel",
				"delete-input",
				"delete-input-security-group",
				"delete-reservation",
				"describe-channel",
				"describe-input",
				"describe-input-security-group",
				"describe-offering",
				"describe-reservation",
				"help",
				"list-channels",
				"list-input-security-groups",
				"list-inputs",
				"list-offerings",
				"list-reservations",
				"purchase-offering",
				"start-channel",
				"stop-channel",
				"update-channel",
				"update-input",
				"update-input-security-group"
			]
		}
	],
	"mediapackage": [{
			"name": "mediapackage"
		},
		{
			"description": "AWS Elemental MediaPackage"
		},
		{
			"available commands": [
				"create-channel",
				"create-origin-endpoint",
				"delete-channel",
				"delete-origin-endpoint",
				"describe-channel",
				"describe-origin-endpoint",
				"help",
				"list-channels",
				"list-origin-endpoints",
				"rotate-channel-credentials",
				"update-channel",
				"update-origin-endpoint"
			]
		}
	],
	"mediastore": [{
			"name": "mediastore"
		},
		{
			"description": "An AWS Elemental MediaStore container is a namespace that holds folders\n       and objects. You use a container endpoint to create, read,  and  delete\n       objects."
		},
		{
			"available commands": [
				"create-container",
				"delete-container",
				"delete-container-policy",
				"delete-cors-policy",
				"describe-container",
				"get-container-policy",
				"get-cors-policy",
				"help",
				"list-containers",
				"put-container-policy",
				"put-cors-policy"
			]
		}
	],
	"mediastore-data": [{
			"name": "mediastore-data"
		},
		{
			"description": "An AWS Elemental MediaStore asset is an object, similar to an object in\n       the Amazon S3 service. Objects are the fundamental  entities  that  are\n       stored in AWS Elemental MediaStore."
		},
		{
			"available commands": [
				"delete-object",
				"describe-object",
				"get-object",
				"help",
				"list-items",
				"put-object"
			]
		}
	],
	"mediatailor": [{
			"name": "mediatailor"
		},
		{
			"description": "Use  the  AWS Elemental MediaTailor SDK to configure scalable ad inser-\n       tion for your live and VOD content. With AWS Elemental MediaTailor, you\n       can  serve  targeted ads to viewers while maintaining broadcast quality\n       in over-the-top (OTT) video applications. For information  about  using\n       the  service, including detailed information about the settings covered\n       in this guide, see the AWS Elemental MediaTailor User Guide.\n\n       Through the SDK, you manage AWS  Elemental  MediaTailor  configurations\n       the  same  as  you  do through the console. For example, you specify ad\n       insertion behavior and mapping information for the  origin  server  and\n       the ad decision server (ADS)."
		},
		{
			"available commands": [
				"delete-playback-configuration",
				"get-playback-configuration",
				"help",
				"list-playback-configurations",
				"put-playback-configuration"
			]
		}
	],
	"meteringmarketplace": [{
			"name": "meteringmarketplace"
		},
		{
			"description": "This  reference  provides descriptions of the low-level AWS Marketplace\n       Metering Service API.\n\n       AWS Marketplace sellers can use this API to submit usage data for  cus-\n       tom usage dimensions.\n          Submitting Metering Records\n\n      'meter-usage'  - Submits the metering record for a Marketplace product.\n         meter-usage is called from an EC2 instance.\n\n      'batch-meter-usage' - Submits the metering record for  a  set  of  cus-\n         tomers.  batch-meter-usage  is  called  from  a software-as-a-service\n         (SaaS) application.\n          Accepting New Customers\n\n      'resolve-customer' - Called by a SaaS application during the  registra-\n         tion  process.  When a buyer visits your website during the registra-\n         tion process, the buyer submits  a  Registration  Token  through  the\n         browser.  The  Registration  Token  is  resolved  through this API to\n         obtain a CustomerIdentifier and Product Code."
		},
		{
			"available commands": [
				"batch-meter-usage",
				"help",
				"meter-usage",
				"resolve-customer"
			]
		}
	],
	"mgh": [{
			"name": "mgh"
		},
		{
			"description": "The AWS Migration Hub API methods help to obtain server and application\n       migration status and integrate your resource-specific migration tool by\n       providing a programmatic interface to Migration Hub."
		},
		{
			"available commands": [
				"associate-created-artifact",
				"associate-discovered-resource",
				"create-progress-update-stream",
				"delete-progress-update-stream",
				"describe-application-state",
				"describe-migration-task",
				"disassociate-created-artifact",
				"disassociate-discovered-resource",
				"help",
				"import-migration-task",
				"list-created-artifacts",
				"list-discovered-resources",
				"list-migration-tasks",
				"list-progress-update-streams",
				"notify-application-state",
				"notify-migration-task-state",
				"put-resource-attributes"
			]
		}
	],
	"mobile": [{
			"name": "mobile"
		},
		{
			"description": "AWS  Mobile  Service  provides  mobile  app and website developers with\n       capabilities required to configure AWS resources  and  bootstrap  their\n       developer  desktop  projects  with the necessary SDKs, constants, tools\n       and samples to make use of those resources."
		},
		{
			"available commands": [
				"create-project",
				"delete-project",
				"describe-bundle",
				"describe-project",
				"export-bundle",
				"export-project",
				"help",
				"list-bundles",
				"list-projects",
				"update-project"
			]
		}
	],
	"mq": [{
			"name": "mq"
		},
		{
			"description": "Amazon  MQ is a managed message broker service for Apache ActiveMQ that\n       makes it easy to set up and operate message brokers  in  the  cloud.  A\n       message  broker allows software applications and components to communi-\n       cate using various programming languages, operating systems, and formal\n       messaging protocols."
		},
		{
			"available commands": [
				"create-broker",
				"create-configuration",
				"create-user",
				"delete-broker",
				"delete-user",
				"describe-broker",
				"describe-configuration",
				"describe-configuration-revision",
				"describe-user",
				"help",
				"list-brokers",
				"list-configuration-revisions",
				"list-configurations",
				"list-users",
				"reboot-broker",
				"update-broker",
				"update-configuration",
				"update-user"
			]
		}
	],
	"mturk": [{
			"name": "mturk"
		},
		{
			"description": "None"
		},
		{
			"available commands": [
				"accept-qualification-request",
				"approve-assignment",
				"associate-qualification-with-worker",
				"create-additional-assignments-for-hit",
				"create-hit",
				"create-hit-type",
				"create-hit-with-hit-type",
				"create-qualification-type",
				"create-worker-block",
				"delete-hit",
				"delete-qualification-type",
				"delete-worker-block",
				"disassociate-qualification-from-worker",
				"get-account-balance",
				"get-assignment",
				"get-file-upload-url",
				"get-hit",
				"get-qualification-score",
				"get-qualification-type",
				"help",
				"list-assignments-for-hit",
				"list-bonus-payments",
				"list-hits",
				"list-hits-for-qualification-type",
				"list-qualification-requests",
				"list-qualification-types",
				"list-review-policy-results-for-hit",
				"list-reviewable-hits",
				"list-worker-blocks",
				"list-workers-with-qualification-type",
				"notify-workers",
				"reject-assignment",
				"reject-qualification-request",
				"send-bonus",
				"send-test-event-notification",
				"update-expiration-for-hit",
				"update-hit-review-status",
				"update-hit-type-of-hit",
				"update-notification-settings",
				"update-qualification-type"
			]
		}
	],
	"neptune": [{
			"name": "neptune"
		},
		{
			"description": "Amazon  Neptune  is a fast, reliable, fully-managed graph database ser-\n       vice that makes it easy to build and run applications  that  work  with\n       highly  connected  datasets.  The  core  of  Amazon  Neptune  is a pur-\n       pose-built, high-performance graph database engine optimized for  stor-\n       ing  billions of relationships and querying the graph with milliseconds\n       latency. Amazon Neptune supports popular graph  models  Property  Graph\n       and  W3C's  RDF,  and their respective query languages Apache TinkerPop\n       Gremlin and SPARQL, allowing you to easily  build  queries  that  effi-\n       ciently  navigate  highly  connected datasets. Neptune powers graph use\n       cases  such  as  recommendation  engines,  fraud  detection,  knowledge\n       graphs, drug discovery, and network security.\n\n       This  interface reference for Amazon Neptune contains documentation for\n       a programming or command line interface you can use  to  manage  Amazon\n       Neptune.  Note  that  Amazon  Neptune is asynchronous, which means that\n       some interfaces might require techniques such as  polling  or  callback\n       functions  to determine when a command has been applied. In this refer-\n       ence, the parameter descriptions indicate whether a command is  applied\n       immediately,  on  the  next  instance reboot, or during the maintenance\n       window. The reference structure is as follows, and  we  list  following\n       some related topics from the user guide.\n          Amazon Neptune API Reference"
		},
		{
			"available commands": [
				"add-role-to-db-cluster",
				"add-source-identifier-to-subscription",
				"add-tags-to-resource",
				"apply-pending-maintenance-action",
				"copy-db-cluster-parameter-group",
				"copy-db-cluster-snapshot",
				"copy-db-parameter-group",
				"create-db-cluster",
				"create-db-cluster-parameter-group",
				"create-db-cluster-snapshot",
				"create-db-instance",
				"create-db-parameter-group",
				"create-db-subnet-group",
				"create-event-subscription",
				"delete-db-cluster",
				"delete-db-cluster-parameter-group",
				"delete-db-cluster-snapshot",
				"delete-db-instance",
				"delete-db-parameter-group",
				"delete-db-subnet-group",
				"delete-event-subscription",
				"describe-db-cluster-parameter-groups",
				"describe-db-cluster-parameters",
				"describe-db-cluster-snapshot-attributes",
				"describe-db-cluster-snapshots",
				"describe-db-clusters",
				"describe-db-engine-versions",
				"describe-db-instances",
				"describe-db-parameter-groups",
				"describe-db-parameters",
				"describe-db-subnet-groups",
				"describe-engine-default-cluster-parameters",
				"describe-engine-default-parameters",
				"describe-event-categories",
				"describe-event-subscriptions",
				"describe-events",
				"describe-orderable-db-instance-options",
				"describe-pending-maintenance-actions",
				"describe-valid-db-instance-modifications",
				"failover-db-cluster",
				"help",
				"list-tags-for-resource",
				"modify-db-cluster",
				"modify-db-cluster-parameter-group",
				"modify-db-cluster-snapshot-attribute",
				"modify-db-instance",
				"modify-db-parameter-group",
				"modify-db-subnet-group",
				"modify-event-subscription",
				"promote-read-replica-db-cluster",
				"reboot-db-instance",
				"remove-role-from-db-cluster",
				"remove-source-identifier-from-subscription",
				"remove-tags-from-resource",
				"reset-db-cluster-parameter-group",
				"reset-db-parameter-group",
				"restore-db-cluster-from-snapshot",
				"restore-db-cluster-to-point-in-time",
				"wait"
			]
		}
	],
	"opsworks": [{
			"name": "opsworks"
		},
		{
			"description": "Welcome  to the AWS OpsWorks Stacks API Reference . This guide provides\n       descriptions, syntax,  and  usage  examples  for  AWS  OpsWorks  Stacks\n       actions and data types, including common parameters and error codes.\n\n       AWS  OpsWorks Stacks is an application management service that provides\n       an integrated experience for overseeing the complete application  life-\n       cycle.  For  information  about  this  product,  go to the AWS OpsWorks\n       details page.\n          SDKs and CLI\n\n       The most common way to use the AWS OpsWorks Stacks API is by using  the\n       AWS  Command  Line  Interface  (CLI) or by using one of the AWS SDKs to\n       implement applications in your preferred language.  For  more  informa-\n       tion, see:\n\n      -AWS CLI\n\n      -AWS SDK for Java\n\n      -AWS SDK for .NET\n\n      -AWS SDK for PHP \n\n      -AWS SDK for Ruby\n\n      -AWS SDK for Node.js\n\n      -AWS SDK for Python(Boto)\n          Endpoints\n\n       AWS  OpsWorks  Stacks  supports the following endpoints, all HTTPS. You\n       must connect to one of the following  endpoints.  Stacks  can  only  be\n       accessed or managed within the endpoint in which they are created.\n\n      -opsworks.us-east-1.amazonaws.com\n\n      opsworks.us-east-2.amazonaws.com\n\n      opsworks.us-west-1.amazonaws.com\n\n      opsworks.us-west-2.amazonaws.com\n\n      opsworks.ca-central-1.amazonaws.com  (API  only; not available in the\n         AWS console)\n\n      opsworks.eu-west-1.amazonaws.com\n\n      opsworks.eu-west-2.amazonaws.com\n\n      opsworks.eu-west-3.amazonaws.com\n\n      opsworks.eu-central-1.amazonaws.com\n\n      opsworks.ap-northeast-1.amazonaws.com\n\n      opsworks.ap-northeast-2.amazonaws.com\n\n      opsworks.ap-south-1.amazonaws.com\n\n      opsworks.ap-southeast-1.amazonaws.com\n\n      opsworks.ap-southeast-2.amazonaws.com\n\n      opsworks.sa-east-1.amazonaws.com\n          Chef Versions\n\n       When you call  create-stack ,  clone-stack , or  update-stack we recom-\n       mend  you  use  the  ConfigurationManager parameter to specify the Chef\n       version. The recommended and default value for  Linux  stacks  is  cur-\n       rently 12. Windows stacks use Chef 12.2. For more information, see Chef\n       Versions .\n\n       NOTE:\n          You can specify Chef 12, 11.10, or 11.4 for  your  Linux  stack.  We\n          recommend migrating your existing Linux stacks to Chef 12 as soon as\n          possible."
		},
		{
			"available commands": [
				"assign-instance",
				"assign-volume",
				"associate-elastic-ip",
				"attach-elastic-load-balancer",
				"clone-stack",
				"create-app",
				"create-deployment",
				"create-instance",
				"create-layer",
				"create-stack",
				"create-user-profile",
				"delete-app",
				"delete-instance",
				"delete-layer",
				"delete-stack",
				"delete-user-profile",
				"deregister-ecs-cluster",
				"deregister-elastic-ip",
				"deregister-instance",
				"deregister-rds-db-instance",
				"deregister-volume",
				"describe-agent-versions",
				"describe-apps",
				"describe-commands",
				"describe-deployments",
				"describe-ecs-clusters",
				"describe-elastic-ips",
				"describe-elastic-load-balancers",
				"describe-instances",
				"describe-layers",
				"describe-load-based-auto-scaling",
				"describe-my-user-profile",
				"describe-operating-systems",
				"describe-permissions",
				"describe-raid-arrays",
				"describe-rds-db-instances",
				"describe-service-errors",
				"describe-stack-provisioning-parameters",
				"describe-stack-summary",
				"describe-stacks",
				"describe-time-based-auto-scaling",
				"describe-user-profiles",
				"describe-volumes",
				"detach-elastic-load-balancer",
				"disassociate-elastic-ip",
				"get-hostname-suggestion",
				"grant-access",
				"help",
				"list-tags",
				"reboot-instance",
				"register",
				"register-ecs-cluster",
				"register-elastic-ip",
				"register-instance",
				"register-rds-db-instance",
				"register-volume",
				"set-load-based-auto-scaling",
				"set-permission",
				"set-time-based-auto-scaling",
				"start-instance",
				"start-stack",
				"stop-instance",
				"stop-stack",
				"tag-resource",
				"unassign-instance",
				"unassign-volume",
				"untag-resource",
				"update-app",
				"update-elastic-ip",
				"update-instance",
				"update-layer",
				"update-my-user-profile",
				"update-rds-db-instance",
				"update-stack",
				"update-user-profile",
				"update-volume",
				"wait"
			]
		}
	],
	"opsworks-cm": [{
			"name": "opsworks-cm"
		},

		{
			"description": "AWS  OpsWorks  for configuration management (CM) is a service that runs and manages configuration management servers.Glossary of terms Server: A configuration management server that can be highly - avail - able.The configuration management server runs on an Amazon Elastic Compute Cloud(EC2) instance,and may use various other AWS services,such as Amazon Relational Database Service(RDS) and Elastic Load Balancing.A server is a generic abstraction over the configuration manager that you want to use, much like Amazon RDS.In AWS OpsWorks CM, you do not start or stop servers.After you create servers, they continue to run until they are deleted."
		},


		{
			"available commands": [
				"associate-node",

				"create-backup",

				"create-server",

				"delete-backup",

				"delete-server",

				"describe-account-attributes",

				"describe-backups",

				"describe-events",

				"describe-node-association-status",

				"describe-servers",

				"disassociate-node",

				"help",

				"restore-server",

				"start-maintenance",

				"update-server",

				"update-server-engine-attributes",

				"wait"
			]
		}
	],
	"organizations": [{
			"name": "organizations"
		},
		{
			"description": "AWS Organizations is a web service that enables you to consolidate your\n       multiple AWS accounts into an organization and  centrally  manage  your\n       accounts and their resources.\n\n       This  guide  provides  descriptions  of the Organizations API. For more\n       information about using this service, see the  AWS  Organizations  User\n       Guide .\n          API Version\n\n       This version of the Organizations API Reference documents the Organiza-\n       tions API version 2016-11-28.\n\n       NOTE:\n          As an alternative to using the API directly, you can use one of  the\n          AWS  SDKs,  which  consist  of libraries and sample code for various\n          programming languages and platforms (Java, Ruby, .NET, iOS, Android,\n          and  more). The SDKs provide a convenient way to create programmatic\n          access to AWS Organizations. For example,  the  SDKs  take  care  of\n          cryptographically  signing  requests,  managing errors, and retrying\n          requests automatically. For more information  about  the  AWS  SDKs,\n          including how to download and install them, see Tools for Amazon Web\n          Services .\n\n       We recommend that you use the AWS SDKs to make programmatic  API  calls\n       to Organizations. However, you also can use the Organizations Query API\n       to make direct calls to the Organizations web service.  To  learn  more\n       about the Organizations Query API, see Making Query Requests in the AWS\n       Organizations User Guide . Organizations supports GET and POST requests\n       for  all  actions. That is, the API does not require you to use GET for\n       some actions and POST for others. However, GET requests are subject  to\n       the  limitation  size  of a URL. Therefore, for operations that require\n       larger sizes, use a POST request.\n          Signing Requests\n\n       When you send HTTP requests to AWS, you must sign the requests so  that\n       AWS  can identify who sent them. You sign requests with your AWS access\n       key, which consists of an access key ID and a  secret  access  key.  We\n       strongly  recommend  that you do not create an access key for your root\n       account. Anyone who has the access key for your root account has  unre-\n       stricted  access  to all the resources in your account. Instead, create\n       an access key for an IAM user account that  has  administrative  privi-\n       leges.  As  another  option, use AWS Security Token Service to generate\n       temporary security credentials,  and  use  those  credentials  to  sign\n       requests.\n\n       To  sign  requests,  we recommend that you use Signature Version 4 . If\n       you have an existing application that uses Signature Version 2, you  do\n       not  have to update it to use Signature Version 4. However, some opera-\n       tions now require Signature Version 4. The documentation for operations\n       that require version 4 indicate this requirement.\n\n       When you use the AWS Command Line Interface (AWS CLI) or one of the AWS\n       SDKs to make requests  to  AWS,  these  tools  automatically  sign  the\n       requests  for you with the access key that you specify when you config-\n       ure the tools.\n\n       In this release, each organization can have only one root. In a  future\n       release, a single organization will support multiple roots.\n          Support and Feedback for AWS Organizations\n\n       We     welcome     your     feedback.    Send    your    comments    to\n       feedback-awsorganizations@amazon.com or post your  feedback  and  ques-\n       tions  in  the  AWS  Organizations support forum . For more information\n       about the AWS support forums, see Forums Help .\n          Endpoint to Call When Using the CLI or the AWS API\n\n       For  the  current  release  of  Organizations,  you  must  specify  the\n       us-east-1  region for all AWS API and CLI calls. You can do this in the\n       CLI by using these parameters and commands:\n\n      Use the following parameter with each command  to  specify  both  the\n         endpoint    and   its   region:    --endpoint-url   https\n         tions.us-east-1.amazonaws.com\n\n      Use the default endpoint, but configure your default region with this\n         command:  aws configure set default.region us-east-1\n\n      Use  the  following  parameter  with each command to specify the end-\n         point:  --region us-east-1\n\n       For the various SDKs used to call the APIs, see the  documentation  for\n       the  SDK  of interest to learn how to direct the requests to a specific\n       endpoint. For more information, see Regions and Endpoints  in  the  AWS\n       General Reference .\n          How examples are presented\n\n       The  JSON returned by the AWS Organizations service as response to your\n       requests is returned as a single long string  without  line  breaks  or\n       formatting  whitespace. Both line breaks and whitespace are included in\n       the examples in this guide to improve readability. When  example  input\n       parameters  also  would result in long strings that would extend beyond\n       the screen, we insert line breaks to enhance  readability.  You  should\n       always submit the input as a single JSON text string.\n          Recording API Requests\n\n       AWS  Organizations  supports AWS CloudTrail, a service that records AWS\n       API calls for your AWS account and delivers log files to an  Amazon  S3\n       bucket.  By  using  information  collected  by  AWS CloudTrail, you can\n       determine which requests were successfully made to  Organizations,  who\n       made the request, when it was made, and so on. For more about AWS Orga-\n       nizations and its support for AWS CloudTrail, see Logging AWS Organiza-\n       tions  Events with AWS CloudTrail in the AWS Organizations User Guide .\n       To learn more about CloudTrail, including how to turn it  on  and  find\n       your log files, see the AWS CloudTrail User Guide ."
		},
		{
			"available commands": [
				"accept-handshake",
				"attach-policy",
				"cancel-handshake",
				"create-account",
				"create-organization",
				"create-organizational-unit",
				"create-policy",
				"decline-handshake",
				"delete-organization",
				"delete-organizational-unit",
				"delete-policy",
				"describe-account",
				"describe-create-account-status",
				"describe-handshake",
				"describe-organization",
				"describe-organizational-unit",
				"describe-policy",
				"detach-policy",
				"disable-aws-service-access",
				"disable-policy-type",
				"enable-all-features",
				"enable-aws-service-access",
				"enable-policy-type",
				"help",
				"invite-account-to-organization",
				"leave-organization",
				"list-accounts",
				"list-accounts-for-parent",
				"list-aws-service-access-for-organization",
				"list-children",
				"list-create-account-status",
				"list-handshakes-for-account",
				"list-handshakes-for-organization",
				"list-organizational-units-for-parent",
				"list-parents",
				"list-policies",
				"list-policies-for-target",
				"list-roots",
				"list-targets-for-policy",
				"move-account",
				"remove-account-from-organization",
				"update-organizational-unit",
				"update-policy"
			]
		}
	],
	"pi": [{
			"name": "pi"
		},
		{
			"description": "AWS  Performance  Insights enables you to monitor and explore different\n       dimensions of database load based on data captured from a  running  RDS\n       instance.  The  guide  provides  detailed information about Performance\n       Insights data types, parameters and errors. For more information  about\n       Performance  Insights  capabilities  see  Using  Amazon RDS Performance\n       Insights in the Amazon RDS User Guide .\n\n       The AWS Performance Insights API provides visibility into  the  perfor-\n       mance  of  your  RDS instance, when Performance Insights is enabled for\n       supported engine types. While Amazon CloudWatch provides the authorita-\n       tive  source for AWS service vended monitoring metrics, AWS Performance\n       Insights offers a domain-specific view of  database  load  measured  as\n       Average  Active  Sessions  and  provided to API consumers as a 2-dimen-\n       sional time-series dataset. The time dimension of the data provides  DB\n       load  data for each time point in the queried time range, and each time\n       point decomposes overall load in relation to the requested  dimensions,\n       such as SQL, Wait-event, User or Host, measured at that time point."
		},
		{
			"available commands": [
				"describe-dimension-keys",
				"get-resource-metrics",
				"help"
			]
		}
	],
	"pinpoint": [{
			"name": "pinpoint"
		},
		{
			"description": "Amazon Pinpoint"
		},
		{
			"available commands": [
				"create-app",
				"create-campaign",
				"create-export-job",
				"create-import-job",
				"create-segment",
				"delete-adm-channel",
				"delete-apns-channel",
				"delete-apns-sandbox-channel",
				"delete-apns-voip-channel",
				"delete-apns-voip-sandbox-channel",
				"delete-app",
				"delete-baidu-channel",
				"delete-campaign",
				"delete-email-channel",
				"delete-endpoint",
				"delete-event-stream",
				"delete-gcm-channel",
				"delete-segment",
				"delete-sms-channel",
				"delete-user-endpoints",
				"get-adm-channel",
				"get-apns-channel",
				"get-apns-sandbox-channel",
				"get-apns-voip-channel",
				"get-apns-voip-sandbox-channel",
				"get-app",
				"get-application-settings",
				"get-apps",
				"get-baidu-channel",
				"get-campaign",
				"get-campaign-activities",
				"get-campaign-version",
				"get-campaign-versions",
				"get-campaigns",
				"get-channels",
				"get-email-channel",
				"get-endpoint",
				"get-event-stream",
				"get-export-job",
				"get-export-jobs",
				"get-gcm-channel",
				"get-import-job",
				"get-import-jobs",
				"get-segment",
				"get-segment-export-jobs",
				"get-segment-import-jobs",
				"get-segment-version",
				"get-segment-versions",
				"get-segments",
				"get-sms-channel",
				"get-user-endpoints",
				"help",
				"phone-number-validate",
				"put-event-stream",
				"remove-attributes",
				"send-messages",
				"send-users-messages",
				"update-adm-channel",
				"update-apns-channel",
				"update-apns-sandbox-channel",
				"update-apns-voip-channel",
				"update-apns-voip-sandbox-channel",
				"update-application-settings",
				"update-baidu-channel",
				"update-campaign",
				"update-email-channel",
				"update-endpoint",
				"update-endpoints-batch",
				"update-gcm-channel",
				"update-segment",
				"update-sms-channel"
			]
		}
	],
	"polly": [{
			"name": "polly"
		},
		{
			"description": "Amazon  Polly  is a web service that makes it easy to synthesize speech\n       from text.\n\n       The Amazon Polly  service  provides  API  operations  for  synthesizing\n       high-quality  speech  from  plain text and Speech Synthesis Markup Lan-\n       guage (SSML), along with managing pronunciations lexicons  that  enable\n       you to get the best results for your application domain."
		},
		{
			"available commands": [
				"delete-lexicon",
				"describe-voices",
				"get-lexicon",
				"help",
				"list-lexicons",
				"put-lexicon",
				"synthesize-speech"
			]
		}
	],
	"pricing": [{
			"name": "pricing"
		},
		{
			"description": "AWS  Price  List  Service API (AWS Price List Service) is a centralized\n       and convenient way to programmatically query Amazon  Web  Services  for\n       services, products, and pricing information. The AWS Price List Service\n       uses standardized product attributes such as Location , Storage Class ,\n       and  Operating  System  , and provides prices at the SKU level. You can\n       use the AWS Price List Service to build cost control and scenario plan-\n       ning tools, reconcile billing data, forecast future spend for budgeting\n       purposes, and provide cost benefit analysis that compare your  internal\n       workloads with AWS.\n\n       Use  GetServices  without  a service code to retrieve the service codes\n       for all AWS services, then GetServices with a service code to  retreive\n       the  attribute  names for that service. After you have the service code\n       and attribute names, you can use get-attribute-values to see what  val-\n       ues  are  available  for  an  attribute.  With  the service code and an\n       attribute name and value, you can use  get-products  to  find  specific\n       products that you're interested in, such as an AmazonEC2 instance, with\n       a Provisioned IOPS  volumeType .\n\n       Service Endpoint\n\n       AWS Price List Service API provides the following two endpoints:\n\n        https://api.pricing.us-east-1.amazonaws.com\n\n        https://api.pricing.ap-south-1.amazonaws.com"
		},
		{
			"available commands": [
				"describe-services",
				"get-attribute-values",
				"get-products",
				"help"
			]
		}
	],
	"rds": [{
			"name": "rds"
		},
		{
			"description": "Amazon  Relational  Database Service (Amazon RDS) is a web service that\n       makes it easier to set up, operate, and scale a relational database  in\n       the cloud. It provides cost-efficient, resizable capacity for an indus-\n       try-standard relational database and manages common  database  adminis-\n       tration  tasks,  freeing  up  developers  to  focus on what makes their\n       applications and businesses unique.\n\n       Amazon RDS gives you access to the capabilities of  a  MySQL,  MariaDB,\n       PostgreSQL,  Microsoft  SQL  Server,  Oracle, or Amazon Aurora database\n       server. These capabilities mean that the code, applications, and  tools\n       you already use today with your existing databases work with Amazon RDS\n       without modification. Amazon RDS automatically backs up  your  database\n       and  maintains the database software that powers your DB instance. Ama-\n       zon RDS is flexible: you can scale your DB instance's compute resources\n       and  storage  capacity  to  meet your application's demand. As with all\n       Amazon Web Services, there are no up-front  investments,  and  you  pay\n       only for the resources you use.\n\n       This  interface  reference  for Amazon RDS contains documentation for a\n       programming or command line interface you can use to manage Amazon RDS.\n       Note  that Amazon RDS is asynchronous, which means that some interfaces\n       might require techniques such  as  polling  or  callback  functions  to\n       determine  when  a  command  has  been  applied. In this reference, the\n       parameter descriptions indicate whether a command  is  applied  immedi-\n       ately,  on  the next instance reboot, or during the maintenance window.\n       The reference structure is as  follows,  and  we  list  following  some\n       related topics from the user guide.\n          Amazon RDS API Reference\n\n      For the alphabetical list of API actions, see API Actions .\n\n      For the alphabetical list of data types, see Data Types .\n\n      For a list of common query parameters, see Common Parameters .\n\n      For descriptions of the error codes, see Common Errors .\n          Amazon RDS User Guide\n\n      For  a summary of the Amazon RDS interfaces, see Available RDS Inter-\n         faces .\n\n      For more information about how to use the Query API,  see  Using  the\n         Query API ."
		},
		{
			"available commands": [
				"add-option-to-option-group",
				"add-role-to-db-cluster",
				"add-source-identifier-to-subscription",
				"add-tags-to-resource",
				"apply-pending-maintenance-action",
				"authorize-db-security-group-ingress",
				"backtrack-db-cluster",
				"copy-db-cluster-parameter-group",
				"copy-db-cluster-snapshot",
				"copy-db-parameter-group",
				"copy-db-snapshot",
				"copy-option-group",
				"create-db-cluster",
				"create-db-cluster-parameter-group",
				"create-db-cluster-snapshot",
				"create-db-instance",
				"create-db-instance-read-replica",
				"create-db-parameter-group",
				"create-db-security-group",
				"create-db-snapshot",
				"create-db-subnet-group",
				"create-event-subscription",
				"create-option-group",
				"delete-db-cluster",
				"delete-db-cluster-parameter-group",
				"delete-db-cluster-snapshot",
				"delete-db-instance",
				"delete-db-parameter-group",
				"delete-db-security-group",
				"delete-db-snapshot",
				"delete-db-subnet-group",
				"delete-event-subscription",
				"delete-option-group",
				"describe-account-attributes",
				"describe-certificates",
				"describe-db-cluster-backtracks",
				"describe-db-cluster-parameter-groups",
				"describe-db-cluster-parameters",
				"describe-db-cluster-snapshot-attributes",
				"describe-db-cluster-snapshots",
				"describe-db-clusters",
				"describe-db-engine-versions",
				"describe-db-instances",
				"describe-db-log-files",
				"describe-db-parameter-groups",
				"describe-db-parameters",
				"describe-db-security-groups",
				"describe-db-snapshot-attributes",
				"describe-db-snapshots",
				"describe-db-subnet-groups",
				"describe-engine-default-cluster-parameters",
				"describe-engine-default-parameters",
				"describe-event-categories",
				"describe-event-subscriptions",
				"describe-events",
				"describe-option-group-options",
				"describe-option-groups",
				"describe-orderable-db-instance-options",
				"describe-pending-maintenance-actions",
				"describe-reserved-db-instances",
				"describe-reserved-db-instances-offerings",
				"describe-source-regions",
				"describe-valid-db-instance-modifications",
				"download-db-log-file-portion",
				"failover-db-cluster",
				"generate-db-auth-token",
				"help",
				"list-tags-for-resource",
				"modify-db-cluster",
				"modify-db-cluster-parameter-group",
				"modify-db-cluster-snapshot-attribute",
				"modify-db-instance",
				"modify-db-parameter-group",
				"modify-db-snapshot",
				"modify-db-snapshot-attribute",
				"modify-db-subnet-group",
				"modify-event-subscription",
				"promote-read-replica",
				"promote-read-replica-db-cluster",
				"purchase-reserved-db-instances-offering",
				"reboot-db-instance",
				"remove-option-from-option-group",
				"remove-role-from-db-cluster",
				"remove-source-identifier-from-subscription",
				"remove-tags-from-resource",
				"reset-db-cluster-parameter-group",
				"reset-db-parameter-group",
				"restore-db-cluster-from-s3",
				"restore-db-cluster-from-snapshot",
				"restore-db-cluster-to-point-in-time",
				"restore-db-instance-from-db-snapshot",
				"restore-db-instance-from-s3",
				"restore-db-instance-to-point-in-time",
				"revoke-db-security-group-ingress",
				"start-db-instance",
				"stop-db-instance",
				"wait"
			]
		}
	],
	"redshift": [{
			"name": "redshift"
		},
		{
			"description": "Overview\n\n       This  is  an interface reference for Amazon Redshift. It contains docu-\n       mentation for one of the programming or command line interfaces you can\n       use  to  manage  Amazon Redshift clusters. Note that Amazon Redshift is\n       asynchronous, which means that some interfaces may require  techniques,\n       such  as polling or asynchronous callback handlers, to determine when a\n       command has been applied. In this reference, the parameter descriptions\n       indicate  whether a change is applied immediately, on the next instance\n       reboot, or during the next maintenance window. For  a  summary  of  the\n       Amazon  Redshift  cluster management interfaces, go to Using the Amazon\n       Redshift Management Interfaces .\n\n       Amazon Redshift manages all the work  of  setting  up,  operating,  and\n       scaling a data warehouse: provisioning capacity, monitoring and backing\n       up the cluster, and applying patches and upgrades to  the  Amazon  Red-\n       shift  engine. You can focus on using your data to acquire new insights\n       for your business and customers.\n\n       If you are a first-time user of Amazon Redshift, we recommend that  you\n       begin by reading the Amazon Redshift Getting Started Guide .\n\n       If you are a database developer, the Amazon Redshift Database Developer\n       Guide explains how to design, build, query, and maintain the  databases\n       that make up your data warehouse."
		},
		{
			"available commands": [
				"accept-reserved-node-exchange",
				"authorize-cluster-security-group-ingress",
				"authorize-snapshot-access",
				"copy-cluster-snapshot",
				"create-cluster",
				"create-cluster-parameter-group",
				"create-cluster-security-group",
				"create-cluster-snapshot",
				"create-cluster-subnet-group",
				"create-event-subscription",
				"create-hsm-client-certificate",
				"create-hsm-configuration",
				"create-snapshot-copy-grant",
				"create-tags",
				"delete-cluster",
				"delete-cluster-parameter-group",
				"delete-cluster-security-group",
				"delete-cluster-snapshot",
				"delete-cluster-subnet-group",
				"delete-event-subscription",
				"delete-hsm-client-certificate",
				"delete-hsm-configuration",
				"delete-snapshot-copy-grant",
				"delete-tags",
				"describe-cluster-db-revisions",
				"describe-cluster-parameter-groups",
				"describe-cluster-parameters",
				"describe-cluster-security-groups",
				"describe-cluster-snapshots",
				"describe-cluster-subnet-groups",
				"describe-cluster-versions",
				"describe-clusters",
				"describe-default-cluster-parameters",
				"describe-event-categories",
				"describe-event-subscriptions",
				"describe-events",
				"describe-hsm-client-certificates",
				"describe-hsm-configurations",
				"describe-logging-status",
				"describe-orderable-cluster-options",
				"describe-reserved-node-offerings",
				"describe-reserved-nodes",
				"describe-resize",
				"describe-snapshot-copy-grants",
				"describe-table-restore-status",
				"describe-tags",
				"disable-logging",
				"disable-snapshot-copy",
				"enable-logging",
				"enable-snapshot-copy",
				"get-cluster-credentials",
				"get-reserved-node-exchange-offerings",
				"help",
				"modify-cluster",
				"modify-cluster-db-revision",
				"modify-cluster-iam-roles",
				"modify-cluster-parameter-group",
				"modify-cluster-subnet-group",
				"modify-event-subscription",
				"modify-snapshot-copy-retention-period",
				"purchase-reserved-node-offering",
				"reboot-cluster",
				"reset-cluster-parameter-group",
				"restore-from-cluster-snapshot",
				"restore-table-from-cluster-snapshot",
				"revoke-cluster-security-group-ingress",
				"revoke-snapshot-access",
				"rotate-encryption-key",
				"wait"
			]
		}
	],
	"rekognition": [{
			"name": "rekognition"
		},
		{
			"description": "This is the Amazon Rekognition API reference."
		},
		{
			"available commands": [
				"compare-faces",
				"create-collection",
				"create-stream-processor",
				"delete-collection",
				"delete-faces",
				"delete-stream-processor",
				"describe-stream-processor",
				"detect-faces",
				"detect-labels",
				"detect-moderation-labels",
				"detect-text",
				"get-celebrity-info",
				"get-celebrity-recognition",
				"get-content-moderation",
				"get-face-detection",
				"get-face-search",
				"get-label-detection",
				"get-person-tracking",
				"help",
				"index-faces",
				"list-collections",
				"list-faces",
				"list-stream-processors",
				"recognize-celebrities",
				"search-faces",
				"search-faces-by-image",
				"start-celebrity-recognition",
				"start-content-moderation",
				"start-face-detection",
				"start-face-search",
				"start-label-detection",
				"start-person-tracking",
				"start-stream-processor",
				"stop-stream-processor"
			]
		}
	],
	"resource-groups": [{
			"name": "resource-groups"
		},
		{
			"description": "AWS  Resource Groups lets you organize AWS resources such as Amazon EC2\n       instances, Amazon Relational Database Service databases, and Amazon  S3\n       buckets  into groups using criteria that you define as tags. A resource\n       group is a collection of resources that match the resource types speci-\n       fied  in  a  query, and share one or more tags or portions of tags. You\n       can create a group of resources based on their roles in your cloud  in-\n       frastructure,  lifecycle stages, regions, application layers, or virtu-\n       ally any criteria. Resource groups enable you  to  automate  management\n       tasks,  such  as  those in AWS Systems Manager Automation documents, on\n       tag-related  resources  in  AWS  Systems  Manager.  Groups  of   tagged\n       resources  also  let  you  quickly view a custom console in AWS Systems\n       Manager that shows AWS Config  compliance  and  other  monitoring  data\n       about member resources.\n\n       To  create  a  resource group, build a resource query, and specify tags\n       that identify the criteria that members of the group  have  in  common.\n       Tags are key-value pairs.\n\n       For more information about Resource Groups, see the AWS Resource Groups\n       User Guide .\n\n       AWS Resource Groups uses a REST-compliant API that you can use to  per-\n       form the following types of operations.\n\n      Create, Read, Update, and Delete (CRUD) operations on resource groups\n         and resource query entities\n\n      Applying, editing, and removing tags from resource groups\n\n      Resolving resource group member ARNs  so  they  can  be  returned  as\n         search results\n\n      Getting data about resources that are members of a group\n\n      Searching AWS resources based on a resource query"
		},
		{
			"available commands": [
				"create-group",
				"delete-group",
				"get-group",
				"get-group-query",
				"get-tags",
				"help",
				"list-group-resources",
				"list-groups",
				"search-resources",
				"tag",
				"untag",
				"update-group",
				"update-group-query"
			]
		}
	],
	"resourcegroupstaggingapi": [{
			"name": "resourcegroupstaggingapi"
		},
		{
			"description": "This  guide  describes  the API operations for the resource groups tag-\n       ging.\n\n       A tag is a label that you assign to an AWS resource. A tag consists  of\n       a  key  and a value, both of which you define. For example, if you have\n       two Amazon EC2 instances, you might assign both a tag key  of  'Stack'\n       But  the  value  of 'Stack' might be 'Testing' for one and 'Production'\n       for the other.\n\n       Tagging can help you organize your resources and enables  you  to  sim-\n       plify  resource  management, access management and cost allocation. For\n       more information about tagging, see Working with Tag Editor and Working\n       with  Resource Groups . For more information about permissions you need\n       to use the resource groups tagging APIs, see Obtaining Permissions  for\n       Resource Groups and Obtaining Permissions for Tagging .\n\n       You  can use the resource groups tagging APIs to complete the following\n       tasks:\n\n      Tag and untag supported resources located in the specified region for\n         the AWS account\n\n      Use  tag-based  filters to search for resources located in the speci-\n         fied region for the AWS account\n\n      List all existing tag keys  in  the  specified  region  for  the  AWS\n         account\n\n      List  all  existing  values  for  the  specified key in the specified\n         region for the AWS account\n\n       Not all resources can have tags. For a lists of resources that you  can\n       tag,  see Supported Resources in the AWS Resource Groups and Tag Editor\n       User Guide .\n\n       To make full use of the resource groups tagging APIs,  you  might  need\n       additional   IAM   permissions,  including  permission  to  access  the\n       resources of individual services as well  as  permission  to  view  and\n       apply tags to those resources. For more information, see Obtaining Per-\n       missions for Tagging in the AWS Resource Groups  and  Tag  Editor  User\n       Guide ."
		},
		{
			"available commands": [
				"get-resources",
				"get-tag-keys",
				"get-tag-values",
				"help",
				"tag-resources",
				"untag-resources"
			]
		}
	],
	"route53": [{
			"name": "route53"
		},
		{
			"description": "None"
		},
		{
			"available commands": [
				"associate-vpc-with-hosted-zone",
				"change-resource-record-sets",
				"change-tags-for-resource",
				"create-health-check",
				"create-hosted-zone",
				"create-query-logging-config",
				"create-reusable-delegation-set",
				"create-traffic-policy",
				"create-traffic-policy-instance",
				"create-traffic-policy-version",
				"create-vpc-association-authorization",
				"delete-health-check",
				"delete-hosted-zone",
				"delete-query-logging-config",
				"delete-reusable-delegation-set",
				"delete-traffic-policy",
				"delete-traffic-policy-instance",
				"delete-vpc-association-authorization",
				"disassociate-vpc-from-hosted-zone",
				"get-account-limit",
				"get-change",
				"get-checker-ip-ranges",
				"get-geo-location",
				"get-health-check",
				"get-health-check-count",
				"get-health-check-last-failure-reason",
				"get-health-check-status",
				"get-hosted-zone",
				"get-hosted-zone-count",
				"get-hosted-zone-limit",
				"get-query-logging-config",
				"get-reusable-delegation-set",
				"get-reusable-delegation-set-limit",
				"get-traffic-policy",
				"get-traffic-policy-instance",
				"get-traffic-policy-instance-count",
				"help",
				"list-geo-locations",
				"list-health-checks",
				"list-hosted-zones",
				"list-hosted-zones-by-name",
				"list-query-logging-configs",
				"list-resource-record-sets",
				"list-reusable-delegation-sets",
				"list-tags-for-resource",
				"list-tags-for-resources",
				"list-traffic-policies",
				"list-traffic-policy-instances",
				"list-traffic-policy-instances-by-hosted-zone",
				"list-traffic-policy-instances-by-policy",
				"list-traffic-policy-versions",
				"list-vpc-association-authorizations",
				"test-dns-answer",
				"update-health-check",
				"update-hosted-zone-comment",
				"update-traffic-policy-comment",
				"update-traffic-policy-instance",
				"wait"
			]
		}
	],
	"route53domains": [{
			"name": "route53domains"
		},
		{
			"description": "Amazon  Route  53 API actions let you register domain names and perform\n       related operations."
		},
		{
			"available commands": [
				"check-domain-availability",
				"check-domain-transferability",
				"delete-tags-for-domain",
				"disable-domain-auto-renew",
				"disable-domain-transfer-lock",
				"enable-domain-auto-renew",
				"enable-domain-transfer-lock",
				"get-contact-reachability-status",
				"get-domain-detail",
				"get-domain-suggestions",
				"get-operation-detail",
				"help",
				"list-domains",
				"list-operations",
				"list-tags-for-domain",
				"register-domain",
				"renew-domain",
				"resend-contact-reachability-email",
				"retrieve-domain-auth-code",
				"transfer-domain",
				"update-domain-contact",
				"update-domain-contact-privacy",
				"update-domain-nameservers",
				"update-tags-for-domain",
				"view-billing"
			]
		}
	],
	"s3": [{
			"name": "s3"
		},
		{
			"description": "<This  section  explains  prominent concepts and notations in the set of\n       high-level S3 commands provided.\n\n   Path Argument Type\n       Whenever using a command, at least one path argument must be specified.\n       There are two types of path arguments: LocalPath and S3Uri.\n\n       LocalPath: represents the path of a local file or directory.  It can be\n       written as an absolute path or relative path.\n\n       S3Uri: represents the location of a S3 object, prefix, or bucket.  This\n       must  be  written in the form s3://mybucket/mykey where mybucket is the\n       specified S3 bucket, mykey is the specified S3 key.  The path  argument\n       must  begin with s3:// in order to denote that the path argument refers\n       to a S3 object. Note that prefixes are separated  by  forward  slashes.\n       For  example, if the S3 object myobject had the prefix myprefix, the S3\n       key would be myprefix/myobject, and if the object  was  in  the  bucket\n       mybucket, the S3Uri would be s3://mybucket/myprefix/myobject.\n\n   Order of Path Arguments\n       Every  command  takes  one or two positional path arguments.  The first\n       path argument represents the source, which is the local  file/directory\n       or  S3  object/prefix/bucket  that  is being referenced.  If there is a\n       second path argument, it represents the destination, which is the local\n       file/directory  or  S3  object/prefix/bucket that is being operated on.\n       Commands with only one path argument do not have a destination  because\n       the operation is being performed only on the source.\n\n   Single Local File and S3 Object Operations\n       Some  commands  perform operations only on single files and S3 objects.\n       The following commands are single file/object operations if no --recur-\n       sive flag is provided.\n\n         'cp',\n\n         'mv',\n\n         'rm'\n\n       For  this  type of operation, the first path argument, the source, must\n       exist and be a local file or S3 object.  The second path argument,  the\n       destination,  can  be  the  name  of  a local file, local directory, S3\n       object, S3 prefix, or S3 bucket.\n\n       The destination is indicated as a local directory,  S3  prefix,  or  S3\n       bucket if it ends with a forward slash or back slash.  The use of slash\n       depends on the path argument type.  If the path argument  is  a  Local-\n       Path,  the type of slash is the separator used by the operating system.\n       If the path is a S3Uri, the forward slash must always be  used.   If  a\n       slash  is at the end of the destination, the destination file or object\n       will adopt the name of the source file or object.  Otherwise, if  there\n       is no slash at the end, the file or object will be saved under the name\n       provided.  See examples in cp and mv to illustrate this description.\n\n   Directory and S3 Prefix Operations\n       Some commands only perform operations on the contents of a local direc-\n       tory  or  S3 prefix/bucket.  Adding or omitting a forward slash or back\n       slash to the end of any path argument, depending on its type, does  not\n       affect  the  results  of  the  operation.   The following commands will\n       always result in a directory or S3 prefix/bucket operation:\n\n      'sync',\n\n      'mb',\n\n      'rb',\n\n      'ls'\n\n   Use of Exclude and Include Filters\n       Currently, there is no support for the use of UNIX style wildcards in a\n       command's  path  arguments.   However,  most  commands  have  --exclude\n       '<value>'' and --include  '<value>'' parameters  that  can  achieve  the\n       desired  result.   These  parameters perform pattern matching to either\n       exclude or include a particular file or object.  The following  pattern\n       symbols are supported.\n\n         *: Matches everything,\n\n         ?: Matches any single character,\n\n         '[sequence]: Matches any character in sequence',\n\n         '[!sequence]: Matches any character not in sequence'\n\n       Any  number of these parameters can be passed to a command.  You can do\n       this by providing an --exclude or --include  argument  multiple  times,\n       e.g.   --include  '*.txt'  --include  '*.png'.  When there are multiple\n       filters, the rule is the filters that appear later in the command  take\n       precedence  over filters that appear earlier in the command.  For exam-\n       ple, if the filter parameters passed to the command were\n\n          --exclude '*'' --include '*.txt'\n\n       All files will be excluded from the command  except  for  files  ending\n       with  .txt   However, if the order of the filter parameters was changed\n       to\n\n          --include '*.txt' --exclude '*''\n\n       All files will be excluded from the command.\n\n       Each filter is evaluated against the source directory.  If  the  source\n       location is a file instead of a directory, the directory containing the\n       file is used as the source directory.  For example, suppose you had the\n       following directory structure:\n\n          /tmp/foo/\n            .git/\n            |---config\n            |---description\n            foo.txt\n            bar.txt\n            baz.jpg\n\n       In  the  command aws s3 sync /tmp/foo s3://bucket/ the source directory\n       is /tmp/foo.  Any include/exclude filters will be  evaluated  with  the\n       source  directory prepended.  Below are several examples to demonstrate\n       this.\n\n       Given the directory structure above and the command aws s3 cp  /tmp/foo\n      's3://bucket/  --recursive --exclude '.git/*', the files .git/config and\n       .git/description will be excluded from the files to upload because  the\n       exclude  filter  .git/*  will  have the source prepended to the filter.\n       This means that:\n\n          /tmp/foo/.git/* -> /tmp/foo/.git/config       (matches, should exclude)\n          /tmp/foo/.git/* -> /tmp/foo/.git/description  (matches, should exclude)\n          /tmp/foo/.git/* -> /tmp/foo/foo.txt  (does not match, should include)\n          /tmp/foo/.git/* -> /tmp/foo/bar.txt  (does not match, should include)\n          /tmp/foo/.git/* -> /tmp/foo/baz.jpg  (does not match, should include)\n\n       The command aws s3  cp  /tmp/foo/  s3://bucket/  --recursive  --exclude\n       'ba*' will exclude /tmp/foo/bar.txt and /tmp/foo/baz.jpg:\n\n          /tmp/foo/ba* -> /tmp/foo/.git/config      (does not match, should include)\n          /tmp/foo/ba* -> /tmp/foo/.git/description (does not match, should include)\n          /tmp/foo/ba* -> /tmp/foo/foo.txt          (does not match, should include)\n          /tmp/foo/ba* -> /tmp/foo/bar.txt  (matches, should exclude)\n          /tmp/foo/ba* -> /tmp/foo/baz.jpg  (matches, should exclude)\n\n       Note that, by default, all files are included.  This means that provid-\n       ing only an --include filter will not  change  what  files  are  trans-\n       ferred.   --include  will only re-include files that have been excluded\n       from an --exclude filter.  If you only want to upload files with a par-\n       ticular extension, you need to first exclude all files, then re-include\n       the files with the particular extension.  This command will upload only\n       files ending with .jpg:\n\n          aws s3 cp /tmp/foo/ s3://bucket/ --recursive --exclude '*' --include '*.jpg'\n\n       If  you wanted to include both .jpg files as well as .txt files you can\n       run:\n\n      \n              --exclude *'' --include '*.jpg' --include '*.txt'\n\n       See 'aws help' for descriptions of global parameters.</p>"
		},
		{
			"synopsis": "aws s3 <Command> [<Arg> ..."
		},
		{
			"options": "None"
		},
		{
			"available commands": [
				"cp",
				"ls",
				"mb",
				"mv",
				"presign",
				"rb",
				"rm",
				"sync",
				"website"
			]
		}
	],
	"s3api": [{
			"name": "s3api"
		},
		{
			"description": "None"
		},
		{
			"available commands": [
				"abort-multipart-upload",
				"complete-multipart-upload",
				"copy-object",
				"create-bucket",
				"create-multipart-upload",
				"delete-bucket",
				"delete-bucket-analytics-configuration",
				"delete-bucket-cors",
				"delete-bucket-encryption",
				"delete-bucket-inventory-configuration",
				"delete-bucket-lifecycle",
				"delete-bucket-metrics-configuration",
				"delete-bucket-policy",
				"delete-bucket-replication",
				"delete-bucket-tagging",
				"delete-bucket-website",
				"delete-object",
				"delete-object-tagging",
				"delete-objects",
				"get-bucket-accelerate-configuration",
				"get-bucket-acl",
				"get-bucket-analytics-configuration",
				"get-bucket-cors",
				"get-bucket-encryption",
				"get-bucket-inventory-configuration",
				"get-bucket-lifecycle-configuration",
				"get-bucket-location",
				"get-bucket-logging",
				"get-bucket-metrics-configuration",
				"get-bucket-notification-configuration",
				"get-bucket-policy",
				"get-bucket-replication",
				"get-bucket-request-payment",
				"get-bucket-tagging",
				"get-bucket-versioning",
				"get-bucket-website",
				"get-object",
				"get-object-acl",
				"get-object-tagging",
				"get-object-torrent",
				"head-bucket",
				"head-object",
				"help",
				"list-bucket-analytics-configurations",
				"list-bucket-inventory-configurations",
				"list-bucket-metrics-configurations",
				"list-buckets",
				"list-multipart-uploads",
				"list-object-versions",
				"list-objects",
				"list-objects-v2",
				"list-parts",
				"put-bucket-accelerate-configuration",
				"put-bucket-acl",
				"put-bucket-analytics-configuration",
				"put-bucket-cors",
				"put-bucket-encryption",
				"put-bucket-inventory-configuration",
				"put-bucket-lifecycle-configuration",
				"put-bucket-logging",
				"put-bucket-metrics-configuration",
				"put-bucket-notification-configuration",
				"put-bucket-policy",
				"put-bucket-replication",
				"put-bucket-request-payment",
				"put-bucket-tagging",
				"put-bucket-versioning",
				"put-bucket-website",
				"put-object",
				"put-object-acl",
				"put-object-tagging",
				"restore-object",
				"select-object-content",
				"upload-part",
				"upload-part-copy",
				"wait"
			]
		}
	],
	"sagemaker": [{
			"name": "sagemaker"
		},
		{
			"description": "Definition of the public APIs exposed by SageMaker"
		},
		{
			"available commands": [
				"add-tags",
				"create-endpoint",
				"create-endpoint-config",
				"create-hyper-parameter-tuning-job",
				"create-model",
				"create-notebook-instance",
				"create-notebook-instance-lifecycle-config",
				"create-presigned-notebook-instance-url",
				"create-training-job",
				"delete-endpoint",
				"delete-endpoint-config",
				"delete-model",
				"delete-notebook-instance",
				"delete-notebook-instance-lifecycle-config",
				"delete-tags",
				"describe-endpoint",
				"describe-endpoint-config",
				"describe-hyper-parameter-tuning-job",
				"describe-model",
				"describe-notebook-instance",
				"describe-notebook-instance-lifecycle-config",
				"describe-training-job",
				"help",
				"list-endpoint-configs",
				"list-endpoints",
				"list-hyper-parameter-tuning-jobs",
				"list-models",
				"list-notebook-instance-lifecycle-configs",
				"list-notebook-instances",
				"list-tags",
				"list-training-jobs",
				"list-training-jobs-for-hyper-parameter-tuning-job",
				"start-notebook-instance",
				"stop-hyper-parameter-tuning-job",
				"stop-notebook-instance",
				"stop-training-job",
				"update-endpoint",
				"update-endpoint-weights-and-capacities",
				"update-notebook-instance",
				"update-notebook-instance-lifecycle-config",
				"wait"
			]
		}
	],
	"sagemaker-runtime": [{
			"name": "sagemaker-runtime"
		},
		{
			"description": "Amazon SageMaker runtime API."
		},
		{
			"available commands": [
				"help",
				"invoke-endpoint"
			]
		}
	],
	"sdb": [{
			"name": "sdb"
		},
		{
			"description": "Amazon  SimpleDB is a web service providing the core database functions\n       of data indexing and querying in the cloud. By offloading the time  and\n       effort  associated  with  building  and operating a web-scale database,\n       SimpleDB provides developers the freedom to focus on application devel-\n       opment.\n\n       A traditional, clustered relational database requires a sizable upfront\n       capital outlay, is complex to design, and often requires extensive  and\n       repetitive  database  administration.  Amazon  SimpleDB is dramatically\n       simpler, requiring no schema, automatically indexing your data and pro-\n       viding  a  simple  API for storage and access. This approach eliminates\n       the administrative burden of data modeling, index maintenance, and per-\n       formance  tuning.  Developers  gain access to this functionality within\n       Amazon's proven computing environment, are able to scale instantly, and\n       pay only for what they use.\n\n       Visit http://aws.amazon.com/simpledb/ for more information.\n\n       NOTE:\n          AWS  CLI  support  for  this  service is only available in a preview\n          stage. You can enable this service by  running:  aws  configure  set\n          preview.sdb true"
		},
		{
			"available commands": [
				"batch-delete-attributes",
				"batch-put-attributes",
				"create-domain",
				"delete-attributes",
				"delete-domain",
				"domain-metadata",
				"get-attributes",
				"help",
				"list-domains",
				"put-attributes",
				"select"
			]
		}
	],
	"secretsmanager": [{
			"name": "secretsmanager"
		},
		{
			"description": "AWS Secrets Manager is a web service that enables you to store, manage,\n       and retrieve, secrets.\n\n       This guide provides descriptions of the Secrets Manager API.  For  more\n       information  about using this service, see the AWS Secrets Manager User\n       Guide .\n          API Version\n\n       This version of the Secrets Manager API Reference documents the Secrets\n       Manager API version 2017-10-17.\n\n       NOTE:\n          As  an alternative to using the API directly, you can use one of the\n          AWS SDKs, which consist of libraries and  sample  code  for  various\n          programming  languages and platforms (such as Java, Ruby, .NET, iOS,\n          and Android). The SDKs provide a convenient way to  create  program-\n          matic access to AWS Secrets Manager. For example, the SDKs take care\n          of cryptographically signing requests, managing errors, and retrying\n          requests  automatically.  For  more  information about the AWS SDKs,\n          including how to download and install them, see Tools for Amazon Web\n          Services .\n\n       We  recommend  that you use the AWS SDKs to make programmatic API calls\n       to Secrets Manager. However, you also can use the Secrets Manager  HTTP\n       Query  API  to make direct calls to the Secrets Manager web service. To\n       learn more about the Secrets Manager HTTP Query API, see  Making  Query\n       Requests in the AWS Secrets Manager User Guide .\n\n       Secrets  Manager  supports  GET and POST requests for all actions. That\n       is, the API doesn't require you to use GET for some  actions  and  POST\n       for others. However, GET requests are subject to the limitation size of\n       a URL. Therefore, for operations that require larger sizes, use a  POST\n       request.\n          Support and Feedback for AWS Secrets Manager\n\n       We     welcome     your     feedback.    Send    your    comments    to\n       awssecretsmanager-feedback@amazon.com , or post your feedback and ques-\n       tions  in  the AWS Secrets Manager Discussion Forum . For more informa-\n       tion about the AWS Discussion Forums, see Forums Help .\n          How examples are presented\n\n       The JSON that AWS Secrets Manager expects as  your  request  parameters\n       and  that  the service returns as a response to HTTP query requests are\n       single, long strings without line breaks or white space formatting. The\n       JSON shown in the examples is formatted with both line breaks and white\n       space to improve readability. When example input parameters would  also\n       result  in  long  strings that extend beyond the screen, we insert line\n       breaks to enhance readability. You should always submit the input as  a\n       single JSON text string.\n          Logging API Requests\n\n       AWS Secrets Manager supports AWS CloudTrail, a service that records AWS\n       API calls for your AWS account and delivers log files to an  Amazon  S3\n       bucket.  By  using  information that's collected by AWS CloudTrail, you\n       can determine which requests were successfully made to Secrets Manager,\n       who  made  the request, when it was made, and so on. For more about AWS\n       Secrets Manager and its support for AWS  CloudTrail,  see  Logging  AWS\n       Secrets  Manager  Events with AWS CloudTrail in the AWS Secrets Manager\n       User Guide . To learn more about CloudTrail, including how to  turn  it\n       on and find your log files, see the AWS CloudTrail User Guide ."
		},
		{
			"available commands": [
				"cancel-rotate-secret",
				"create-secret",
				"delete-resource-policy",
				"delete-secret",
				"describe-secret",
				"get-random-password",
				"get-resource-policy",
				"get-secret-value",
				"help",
				"list-secret-version-ids",
				"list-secrets",
				"put-resource-policy",
				"put-secret-value",
				"restore-secret",
				"rotate-secret",
				"tag-resource",
				"untag-resource",
				"update-secret",
				"update-secret-version-stage"
			]
		}
	],
	"serverlessrepo": [{
			"name": "serverlessrepo"
		},
		{
			"description": "The  AWS Serverless Application Repository makes it easy for developers\n       and enterprises to quickly find and deploy serverless  applications  in\n       the  AWS Cloud. For more information about serverless applications, see\n       Serverless Computing and Applications on the AWS website.\n\n       The AWS Serverless Application Repository is deeply integrated with the\n       AWS  Lambda  console,  so that developers of all levels can get started\n       with serverless computing without needing to learn  anything  new.  You\n       can  use  category  keywords to browse for applications such as web and\n       mobile backends, data processing applications,  or  chatbots.  You  can\n       also  search  for  applications by name, publisher, or event source. To\n       use an application,  you  simply  choose  it,  configure  any  required\n       fields, and deploy it with a few clicks.\n\n       You  can  also  easily publish applications, sharing them publicly with\n       the community at large, or privately within your team  or  across  your\n       organization. To publish a serverless application (or app), you can use\n       the AWS Management Console, AWS Command Line Interface  (AWS  CLI),  or\n       AWS  SDKs  to upload the code. Along with the code, you upload a simple\n       manifest file, also known as the AWS Serverless Application Model  (AWS\n       SAM)  template.  For more information about AWS SAM, see AWS Serverless\n       Application Model (AWS SAM) on the AWS Labs GitHub repository.\n\n       The AWS Serverless Application Repository Developer Guide contains more\n       information about the two developer experiences available:\n\n      Consuming  Applications  Browse for applications and view information\n         about them, including source code and  readme  files.  Also  install,\n         configure,  and  deploy  applications  of  your choosing.  Publishing\n         Applications  Configure and upload applications to make  them  avail-\n         able to other developers, and publish new versions of applications."
		},
		{
			"available commands": [
				"create-application",
				"create-application-version",
				"create-cloud-formation-change-set",
				"delete-application",
				"get-application",
				"get-application-policy",
				"help",
				"list-application-versions",
				"list-applications",
				"put-application-policy",
				"update-application"
			]
		}
	],
	"servicecatalog": [{
			"name": "servicecatalog"
		},
		{
			"description": "AWS Service Catalog enables organizations to create and manage cata-\n          logs of IT services that are approved for use on  AWS.  To  get  the\n          most out of this documentation, you should be familiar with the ter-\n          minology discussed in AWS Service Catalog Concepts ."
		},
		{
			"available commands": [
				"accept-portfolio-share",
				"associate-principal-with-portfolio",
				"associate-product-with-portfolio",
				"associate-tag-option-with-resource",
				"copy-product",
				"create-constraint",
				"create-portfolio",
				"create-portfolio-share",
				"create-product",
				"create-provisioned-product-plan",
				"create-provisioning-artifact",
				"create-tag-option",
				"delete-constraint",
				"delete-portfolio",
				"delete-portfolio-share",
				"delete-product",
				"delete-provisioned-product-plan",
				"delete-provisioning-artifact",
				"delete-tag-option",
				"describe-constraint",
				"describe-copy-product-status",
				"describe-portfolio",
				"describe-product",
				"describe-product-as-admin",
				"describe-product-view",
				"describe-provisioned-product",
				"describe-provisioned-product-plan",
				"describe-provisioning-artifact",
				"describe-provisioning-parameters",
				"describe-record",
				"describe-tag-option",
				"disassociate-principal-from-portfolio",
				"disassociate-product-from-portfolio",
				"disassociate-tag-option-from-resource",
				"execute-provisioned-product-plan",
				"generate",
				"help",
				"list-accepted-portfolio-shares",
				"list-constraints-for-portfolio",
				"list-launch-paths",
				"list-portfolio-access",
				"list-portfolios",
				"list-portfolios-for-product",
				"list-principals-for-portfolio",
				"list-provisioned-product-plans",
				"list-provisioning-artifacts",
				"list-record-history",
				"list-resources-for-tag-option",
				"list-tag-options",
				"provision-product",
				"reject-portfolio-share",
				"scan-provisioned-products",
				"search-products",
				"search-products-as-admin",
				"search-provisioned-products",
				"terminate-provisioned-product",
				"update-constraint",
				"update-portfolio",
				"update-product",
				"update-provisioned-product",
				"update-provisioning-artifact",
				"update-tag-option"
			]
		}
	],
	"servicediscovery": [{
			"name": "servicediscovery"
		},
		{
			"description": "Amazon Route 53 auto naming lets you configure public or private names-\n       paces that your microservice applications run in. When instances of the\n       service  become available, you can call the auto naming API to register\n       the instance, and Route 53 automatically creates up to five DNS records\n       and  an  optional health check. Clients that submit DNS queries for the\n       service receive an answer that contains up to eight healthy records."
		},
		{
			"available commands": [
				"create-private-dns-namespace",
				"create-public-dns-namespace",
				"create-service",
				"delete-namespace",
				"delete-service",
				"deregister-instance",
				"get-instance",
				"get-instances-health-status",
				"get-namespace",
				"get-operation",
				"get-service",
				"help",
				"list-instances",
				"list-namespaces",
				"list-operations",
				"list-services",
				"register-instance",
				"update-instance-custom-health-status",
				"update-service"
			]
		}
	],
	"ses": [{
			"name": "ses"
		},
		{
			"description": "This  document  contains  reference  information  for the Amazon Simple\n       Email Service (Amazon SES) API, version 2010-12-01.  This  document  is\n       best used in conjunction with the Amazon SES Developer Guide .\n\n       NOTE:\n          For  a  list of Amazon SES endpoints to use in service requests, see\n          Regions and Amazon SES in the Amazon SES Developer Guide ."
		},
		{
			"available commands": [
				"clone-receipt-rule-set",
				"create-configuration-set",
				"create-configuration-set-event-destination",
				"create-configuration-set-tracking-options",
				"create-custom-verification-email-template",
				"create-receipt-filter",
				"create-receipt-rule",
				"create-receipt-rule-set",
				"create-template",
				"delete-configuration-set",
				"delete-configuration-set-event-destination",
				"delete-configuration-set-tracking-options",
				"delete-custom-verification-email-template",
				"delete-identity",
				"delete-identity-policy",
				"delete-receipt-filter",
				"delete-receipt-rule",
				"delete-receipt-rule-set",
				"delete-template",
				"describe-active-receipt-rule-set",
				"describe-configuration-set",
				"describe-receipt-rule",
				"describe-receipt-rule-set",
				"get-account-sending-enabled",
				"get-custom-verification-email-template",
				"get-identity-dkim-attributes",
				"get-identity-mail-from-domain-attributes",
				"get-identity-notification-attributes",
				"get-identity-policies",
				"get-identity-verification-attributes",
				"get-send-quota",
				"get-send-statistics",
				"get-template",
				"help",
				"list-configuration-sets",
				"list-custom-verification-email-templates",
				"list-identities",
				"list-identity-policies",
				"list-receipt-filters",
				"list-receipt-rule-sets",
				"list-templates",
				"put-identity-policy",
				"reorder-receipt-rule-set",
				"send-bounce",
				"send-bulk-templated-email",
				"send-custom-verification-email",
				"send-email",
				"send-raw-email",
				"send-templated-email",
				"set-active-receipt-rule-set",
				"set-identity-dkim-enabled",
				"set-identity-feedback-forwarding-enabled",
				"set-identity-headers-in-notifications-enabled",
				"set-identity-mail-from-domain",
				"set-identity-notification-topic",
				"set-receipt-rule-position",
				"test-render-template",
				"update-account-sending-enabled",
				"update-configuration-set-event-destination",
				"update-configuration-set-reputation-metrics-enabled",
				"update-configuration-set-sending-enabled",
				"update-configuration-set-tracking-options",
				"update-custom-verification-email-template",
				"update-receipt-rule",
				"update-template",
				"verify-domain-dkim",
				"verify-domain-identity",
				"verify-email-identity",
				"wait"
			]
		}
	],
	"shield": [{
			"name": "shield"
		},
		{
			"description": "This  is  the  AWS  Shield  Advanced  API Reference . This guide is for\n       developers who need detailed information about the AWS Shield  Advanced\n       API actions, data types, and errors. For detailed information about AWS\n       WAF and AWS Shield Advanced features and an overview of how to use  the\n       AWS  WAF  and  AWS Shield Advanced APIs, see the AWS WAF and AWS Shield\n       Developer Guide ."
		},
		{
			"available commands": [
				"associate-drt-log-bucket",
				"associate-drt-role",
				"create-protection",
				"create-subscription",
				"delete-protection",
				"describe-attack",
				"describe-drt-access",
				"describe-emergency-contact-settings",
				"describe-protection",
				"describe-subscription",
				"disassociate-drt-log-bucket",
				"disassociate-drt-role",
				"get-subscription-state",
				"help",
				"list-attacks",
				"list-protections",
				"update-emergency-contact-settings",
				"update-subscription"
			]
		}
	],
	"sms": [{
			"name": "sms"
		},
		{
			"description": "Amazon  Server  Migration  Service  automates  the process of migrating\n       servers to EC2."
		},
		{
			"available commands": [
				"create-replication-job",
				"delete-replication-job",
				"delete-server-catalog",
				"disassociate-connector",
				"get-connectors",
				"get-replication-jobs",
				"get-replication-runs",
				"get-servers",
				"help",
				"import-server-catalog",
				"start-on-demand-replication-run",
				"update-replication-job"
			]
		}
	],
	"snowball": [{
			"name": "snowball"
		},
		{
			"description": "AWS  Snowball  is  a  petabyte-scale  data transport solution that uses\n       secure appliances to  transfer  large  amounts  of  data  between  your\n       on-premises data centers and Amazon Simple Storage Service (Amazon S3).\n       The Snowball commands described here provide access to the  same  func-\n       tionality  that  is  available  in the AWS Snowball Management Console,\n       which enables you to create and manage jobs for Snowball.  To  transfer\n       data locally with a Snowball appliance, you'll need to use the Snowball\n       client or the Amazon S3 API adapter for Snowball. For more information,\n       see the User Guide ."
		},
		{
			"available commands": [
				"cancel-cluster",
				"cancel-job",
				"create-address",
				"create-cluster",
				"create-job",
				"describe-address",
				"describe-addresses",
				"describe-cluster",
				"describe-job",
				"get-job-manifest",
				"get-job-unlock-code",
				"get-snowball-usage",
				"help",
				"list-cluster-jobs",
				"list-clusters",
				"list-jobs",
				"update-cluster",
				"update-job"
			]
		}
	],
	"sns": [{
			"name": "sns"
		},
		{
			"description": "Amazon  Simple  Notification Service (Amazon SNS) is a web service that\n       enables you to build distributed web-enabled applications. Applications\n       can  use  Amazon  SNS to easily push real-time notification messages to\n       interested subscribers  over  multiple  delivery  protocols.  For  more\n       information  about  this  product  see  http://aws.amazon.com/sns . For\n       detailed information about Amazon SNS features and their associated API\n       calls, see the Amazon SNS Developer Guide .\n\n       We  also  provide  SDKs  that enable you to access Amazon SNS from your\n       preferred programming language. The  SDKs  contain  functionality  that\n       automatically  takes  care  of tasks such as: cryptographically signing\n       your service requests, retrying requests, and handling error responses.\n       For a list of available SDKs, go to Tools for Amazon Web Services ."
		},
		{
			"available commands": [
				"add-permission",
				"check-if-phone-number-is-opted-out",
				"confirm-subscription",
				"create-platform-application",
				"create-platform-endpoint",
				"create-topic",
				"delete-endpoint",
				"delete-platform-application",
				"delete-topic",
				"get-endpoint-attributes",
				"get-platform-application-attributes",
				"get-sms-attributes",
				"get-subscription-attributes",
				"get-topic-attributes",
				"help",
				"list-endpoints-by-platform-application",
				"list-phone-numbers-opted-out",
				"list-platform-applications",
				"list-subscriptions",
				"list-subscriptions-by-topic",
				"list-topics",
				"opt-in-phone-number",
				"publish",
				"remove-permission",
				"set-endpoint-attributes",
				"set-platform-application-attributes",
				"set-sms-attributes",
				"set-subscription-attributes",
				"set-topic-attributes",
				"subscribe",
				"unsubscribe"
			]
		}
	],
	"sqs": [{
			"name": "sqs"
		},
		{
			"description": "Welcome to the Amazon Simple Queue Service API Reference .\n\n       Amazon Simple Queue Service (Amazon SQS) is a reliable, highly-scalable\n       hosted queue for storing messages as they travel  between  applications\n       or microservices. Amazon SQS moves data between distributed application\n       components and helps you decouple these components.\n\n       NOTE:\n          Standard queues are available in all regions. FIFO queues are avail-\n          able in the US East (N. Virginia), US East (Ohio), US West (Oregon),\n          and EU (Ireland) regions.\n\n       You can use AWS SDKs to access Amazon SQS using your favorite  program-\n       ming  language.  The SDKs perform tasks such as the following automati-\n       cally:\n\n      -Cryptographically sign your service requests,\n\n       -Retry requests,\n\n        -Handle error responses,\n         \n\n         -Amazon SQS Product Page,\n\n         -Amazon Simple Queue Service Developer Guide,\n\n          -Making API Requests,\n\n          -Using Amazon SQS Message Attributes,\n\n          -Using Amazon SQS Dead-Letter Queues,\n\n          -Amazon Web Services General Reference\n\n          -Regions and Endpoints"
		},
		{
			"available commands": [
				"add-permission",
				"change-message-visibility",
				"change-message-visibility-batch",
				"create-queue",
				"delete-message",
				"delete-message-batch",
				"delete-queue",
				"get-queue-attributes",
				"get-queue-url",
				"help",
				"list-dead-letter-source-queues",
				"list-queue-tags",
				"list-queues",
				"purge-queue",
				"receive-message",
				"remove-permission",
				"send-message",
				"send-message-batch",
				"set-queue-attributes",
				"tag-queue",
				"untag-queue"
			]
		}
	],
	"ssm": [{
			"name": "ssm"
		},
		{
			"description": "AWS  Systems  Manager  is  a  collection of capabilities that helps you\n       automate management tasks such as collecting system inventory, applying\n       operating  system  (OS)  patches,  automating  the  creation  of Amazon\n       Machine Images (AMIs), and  configuring  operating  systems  (OSs)  and\n       applications  at  scale. Systems Manager lets you remotely and securely\n       manage the configuration of your managed instances. A managed  instance\n       is  any Amazon EC2 instance or on-premises machine in your hybrid envi-\n       ronment that has been configured for Systems Manager.\n\n       This reference is intended to be used with the AWS Systems Manager User\n       Guide .\n\n       To  get  started, verify prerequisites and configure managed instances.\n       For more information, see Systems Manager Prerequisites in the AWS Sys-\n       tems Manager User Guide .\n\n       For  information  about other API actions you can perform on Amazon EC2\n       instances, see the Amazon EC2 API Reference . For information about how\n       to use a Query API, see Making API Requests ."
		},
		{
			"available commands": [
				"add-tags-to-resource",
				"cancel-command",
				"create-activation",
				"create-association",
				"create-association-batch",
				"create-document",
				"create-maintenance-window",
				"create-patch-baseline",
				"create-resource-data-sync",
				"delete-activation",
				"delete-association",
				"delete-document",
				"delete-inventory",
				"delete-maintenance-window",
				"delete-parameter",
				"delete-parameters",
				"delete-patch-baseline",
				"delete-resource-data-sync",
				"deregister-managed-instance",
				"deregister-patch-baseline-for-patch-group",
				"deregister-target-from-maintenance-window",
				"deregister-task-from-maintenance-window",
				"describe-activations",
				"describe-association",
				"describe-association-execution-targets",
				"describe-association-executions",
				"describe-automation-executions",
				"describe-automation-step-executions",
				"describe-available-patches",
				"describe-document",
				"describe-document-permission",
				"describe-effective-instance-associations",
				"describe-effective-patches-for-patch-baseline",
				"describe-instance-associations-status",
				"describe-instance-information",
				"describe-instance-patch-states",
				"describe-instance-patch-states-for-patch-group",
				"describe-instance-patches",
				"describe-inventory-deletions",
				"describe-maintenance-window-execution-task-invocations",
				"describe-maintenance-window-execution-tasks",
				"describe-maintenance-window-executions",
				"describe-maintenance-window-targets",
				"describe-maintenance-window-tasks",
				"describe-maintenance-windows",
				"describe-parameters",
				"describe-patch-baselines",
				"describe-patch-group-state",
				"describe-patch-groups",
				"get-automation-execution",
				"get-command-invocation",
				"get-default-patch-baseline",
				"get-deployable-patch-snapshot-for-instance",
				"get-document",
				"get-inventory",
				"get-inventory-schema",
				"get-maintenance-window",
				"get-maintenance-window-execution",
				"get-maintenance-window-execution-task",
				"get-maintenance-window-execution-task-invocation",
				"get-maintenance-window-task",
				"get-parameter",
				"get-parameter-history",
				"get-parameters",
				"get-parameters-by-path",
				"get-patch-baseline",
				"get-patch-baseline-for-patch-group",
				"help",
				"list-association-versions",
				"list-associations",
				"list-command-invocations",
				"list-commands",
				"list-compliance-items",
				"list-compliance-summaries",
				"list-document-versions",
				"list-documents",
				"list-inventory-entries",
				"list-resource-compliance-summaries",
				"list-resource-data-sync",
				"list-tags-for-resource",
				"modify-document-permission",
				"put-compliance-items",
				"put-inventory",
				"put-parameter",
				"register-default-patch-baseline",
				"register-patch-baseline-for-patch-group",
				"register-target-with-maintenance-window",
				"register-task-with-maintenance-window",
				"remove-tags-from-resource",
				"send-automation-signal",
				"send-command",
				"start-associations-once",
				"start-automation-execution",
				"stop-automation-execution",
				"update-association",
				"update-association-status",
				"update-document",
				"update-document-default-version",
				"update-maintenance-window",
				"update-maintenance-window-target",
				"update-maintenance-window-task",
				"update-managed-instance-role",
				"update-patch-baseline"
			]
		}
	],
	"stepfunctions": [{
			"name": "stepfunctions"
		},
		{
			"description": "AWS Step Functions is a service that lets you coordinate the components\n       of distributed applications and microservices using visual workflows.\n\n       You can use Step Functions to build applications from individual compo-\n       nents,  each  of which performs a discrete function, or task , allowing\n       you to scale and change applications quickly. Step Functions provides a\n       console  that  helps  visualize the components of your application as a\n       series of steps. Step Functions automatically triggers and tracks  each\n       step, and retries steps when there are errors, so your application exe-\n       cutes predictably and in the right order  every  time.  Step  Functions\n       logs  the state of each step, so you can quickly diagnose and debug any\n       issues.\n\n       Step Functions manages  operations  and  underlying  infrastructure  to\n       ensure your application is available at any scale. You can run tasks on\n       AWS, your own servers, or any system that has access to  AWS.  You  can\n       access  and  use  Step Functions using the console, the AWS SDKs, or an\n       HTTP API. For more information about Step Functions, see the * AWS Step\n       Functions Developer Guide * ."
		},
		{
			"available commands": [
				"create-activity",
				"create-state-machine",
				"delete-activity",
				"delete-state-machine",
				"describe-activity",
				"describe-execution",
				"describe-state-machine",
				"describe-state-machine-for-execution",
				"get-activity-task",
				"get-execution-history",
				"help",
				"list-activities",
				"list-executions",
				"list-state-machines",
				"send-task-failure",
				"send-task-heartbeat",
				"send-task-success",
				"start-execution",
				"stop-execution",
				"update-state-machine"
			]
		}
	],
	"storagegateway": [{
			"name": "storagegateway"
		},
		{
			"description": "AWS  Storage  Gateway is the service that connects an on-premises soft-\n       ware appliance with cloud-based storage to provide seamless and  secure\n       integration  between  an  organization's on-premises IT environment and\n       AWS's storage infrastructure.  The  service  enables  you  to  securely\n       upload data to the AWS cloud for cost effective backup and rapid disas-\n       ter recovery.\n\n       Use the following links to get started using the  AWS  Storage  Gateway\n       Service API Reference :\n\n     < AWS Storage Gateway Required Request Headers : Describes the required\n         headers that you must send with every POST  request  to  AWS  Storage\n         Gateway.\n\n     < Signing Requests : AWS Storage Gateway requires that you authenticate\n         every request you send; this topic describes how sign such a request.\n\n     < Error  Responses  :  Provides reference information about AWS Storage\n         Gateway errors.\n\n     < Operations in AWS Storage Gateway : Contains detailed descriptions of\n         all   AWS  Storage  Gateway  operations,  their  request  parameters,\n         response elements, possible errors,  and  examples  of  requests  and\n         responses.\n\n     < AWS  Storage  Gateway  Regions and Endpoints: Provides a list of each\n         region and endpoints available for use with AWS Storage Gateway.\n\n       NOTE:\n          AWS Storage Gateway resource IDs are  in  uppercase.  When  you  use\n          these resource IDs with the Amazon EC2 API, EC2 expects resource IDs\n          in lowercase. You must change your resource ID to lowercase  to  use\n          it  with  the  EC2 API. For example, in Storage Gateway the ID for a\n          volume might be vol-AA22BB012345DAF670 . When you use this  ID  with\n          the  EC2  API, you must change it to vol-aa22bb012345daf670 . Other-\n          wise, the EC2 API might not behave as expected.\n\n       WARNING:\n          IDs for Storage Gateway volumes and  Amazon  EBS  snapshots  created\n          from  gateway  volumes  are changing to a longer format. Starting in\n          December 2016, all new volumes and snapshots will be created with  a\n          17-character string. Starting in April 2016, you will be able to use\n          these longer IDs so you can test your systems with the  new  format.\n          For more information, see Longer EC2 and EBS Resource IDs .\n\n          For  example,  a  volume  Amazon Resource Name (ARN) with the longer\n          volume ID format looks like the following:\n              arn:aws:storagegateway:us-west-2:111122223333:gate-\n              way/sgw-12A3456B/volume/vol-1122AABBCCDDEEFFG .\n\n          A  snapshot  ID  with the longer ID format looks like the following:\n          snap-78e226633445566ee .\n\n          For more information, see Announcement: Heads-up  Longer AWS Storage\n          Gateway volume and snapshot IDs coming in 2016 ."
		},
		{
			"available commands": [
				"activate-gateway",
				"add-cache",
				"add-tags-to-resource",
				"add-upload-buffer",
				"add-working-storage",
				"cancel-archival",
				"cancel-retrieval",
				"create-cached-iscsi-volume",
				"create-nfs-file-share",
				"create-smb-file-share",
				"create-snapshot",
				"create-snapshot-from-volume-recovery-point",
				"create-stored-iscsi-volume",
				"create-tape-with-barcode",
				"create-tapes",
				"delete-bandwidth-rate-limit",
				"delete-chap-credentials",
				"delete-file-share",
				"delete-gateway",
				"delete-snapshot-schedule",
				"delete-tape",
				"delete-tape-archive",
				"delete-volume",
				"describe-bandwidth-rate-limit",
				"describe-cache",
				"describe-cached-iscsi-volumes",
				"describe-chap-credentials",
				"describe-gateway-information",
				"describe-maintenance-start-time",
				"describe-nfs-file-shares",
				"describe-smb-file-shares",
				"describe-smb-settings",
				"describe-snapshot-schedule",
				"describe-stored-iscsi-volumes",
				"describe-tape-archives",
				"describe-tape-recovery-points",
				"describe-tapes",
				"describe-upload-buffer",
				"describe-vtl-devices",
				"describe-working-storage",
				"disable-gateway",
				"help",
				"join-domain",
				"list-file-shares",
				"list-gateways",
				"list-local-disks",
				"list-tags-for-resource",
				"list-tapes",
				"list-volume-initiators",
				"list-volume-recovery-points",
				"list-volumes",
				"notify-when-uploaded",
				"refresh-cache",
				"remove-tags-from-resource",
				"reset-cache",
				"retrieve-tape-archive",
				"retrieve-tape-recovery-point",
				"set-local-console-password",
				"set-smb-guest-password",
				"shutdown-gateway",
				"start-gateway",
				"update-bandwidth-rate-limit",
				"update-chap-credentials",
				"update-gateway-information",
				"update-gateway-software-now",
				"update-maintenance-start-time",
				"update-nfs-file-share",
				"update-smb-file-share",
				"update-snapshot-schedule",
				"update-vtl-device-type"
			]
		}
	],
	"sts": [{
			"name": "sts"
		},
		{
			"description": "The  AWS Security Token Service (STS) is a web service that enables you\n       to request temporary, limited-privilege credentials  for  AWS  Identity\n       and  Access  Management  (IAM) users or for users that you authenticate\n       (federated users). This guide provides descriptions of the STS API. For\n       more  detailed  information  about  using this service, go to Temporary\n       Security Credentials .\n\n       NOTE:\n          As an alternative to using the API, you can use one of the AWS SDKs,\n          which  consist  of libraries and sample code for various programming\n          languages and platforms (Java, Ruby, .NET, iOS, Android, etc.).  The\n          SDKs  provide a convenient way to create programmatic access to STS.\n          For  example,  the  SDKs  take  care  of  cryptographically  signing\n          requests,  managing errors, and retrying requests automatically. For\n          information about the  AWS  SDKs,  including  how  to  download  and\n          install them, see the Tools for Amazon Web Services page .\n\n       For  information  about setting up signatures and authorization through\n       the API, go to Signing AWS API Requests in the AWS General Reference  .\n       For  general  information  about  the  Query  API,  go  to Making Query\n       Requests in Using IAM . For information  about  using  security  tokens\n       with  other  AWS products, go to AWS Services That Work with IAM in the\n       IAM User Guide .\n\n       If you're new to AWS and need additional technical information about  a\n       specific  AWS  product, you can find the product's technical documenta-\n       tion at http://aws.amazon.com/documentation/ .\n          Endpoints\n\n       The AWS  Security  Token  Service  (STS)  has  a  default  endpoint  of\n       https://sts.amazonaws.com  that  maps  to  the  US  East  (N. Virginia)\n       region. Additional regions are available and are activated by  default.\n       For more information, see Activating and Deactivating AWS STS in an AWS\n       Region in the IAM User Guide .\n\n       For information about STS endpoints, see Regions and Endpoints  in  the\n       AWS General Reference .\n          Recording API requests\n\n       STS  supports AWS CloudTrail, which is a service that records AWS calls\n       for your AWS account and delivers log files to an Amazon S3 bucket.  By\n       using  information  collected  by  CloudTrail,  you  can determine what\n       requests were successfully made to STS, who made the request,  when  it\n       was  made,  and so on. To learn more about CloudTrail, including how to\n       turn it on and find your log files, see the AWS CloudTrail User Guide ."
		},
		{
			"available commands": [
				"assume-role",
				"assume-role-with-saml",
				"assume-role-with-web-identity",
				"decode-authorization-message",
				"get-caller-identity",
				"get-federation-token",
				"get-session-token",
				"help"
			]
		}
	],
	"support": [{
			"name": "support"
		},
		{
			"description": "The  AWS  Support  API  reference  is intended for programmers who need\n       detailed information about the AWS Support operations and  data  types.\n       This  service enables you to manage your AWS Support cases programmati-\n       cally. It uses HTTP methods that return results in JSON format.\n\n       The AWS Support service also exposes a set of Trusted Advisor features.\n       You  can  retrieve  a  list of checks and their descriptions, get check\n       results, specify checks to refresh,  and  get  the  refresh  status  of\n       checks.\n\n       The  following  list  describes  the AWS Support case management opera-\n       tions:\n\n      Service names, issue categories, and available severity  levels.  The\n         describe-services and  describe-severity-levels operations return AWS\n         service names, service codes, service categories, and problem  sever-\n         ity levels. You use these values when you call the  create-case oper-\n         ation.\n\n      Case creation, case details, and case resolution. The  create-case  ,\n         describe-cases  ,  describe-attachment , and  resolve-case operations\n         create AWS Support  cases,  retrieve  information  about  cases,  and\n         resolve cases.\n\n      Case  communication.  The   describe-communications ,  add-communica-\n         tion-to-case , and  add-attachments-to-set  operations  retrieve  and\n         add communications and attachments to AWS Support cases.\n\n       The following list describes the operations available from the AWS Sup-\n       port service for Trusted Advisor:\n\n      describe-trusted-advisor-checks returns the list of checks  that  run\n         against your AWS resources.\n\n      Using    the    checkId    for   a   specific   check   returned   by\n         describe-trusted-advisor-checks      ,       you       can       call\n         describe-trusted-advisor-check-result  to  obtain the results for the\n         check you specified.\n\n      describe-trusted-advisor-check-summaries returns  summarized  results\n         for one or more Trusted Advisor checks.\n\n      refresh-trusted-advisor-check  requests  that Trusted Advisor rerun a\n         specified check.\n\n      describe-trusted-advisor-check-refresh-statuses reports  the  refresh\n         status of one or more checks.\n\n       For  authentication  of  requests, AWS Support uses Signature Version 4\n       Signing Process .\n\n       See About the AWS Support API in the AWS Support User Guide for  infor-\n       mation  about how to use this service to create and manage your support\n       cases, and how to call Trusted Advisor for results of  checks  on  your\n       resources."
		},
		{
			"available commands": [
				"add-attachments-to-set",
				"add-communication-to-case",
				"create-case",
				"describe-attachment",
				"describe-cases",
				"describe-communications",
				"describe-services",
				"describe-severity-levels",
				"describe-trusted-advisor-check-refresh-statuses",
				"describe-trusted-advisor-check-result",
				"describe-trusted-advisor-check-summaries",
				"describe-trusted-advisor-checks",
				"help",
				"refresh-trusted-advisor-check",
				"resolve-case"
			]
		}
	],
	"swf": [{
			"name": "swf"
		},
		{
			"description": "The  Amazon Simple Workflow Service (Amazon SWF) makes it easy to build\n       applications that use Amazon's cloud to coordinate work across distrib-\n       uted  components.  In  Amazon  SWF, a task represents a logical unit of\n       work that is performed by a component of  your  workflow.  Coordinating\n       tasks  in a workflow involves managing intertask dependencies, schedul-\n       ing, and concurrency in accordance with the logical flow of the  appli-\n       cation.\n\n       Amazon  SWF  gives you full control over implementing tasks and coordi-\n       nating them without worrying  about  underlying  complexities  such  as\n       tracking their progress and maintaining their state.\n\n       This  documentation serves as reference only. For a broader overview of\n       the Amazon SWF programming model, see the * Amazon SWF Developer  Guide\n       * ."
		},
		{
			"available commands": [
				"count-closed-workflow-executions",
				"count-open-workflow-executions",
				"count-pending-activity-tasks",
				"count-pending-decision-tasks",
				"deprecate-activity-type",
				"deprecate-domain",
				"deprecate-workflow-type",
				"describe-activity-type",
				"describe-domain",
				"describe-workflow-execution",
				"describe-workflow-type",
				"get-workflow-execution-history",
				"help",
				"list-activity-types",
				"list-closed-workflow-executions",
				"list-domains",
				"list-open-workflow-executions",
				"list-workflow-types",
				"poll-for-activity-task",
				"poll-for-decision-task",
				"record-activity-task-heartbeat",
				"register-activity-type",
				"register-domain",
				"register-workflow-type",
				"request-cancel-workflow-execution",
				"respond-activity-task-canceled",
				"respond-activity-task-completed",
				"respond-activity-task-failed",
				"respond-decision-task-completed",
				"signal-workflow-execution",
				"start-workflow-execution",
				"terminate-workflow-execution"
			]
		}
	],
	"transcribe": [{
			"name": "transcribe"
		},
		{
			"description": "Operations and objects for transcribing speech to text."
		},
		{
			"available commands": [
				"create-vocabulary",
				"delete-vocabulary",
				"get-transcription-job",
				"get-vocabulary",
				"help",
				"list-transcription-jobs",
				"list-vocabularies",
				"start-transcription-job",
				"update-vocabulary"
			]
		}
	],
	"translate": [{
			"name": "translate"
		},
		{
			"description": "Provides  translation  between  English  and  one  of six languages, or\n       between one of the six languages and English."
		},
		{
			"available commands": [
				"help",
				"translate-text"
			]
		}
	],
	"waf": [{
			"name": "waf"
		},
		{
			"description": "This  is the AWS WAF API Reference for using AWS WAF with Amazon Cloud-\n       Front. The AWS WAF actions and data types listed in the  reference  are\n       available  for  protecting Amazon CloudFront distributions. You can use\n       these actions and data types via the endpoint waf.amazonaws.com .  This\n       guide is for developers who need detailed information about the AWS WAF\n       API actions, data types, and errors. For detailed information about AWS\n       WAF features and an overview of how to use the AWS WAF API, see the AWS\n       WAF Developer Guide ."
		},
		{
			"available commands": [
				"create-byte-match-set",
				"create-geo-match-set",
				"create-ip-set",
				"create-rate-based-rule",
				"create-regex-match-set",
				"create-regex-pattern-set",
				"create-rule",
				"create-rule-group",
				"create-size-constraint-set",
				"create-sql-injection-match-set",
				"create-web-acl",
				"create-xss-match-set",
				"delete-byte-match-set",
				"delete-geo-match-set",
				"delete-ip-set",
				"delete-permission-policy",
				"delete-rate-based-rule",
				"delete-regex-match-set",
				"delete-regex-pattern-set",
				"delete-rule",
				"delete-rule-group",
				"delete-size-constraint-set",
				"delete-sql-injection-match-set",
				"delete-web-acl",
				"delete-xss-match-set",
				"get-byte-match-set",
				"get-change-token",
				"get-change-token-status",
				"get-geo-match-set",
				"get-ip-set",
				"get-permission-policy",
				"get-rate-based-rule",
				"get-rate-based-rule-managed-keys",
				"get-regex-match-set",
				"get-regex-pattern-set",
				"get-rule",
				"get-rule-group",
				"get-sampled-requests",
				"get-size-constraint-set",
				"get-sql-injection-match-set",
				"get-web-acl",
				"get-xss-match-set",
				"help",
				"list-activated-rules-in-rule-group",
				"list-byte-match-sets",
				"list-geo-match-sets",
				"list-ip-sets",
				"list-rate-based-rules",
				"list-regex-match-sets",
				"list-regex-pattern-sets",
				"list-rule-groups",
				"list-rules",
				"list-size-constraint-sets",
				"list-sql-injection-match-sets",
				"list-subscribed-rule-groups",
				"list-web-acls",
				"list-xss-match-sets",
				"put-permission-policy",
				"update-byte-match-set",
				"update-geo-match-set",
				"update-ip-set",
				"update-rate-based-rule",
				"update-regex-match-set",
				"update-regex-pattern-set",
				"update-rule",
				"update-rule-group",
				"update-size-constraint-set",
				"update-sql-injection-match-set",
				"update-web-acl",
				"update-xss-match-set"
			]
		}
	],
	"waf-regional": [{
			"name": "waf-regional"
		},
		{
			"description": "This is the AWS WAF Regional API Reference for using AWS WAF with Elas-\n       tic Load Balancing  (ELB)  Application  Load  Balancers.  The  AWS  WAF\n       actions  and  data types listed in the reference are available for pro-\n       tecting Application Load Balancers. You can use these actions and  data\n       types  by  means of the endpoints listed in AWS Regions and Endpoints .\n       This guide is for developers who need detailed  information  about  the\n       AWS  WAF  API actions, data types, and errors. For detailed information\n       about AWS WAF features and an overview of how to use the AWS  WAF  API,\n       see the AWS WAF Developer Guide ."
		},
		{
			"available commands": [
				"associate-web-acl",
				"create-byte-match-set",
				"create-geo-match-set",
				"create-ip-set",
				"create-rate-based-rule",
				"create-regex-match-set",
				"create-regex-pattern-set",
				"create-rule",
				"create-rule-group",
				"create-size-constraint-set",
				"create-sql-injection-match-set",
				"create-web-acl",
				"create-xss-match-set",
				"delete-byte-match-set",
				"delete-geo-match-set",
				"delete-ip-set",
				"delete-permission-policy",
				"delete-rate-based-rule",
				"delete-regex-match-set",
				"delete-regex-pattern-set",
				"delete-rule",
				"delete-rule-group",
				"delete-size-constraint-set",
				"delete-sql-injection-match-set",
				"delete-web-acl",
				"delete-xss-match-set",
				"disassociate-web-acl",
				"get-byte-match-set",
				"get-change-token",
				"get-change-token-status",
				"get-geo-match-set",
				"get-ip-set",
				"get-permission-policy",
				"get-rate-based-rule",
				"get-rate-based-rule-managed-keys",
				"get-regex-match-set",
				"get-regex-pattern-set",
				"get-rule",
				"get-rule-group",
				"get-sampled-requests",
				"get-size-constraint-set",
				"get-sql-injection-match-set",
				"get-web-acl",
				"get-web-acl-for-resource",
				"get-xss-match-set",
				"help",
				"list-activated-rules-in-rule-group",
				"list-byte-match-sets",
				"list-geo-match-sets",
				"list-ip-sets",
				"list-rate-based-rules",
				"list-regex-match-sets",
				"list-regex-pattern-sets",
				"list-resources-for-web-acl",
				"list-rule-groups",
				"list-rules",
				"list-size-constraint-sets",
				"list-sql-injection-match-sets",
				"list-subscribed-rule-groups",
				"list-web-acls",
				"list-xss-match-sets",
				"put-permission-policy",
				"update-byte-match-set",
				"update-geo-match-set",
				"update-ip-set",
				"update-rate-based-rule",
				"update-regex-match-set",
				"update-regex-pattern-set",
				"update-rule",
				"update-rule-group",
				"update-size-constraint-set",
				"update-sql-injection-match-set",
				"update-web-acl",
				"update-xss-match-set"
			]
		}
	],
	"workdocs": [{
			"name": "workdocs"
		},
		{
			"description": "The WorkDocs API is designed for the following use cases:\n\n     < File  Migration:  File migration applications are supported for users\n         who want to migrate their files from an on-premises  or  off-premises\n         file  system or service. Users can insert files into a user directory\n         structure, as well as allow for basic metadata changes, such as modi-\n         fications to the permissions of files.\n\n     < Security:  Support  security applications are supported for users who\n         have additional security needs, such as antivirus or data  loss  pre-\n         vention.  The  API  actions,  along  with AWS CloudTrail, allow these\n         applications to detect when changes occur in Amazon  WorkDocs.  Then,\n         the application can take the necessary actions and replace the target\n         file. If the target file violates the  policy,  the  application  can\n         also choose to email the user.\n\n     < eDiscovery/Analytics:  General  administrative  applications are sup-\n         ported, such as eDiscovery  and  analytics.  These  applications  can\n         choose  to  mimic  or  record the actions in an Amazon WorkDocs site,\n         along with AWS CloudTrail, to replicate data for eDiscovery,  backup,\n         or analytical applications.\n\n       All  Amazon  WorkDocs API actions are Amazon authenticated and certifi-\n       cate-signed. They not only require the use of the  AWS  SDK,  but  also\n       allow  for  the exclusive use of IAM users and roles to help facilitate\n       access, trust, and permission policies. By creating a role and allowing\n       an IAM user to access the Amazon WorkDocs site, the IAM user gains full\n       administrative visibility into the entire Amazon WorkDocs site  (or  as\n       set in the IAM policy). This includes, but is not limited to, the abil-\n       ity to modify file permissions and upload any file to  any  user.  This\n       allows developers to perform the three use cases above, as well as give\n       users the ability to grant access on a selective basis  using  the  IAM\n       model."
		},
		{
			"available commands": [
				"abort-document-version-upload",
				"activate-user",
				"add-resource-permissions",
				"create-comment",
				"create-custom-metadata",
				"create-folder",
				"create-labels",
				"create-notification-subscription",
				"create-user",
				"deactivate-user",
				"delete-comment",
				"delete-custom-metadata",
				"delete-document",
				"delete-folder",
				"delete-folder-contents",
				"delete-labels",
				"delete-notification-subscription",
				"delete-user",
				"describe-activities",
				"describe-comments",
				"describe-document-versions",
				"describe-folder-contents",
				"describe-groups",
				"describe-notification-subscriptions",
				"describe-resource-permissions",
				"describe-root-folders",
				"describe-users",
				"get-current-user",
				"get-document",
				"get-document-path",
				"get-document-version",
				"get-folder",
				"get-folder-path",
				"help",
				"initiate-document-version-upload",
				"remove-all-resource-permissions",
				"remove-resource-permission",
				"update-document",
				"update-document-version",
				"update-folder",
				"update-user"
			]
		}
	],
	"workmail": [{
			"name": "workmail"
		},
		{
			"description": "Amazon  WorkMail  is  a  secure, managed business email and calendaring\n       service with support for existing desktop and mobile email clients. You\n       can access your email, contacts, and calendars using Microsoft Outlook,\n       your browser, or their native iOS and Android email  applications.  You\n       can  integrate  Amazon  WorkMail with your existing corporate directory\n       and control both the keys that encrypt your data and  the  location  in\n       which your data is stored.\n\n       The Amazon WorkMail API is designed for the following scenarios:\n\n      -Listing and describing organizations,\n\n      -Managing users,\n\n      -Managing groups,\n\n      -Managing resources,\n\n       All  Amazon  WorkMail API actions are Amazon-authenticated and certifi-\n       cate-signed. They not only require the use of the  AWS  SDK,  but  also\n       allow  for  the exclusive use of IAM users and roles to help facilitate\n       access, trust, and permission policies. By creating a role and allowing\n       an IAM user to access the Amazon WorkMail site, the IAM user gains full\n       administrative visibility into the entire Amazon WorkMail  organization\n       (or  as  set  in the IAM policy). This includes, but is not limited to,\n       the ability to create, update, and delete users, groups, and resources.\n       This  allows  developers to perform the scenarios listed above, as well\n       as give users the ability to grant access on a  selective  basis  using\n       the IAM model."
		},
		{
			"available commands": [
				"associate-delegate-to-resource",
				"associate-member-to-group",
				"create-alias",
				"create-group",
				"create-resource",
				"create-user",
				"delete-alias",
				"delete-group",
				"delete-mailbox-permissions",
				"delete-resource",
				"delete-user",
				"deregister-from-work-mail",
				"describe-group",
				"describe-organization",
				"describe-resource",
				"describe-user",
				"disassociate-delegate-from-resource",
				"disassociate-member-from-group",
				"help",
				"list-aliases",
				"list-group-members",
				"list-groups",
				"list-mailbox-permissions",
				"list-organizations",
				"list-resource-delegates",
				"list-resources",
				"list-users",
				"put-mailbox-permissions",
				"register-to-work-mail",
				"reset-password",
				"update-primary-email-address",
				"update-resource"
			]
		}
	],
	"workspaces": [{
			"name": "workspaces"
		},
		{
			"description": "Amazon   WorkSpaces  enables  you  to  provision  virtual,  cloud-based\n       Microsoft Windows desktops for your users."
		},
		{
			"available commands": [
				"associate-ip-groups",
				"authorize-ip-rules",
				"create-ip-group",
				"create-tags",
				"create-workspaces",
				"delete-ip-group",
				"delete-tags",
				"describe-ip-groups",
				"describe-tags",
				"describe-workspace-bundles",
				"describe-workspace-directories",
				"describe-workspaces",
				"describe-workspaces-connection-status",
				"disassociate-ip-groups",
				"help",
				"modify-workspace-properties",
				"modify-workspace-state",
				"reboot-workspaces",
				"rebuild-workspaces",
				"revoke-ip-rules",
				"start-workspaces",
				"stop-workspaces",
				"terminate-workspaces",
				"update-rules-of-ip-group"
			]
		}
	],
	"xray": [{
			"name": "xray"
		},
		{
			"description": "AWS  X-Ray  provides APIs for managing debug traces and retrieving ser-\n       vice maps and other data created by processing those traces."
		},
		{
			"available commands": [
				"batch-get-traces",
				"get-encryption-config",
				"get-service-graph",
				"get-trace-graph",
				"get-trace-summaries",
				"help",
				"put-encryption-config",
				"put-telemetry-records",
				"put-trace-segments"
			]
		}
	]

}